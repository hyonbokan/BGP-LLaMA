{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57c4be9003d4a2c891c8c0ec7275321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e700894d2b24780b241b9367d5eb4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "import os\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "# bnb_config = transformers.BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type='nf4',\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_compute_dtype=bfloat16\n",
    "# )\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Need auth token for these\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Given a n3.pcap file containing network traffic data, create a Python script to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Store this data in a pandas DataFrame and display it. [/INST]  To process a PCAP file and extract the source IP, destination IP, source port, destination port, and raw payload data for each packet, you can use the `pcapy` library in Python. Here's an example of how you can do this:\n",
      "```\n",
      "import pcapy\n",
      "import pandas as pd\n",
      "\n",
      "# Open the PCAP file\n",
      "with open(\"n3.pcap\", \"rb\") as f:\n",
      "    # Create a pcapy.Pcap object\n",
      "    pcap = pcapy.Pcap(f)\n",
      "\n",
      "    # Extract the packet data\n",
      "    packets = []\n",
      "    for packet in pcap.packets():\n",
      "        # Extract the source IP, destination IP, source port, destination port, and raw payload data\n",
      "        src_ip = packet.get_field(\"src_ip\")\n",
      "        dst_ip = packet.get_field(\"dst_ip\")\n",
      "        src_port = packet.get_field(\"src_port\")\n",
      "        dst_port = packet.get_field(\"dst_port\")\n",
      "        payload = packet.get_field(\"payload\")\n",
      "\n",
      "        # Add the data to a list\n",
      "        packets.append({\n",
      "            \"src_ip\": src_ip,\n",
      "            \"dst_ip\": dst_ip,\n",
      "            \"src_port\": src_port,\n",
      "            \"dst_port\": dst_port,\n",
      "            \"payload\": payload\n",
      "        })\n",
      "\n",
      "# Create a pandas DataFrame from the packet data\n",
      "df = pd.DataFrame(packets)\n",
      "\n",
      "# Display the DataFrame\n",
      "print(df)\n",
      "```\n",
      "This script will extract the source IP, destination IP, source port, destination port, and raw payload data for each packet in the PCAP file and store it in a pandas DataFrame. The DataFrame will have the following columns:\n",
      "\n",
      "* `src_ip`: The source IP address of the packet.\n",
      "* `dst_ip`: The destination IP address of the packet.\n",
      "* `src_port`: The source port number of the packet.\n",
      "* `dst_port`: The destination port number of the packet.\n",
      "* `payload`: The raw payload data of the packet.\n",
      "\n",
      "You can modify the script to suit your needs, such as filtering the packets based on specific criteria or extracting additional fields from the packets.\n",
      "\n",
      "Note: The `pcapy` library is a Python library for working with PCAP files. It provides a convenient way to parse and manipulate the packets in a PCAP file.\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Given a n3.pcap file containing network traffic data, create a Python script to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Store this data in a pandas DataFrame and display it.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Generate Python code to calculate and visualize 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns. [/INST]  Sure! Here is some Python code that can be used to calculate and visualize 5G network performance KPIs based on the provided CSV file:\n",
      "```\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "# Load the data from the CSV file\n",
      "df = pd.read_csv('5G_Infrastructure/demand_driven_postcode_data_results.csv')\n",
      "\n",
      "# Identify the relevant columns\n",
      "capacity = df['capacity']\n",
      "cost = df['cost']\n",
      "area = df['area']\n",
      "numpoints = df['numpoints']\n",
      "\n",
      "# Calculate the KPIs\n",
      "total_network_capacity = capacity.sum()\n",
      "capacity_per_area = capacity / area\n",
      "capacity_per_point = capacity / numpoints\n",
      "cost_per_capacity = cost / capacity\n",
      "cost_per_area = cost / area\n",
      "surplus_per_area = cost - (capacity * cost_per_point)\n",
      "\n",
      "# Visualize the results\n",
      "sns.barplot(x=range(len(capacity)), y=capacity, hue='numpoints')\n",
      "sns.lineplot(x=range(len(capacity)), y=capacity_per_point, label='Capacity per Point')\n",
      "sns.lineplot(x=range(len(area)), y=capacity_per_area, label='Capacity per Area')\n",
      "sns.lineplot(x=range(len(cost)), y=cost_per_capacity, label='Cost per Capacity')\n",
      "sns.lineplot(x=range(len(area)), y=cost_per_area, label='Cost per Area')\n",
      "sns.barplot(x=range(len(surplus)), y=surplus_per_area, label='Surplus per Area')\n",
      "\n",
      "# Add axis labels and titles\n",
      "plt.xlabel('Postcode')\n",
      "plt.ylabel('Capacity/Cost')\n",
      "plt.title('5G Network Performance KPIs')\n",
      "\n",
      "# Show the plot\n",
      "plt.show()\n",
      "```\n",
      "This code first loads the data from the `demand_driven_postcode_data_results.csv` file using the `pd.read_csv()` function. It then identifies the relevant columns in the data frame using the `capacity`, `cost`, `area`, and `numpoints` keywords.\n",
      "\n",
      "Next, the code calculates the KPIs using the identified columns. Specifically, it calculates the total network capacity by summing the `capacity` column, the capacity per area by dividing the `capacity` column by the `area` column, and the capacity per point by dividing the `capacity` column by the `\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Generate Python code to calculate and visualize 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Choice\n",
    "`5G configuration analysis v1`:\n",
    "Accuracy: 66%\n",
    "Correct answers: 13 + 7 = 20\n",
    "Incorrect answers: 10\n",
    "\n",
    "`5G configuration analysis v2`:\n",
    "Accuracy: 56%\n",
    "Correct answers: 17\n",
    "Incorrect answers: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
