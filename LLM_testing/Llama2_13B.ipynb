{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/myenv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d2fb931dc24e8ba872c41fa30dc608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# bnb_config = transformers.BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type='nf4',\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_compute_dtype=bfloat16\n",
    "# )\n",
    "\n",
    "hf_token = os.environ.get('hf_token')\n",
    "\n",
    "# Need auth token for these\n",
    "hf_auth = hf_token\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/20\n",
      "Processed 2/20\n",
      "Processed 3/20\n",
      "Processed 4/20\n",
      "Processed 5/20\n",
      "Processed 6/20\n",
      "Processed 7/20\n",
      "Processed 8/20\n",
      "Processed 9/20\n",
      "Processed 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/myenv/lib/python3.8/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 11/20\n",
      "Processed 12/20\n",
      "Processed 13/20\n",
      "Processed 14/20\n",
      "Processed 15/20\n",
      "Processed 16/20\n",
      "Processed 17/20\n",
      "Processed 18/20\n",
      "Processed 19/20\n",
      "Processed 20/20\n",
      "[{'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 07:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 07:05:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | no anomalies detected | [SEP] row 3: | 2022-03-28 07:10:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 07:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 07:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 07:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 07:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 07:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2022-03-28 07:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2022-03-28 07:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, no anomalies are detected during the specified time period. All values are within the expected range, and there are no significant changes or deviations from the norm.\\n\\nThe data shows a consistent number of routes, new routes, withdrawals, origin changes, and route changes throughout the time period. The maximum path length and average path length are also within the expected range. The edit distance and number of announcements are low, and there are no unique prefixes announced.\\n\\nTherefore, based on the data provided, no anomalies are detected during the specified time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 07:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 07:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 08:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 08:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 08:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 08:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 08:20:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | no anomalies detected | [SEP] row 8: | 2022-03-28 08:25:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2022-03-28 08:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2022-03-28 08:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there is no anomaly detected during the specified time period. All the values are within the expected range, and there are no sudden changes or significant deviations from the norm.\\n\\nThe table shows the following values for each column:\\n\\n* timestamp: A sequence of timestamps representing the start of each 5-minute monitoring period.\\n* asn: The Autonomous System Number (ASN) of the monitored network.\\n* num_routes: The number of routes advertised by the monitored network.\\n* num_new_routes: The number of new routes advertised by the monitored network during the monitoring period.\\n* num_withdrawals: The number of routes withdrawn by the monitored network during the monitoring period.\\n* num_origin_changes: The number of origin changes made by the monitored network during the monitoring period.\\n* num_route_changes: The number of route changes made by the monitored network during the monitoring period.\\n* max_path_length: The maximum path length observed during the monitoring period.\\n* avg_path_length: The average path length observed during the monitoring period.\\n* max_edit_distance: The maximum edit distance observed during the monitoring period.\\n* avg_edit_distance: The average edit distance observed during the monitoring period.\\n* num_announcements: The number of BGP announcements received during the monitoring period.\\n* num_unique_prefixes_announced: The number of unique prefixes announced by the monitored network during the monitoring period.\\n* anomaly_status: A flag indicating whether an anomaly was detected during the monitoring period.\\n\\nAll the values are within the expected range, and there are no sudden changes or significant deviations from the norm. Therefore, no anomaly is detected during the specified time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 08:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 08:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 08:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 08:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 09:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 09:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 09:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 09:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2022-03-28 09:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2022-03-28 09:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are no anomalies detected during the specified time period of 2022-03-28 08:40:00 to 2022-03-28 09:25:00. All the values for each column are within the expected range, and there are no significant deviations or outliers that indicate an anomaly.\\n\\nThe table shows a consistent pattern of zero values for all columns, indicating that there were no BGP announcements or changes during the monitored time period. The maximum path length and average path length are both 0, indicating that there were no routes with non-zero length. The number of announcements, unique prefixes announced, and the anomaly status are all 0, indicating that there were no anomalies detected.\\n\\nTherefore, based on the data provided, there are no anomalies detected during the specified time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 09:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 09:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 09:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 09:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 09:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 09:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 10:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 10:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 9: | 2022-03-28 10:10:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 10: | 2022-03-28 10:15:00 | 8342 | 10 | 10 | 17 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 41 | 10 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there is no anomaly detected during the specified time period. All the values are within the expected range, and there are no significant changes or deviations from the norm.\\n\\nThe data shows a steady increase in the number of routes, but the values are all within the range of 0-10, which is the expected range for this specific BGP monitoring context. There are no sudden spikes or drops in the values, and all the values are consistent with the expected behavior.\\n\\nTherefore, based on the data provided, no anomaly is detected during the specified time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 10:20:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | no anomalies detected | [SEP] row 2: | 2022-03-28 10:25:00 | 8342 | 8 | 2 | 29 | 0 | 6 | 6 | 3.5 | 4 | 2.5 | 39 | 8 | anomaly detected at 2022-03-28 10:25:00 due to high value of num_withdrawals=29, max_path_length=6, avg_path_length=3.5, max_edit_distance=4, avg_edit_distance=2.5 | [SEP] row 3: | 2022-03-28 10:30:00 | 8342 | 13 | 8 | 3 | 0 | 0 | 6 | 1.6923076923076923 | 0 | 0.0 | 13 | 13 | anomaly detected at 2022-03-28 10:30:00 due to high value of num_withdrawals=3 | [SEP] row 4: | 2022-03-28 10:35:00 | 8342 | 26 | 13 | 0 | 0 | 13 | 6 | 2.8076923076923075 | 5 | 1.6538461538461535 | 26 | 26 | anomaly detected at 2022-03-28 10:35:00 due to high value of num_route_changes=13, max_edit_distance=5 | [SEP] row 5: | 2022-03-28 10:40:00 | 8342 | 0 | 0 | 26 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | anomaly detected at 2022-03-28 10:40:00 due to high value of num_withdrawals=26 | [SEP] row 6: | 2022-03-28 10:45:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 10 | 10 | no anomalies detected | [SEP] row 7: | 2022-03-28 10:50:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | no anomalies detected | [SEP] row 8: | 2022-03-28 10:55:00 | 8342 | 6 | 1 | 11 | 0 | 5 | 7 | 5.333333333333333 | 5 | 3.5 | 6 | 6 | anomaly detected at 2022-03-28 10:55:00 due to high value of max_path_length=7, avg_path_length=5.333333333333333, max_edit_distance=5, avg_edit_distance=3.5 | [SEP] row 9: | 2022-03-28 11:00:00 | 8342 | 20 | 20 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | anomaly detected at 2022-03-28 11:00:00 due to high value of num_new_routes=20 | [SEP] row 10: | 2022-03-28 11:05:00 | 8342 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data analysis for the specified time period.\\n\\nThe first anomaly is detected at 2022-03-28 10:25:00, with the following anomalous values:\\n\\n* num_withdrawals: 29\\n* max_path_length: 6\\n* avg_path_length: 3.5\\n* max_edit_distance: 4\\n* avg_edit_distance: 2.5\\n\\nThe reason for this anomaly is the high value of num_withdrawals, which indicates a significant change in the number of routes withdrawn from the BGP table.\\n\\nThe second anomaly is detected at 2022-03-28 10:30:00, with the following anomalous values:\\n\\n* num_withdrawals: 3\\n\\nThe reason for this anomaly is the high value of num_withdrawals, which indicates a significant change in the number of routes withdrawn from the BGP table.\\n\\nThe third anomaly is detected at 2022-03-28 10:35:00, with the following anomalous values:\\n\\n* num_route_changes: 13\\n* max_edit_distance: 5\\n\\nThe reason for this anomaly is the high value of num_route_changes, which indicates a significant change in the number of routes changed in the BGP table.\\n\\nThe fourth anomaly is detected at 2022-03-28 10:40:00, with the following anomalous values:\\n\\n* num_withdrawals: 26\\n\\nThe reason for this anomaly is the high value of num_withdrawals, which indicates a significant change in the number of routes withdrawn from the BGP table.\\n\\nThe fifth anomaly is detected at 2022-03-28 10:45:00, with the following anomalous values:\\n\\n* max_path_length: 7\\n* avg_path_length: 5.333333333333333\\n* max_edit_distance: 5\\n* avg_edit_distance: 3.5\\n\\nThe reason for this anomaly is the high value of max_path_length and avg_path_length, which indicates a significant change in the length of the shortest path and the average path length in the BGP table.\\n\\nThe sixth anomaly is detected at 2022-03-28 10:55:00, with the following anomalous values:\\n\\n* num_new_routes: 20\\n\\nThe reason for this anomaly is the high value of num_new_routes, which indicates a significant change in the number of new routes announced in the BGP table.\\n\\nThe seventh anomaly is detected at 2022-03-28 11:00:00, with the following anomalous values:\\n\\n* num_withdrawals: 20\\n\\nThe reason for this anomaly is the high value of num_withdrawals, which indicates a significant change in the number of routes withdrawn from the BGP table.\\n\\nIn conclusion, there are several anomalies detected in the BGP data analysis for the specified time period, including high values of num_withdrawals, num_route_changes, max_path_length, avg_path_length, max_edit_distance, and avg_edit_distance. These anomalies indicate significant changes in the BGP table, which may be indicative of network issues or attacks.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 11:10:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 2: | 2022-03-28 11:15:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 11:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 11:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 11:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 11:35:00 | 8342 | 27 | 27 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 27 | 27 | anomaly detected at 2022-03-28 11:35:00 due to high value of num_routes=27, num_new_routes=27, num_unique_prefixes_announced=27 | [SEP] row 7: | 2022-03-28 11:40:00 | 8342 | 27 | 0 | 0 | 0 | 27 | 6 | 4.962962962962963 | 5 | 3.2222222222222223 | 27 | 27 | anomaly detected at 2022-03-28 11:40:00 due to high value of num_route_changes=27, max_path_length=6, avg_path_length=4.962962962962963, max_edit_distance=5, avg_edit_distance=3.2222222222222223 | [SEP] row 8: | 2022-03-28 11:45:00 | 8342 | 0 | 0 | 27 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | anomaly detected at 2022-03-28 11:45:00 due to high value of num_withdrawals=27 | [SEP] row 9: | 2022-03-28 11:50:00 | 8342 | 6 | 6 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 6 | 6 | no anomalies detected | [SEP] row 10: | 2022-03-28 11:55:00 | 8342 | 0 | 0 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are two anomalies detected:\\n\\n1. At timestamp 2022-03-28 11:35:00, there is an anomaly due to high values of num_routes=27, num_new_routes=27, and num_unique_prefixes_announced=27.\\n2. At timestamp 2022-03-28 11:40:00, there is an anomaly due to high values of num_route_changes=27, max_path_length=6, avg_path_length=4.962962962962963, max_edit_distance=5, and avg_edit_distance=3.2222222222222223.\\n\\nThe other timestamps do not indicate any anomalies.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 12:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 12:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 3: | 2022-03-28 12:10:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 12:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 12:20:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 6: | 2022-03-28 12:25:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 12:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 12:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 9: | 2022-03-28 12:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2022-03-28 12:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': \"Based on the data provided, there are no anomalies detected during the specified time period of 2022-03-28. All the values fall within the expected range, and there are no significant deviations or outliers that indicate an anomaly.\\n\\nThe table shows the following values for each column:\\n\\n* timestamp: The timestamp for each data point, in the format of '2022-03-28 12:00:00'\\n* asn: The autonomous system number (ASN) of the BGP peer, which is constant across all data points\\n* num_routes: The number of routes advertised by the BGP peer\\n* num_new_routes: The number of new routes advertised by the BGP peer since the previous data point\\n* num_withdrawals: The number of routes withdrawn by the BGP peer since the previous data point\\n* num_origin_changes: The number of origin changes made by the BGP peer since the previous data point\\n* num_route_changes: The number of route changes made by the BGP peer since the previous data point\\n* max_path_length: The maximum path length of the advertised routes\\n* avg_path_length: The average path length of the advertised routes\\n* max_edit_distance: The maximum edit distance of the advertised routes\\n* avg_edit_distance: The average edit distance of the advertised routes\\n* num_announcements: The number of BGP announcements received from the peer\\n* num_unique_prefixes_announced: The number of unique prefixes announced by the peer\\n* anomaly_status: A flag indicating whether an anomaly is detected or not\\n\\nAll the values are within the expected range, and there are no significant deviations or outliers that indicate an anomaly. Therefore, no anomalies are detected in the data.\"}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 12:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 12:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 13:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 13:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 13:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 13:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 13:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 13:25:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 175 | 20 | anomaly detected at 2022-03-28 13:25:00 due to high value of num_routes=20, num_new_routes=20, num_announcements=175, num_unique_prefixes_announced=20 | [SEP] row 9: | 2022-03-28 13:30:00 | 8342 | 20 | 0 | 0 | 0 | 20 | 6 | 5.75 | 4 | 4.0 | 94 | 20 | anomaly detected at 2022-03-28 13:30:00 due to high value of num_route_changes=20, max_path_length=6, avg_path_length=5.75, max_edit_distance=4, avg_edit_distance=4.0, num_announcements=94 | [SEP] row 10: | 2022-03-28 13:35:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 4 | 4.0 | 11 | 11 | anomaly detected at 2022-03-28 13:35:00 due to high value of num_announcements=11 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are three anomalies detected in the given time period. The timestamps of the anomalies and the reasons for their detection are as follows:\\n\\n1. Anomaly detected at 2022-03-28 13:25:00 due to high value of num_routes=20, num_new_routes=20, num_announcements=175, num_unique_prefixes_announced=20.\\n2. Anomaly detected at 2022-03-28 13:30:00 due to high value of num_route_changes=20, max_path_length=6, avg_path_length=5.75, max_edit_distance=4, avg_edit_distance=4.0, num_announcements=94.\\n3. Anomaly detected at 2022-03-28 13:35:00 due to high value of num_announcements=11.\\n\\nThe values that are anomalous in each case are:\\n\\n1. num_routes=20, num_new_routes=20, num_announcements=175, num_unique_prefixes_announced=20.\\n2. num_route_changes=20, max_path_length=6, avg_path_length=5.75, max_edit_distance=4, avg_edit_distance=4.0, num_announcements=94.\\n3. num_announcements=11.\\n\\nThese values are considered anomalous because they are significantly higher than the normal values seen in the data. For example, the normal value of num_routes is around 0-5, and the value of 20 is much higher than the normal range. Similarly, the normal value of num_announcements is around 0-5, and the value of 11 is also much higher than the normal range.\\n\\nTherefore, based on the data provided, there are three anomalies detected in the given time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 13:40:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 13:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 13:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 13:55:00 | 8342 | 9 | 9 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 18 | 9 | no anomalies detected | [SEP] row 5: | 2022-03-28 14:00:00 | 8342 | 25 | 16 | 1 | 0 | 9 | 8 | 2.88 | 2 | 0.72 | 69 | 25 | anomaly detected at 2022-03-28 14:00:00 due to high value of max_path_length=8 | [SEP] row 6: | 2022-03-28 14:05:00 | 8342 | 0 | 0 | 25 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | anomaly detected at 2022-03-28 14:05:00 due to high value of num_withdrawals=25 | [SEP] row 7: | 2022-03-28 14:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 14:15:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 117 | 10 | anomaly detected at 2022-03-28 14:15:00 due to high value of num_announcements=117 | [SEP] row 9: | 2022-03-28 14:20:00 | 8342 | 20 | 11 | 1 | 0 | 9 | 5 | 2.25 | 4 | 1.8 | 127 | 20 | anomaly detected at 2022-03-28 14:20:00 due to high value of max_path_length=5, max_edit_distance=4 | [SEP] row 10: | 2022-03-28 14:25:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 2 | 2.0 | 11 | 11 | anomaly detected at 2022-03-28 14:25:00 due to high value of num_announcements=11 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data analysis for the specified time period.\\n\\nThe first anomaly is detected at 2022-03-28 14:00:00, with a high value of max_path_length=8. This indicates that there is an unusual increase in the length of the shortest path in the BGP routing table.\\n\\nThe second anomaly is detected at 2022-03-28 14:05:00, with a high value of num_withdrawals=25. This indicates that there is an unusual increase in the number of withdrawals in the BGP routing table.\\n\\nThe third anomaly is detected at 2022-03-28 14:15:00, with a high value of num_announcements=117. This indicates that there is an unusual increase in the number of announcements in the BGP routing table.\\n\\nThe fourth anomaly is detected at 2022-03-28 14:20:00, with a high value of max_path_length=5 and max_edit_distance=4. This indicates that there is an unusual increase in the length of the shortest path and the number of edits in the BGP routing table.\\n\\nThe fifth anomaly is detected at 2022-03-28 14:25:00, with a high value of num_announcements=11. This indicates that there is an unusual increase in the number of announcements in the BGP routing table.\\n\\nTherefore, based on the data provided, there are several anomalies detected in the BGP data analysis for the specified time period. The timestamps of the anomalies and the reasons for their detection are as follows:\\n\\n* Anomaly 1: 2022-03-28 14:00:00, due to high value of max_path_length=8.\\n* Anomaly 2: 2022-03-28 14:05:00, due to high value of num_withdrawals=25.\\n* Anomaly 3: 2022-03-28 14:15:00, due to high value of num_announcements=117.\\n* Anomaly 4: 2022-03-28 14:20:00, due to high value of max_path_length=5 and max_edit_distance=4.\\n* Anomaly 5: 2022-03-28 14:25:00, due to high value of num_announcements=11.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 14:30:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 14:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 3: | 2022-03-28 14:40:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 5 | 1 | no anomalies detected | [SEP] row 4: | 2022-03-28 14:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 14:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 14:55:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 3 | 1 | no anomalies detected | [SEP] row 7: | 2022-03-28 15:00:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 15:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2022-03-28 15:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2022-03-28 15:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, no anomalies are detected during the specified time period. All the values are within the expected range, and there are no significant changes or deviations that indicate an anomaly.\\n\\nThe data shows a steady state of BGP activity, with a consistent number of routes, new routes, withdrawals, and origin changes. The maximum path length and average path length are also within the expected range, indicating that the BGP protocol is functioning correctly.\\n\\nTherefore, no anomalies are detected in the provided data.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 15:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 15:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 15:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 15:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 15:40:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 6: | 2022-03-28 15:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 15:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 15:55:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | anomaly detected at 2022-03-28 15:55:00 due to high value of num_routes=20, num_new_routes=20, num_unique_prefixes_announced=20 | [SEP] row 9: | 2022-03-28 16:00:00 | 8342 | 1 | 1 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | anomaly detected at 2022-03-28 16:00:00 due to high value of num_routes=1, num_new_routes=1, num_withdrawals=20, num_unique_prefixes_announced=1 | [SEP] row 10: | 2022-03-28 16:05:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | anomaly detected at 2022-03-28 16:05:00 due to high value of num_withdrawals=1 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are two anomalies detected:\\n\\n1. At timestamp 2022-03-28 15:55:00, there is an anomaly due to high values of num_routes=20, num_new_routes=20, and num_unique_prefixes_announced=20.\\n2. At timestamp 2022-03-28 16:05:00, there is an anomaly due to high value of num_withdrawals=1.\\n\\nThe reason for the first anomaly is that the number of routes, new routes, and unique prefixes announced are all significantly higher than usual, indicating a potential issue with the network or a sudden change in the routing table.\\n\\nThe reason for the second anomaly is that the number of withdrawals is significantly higher than usual, indicating a potential issue with the network or a sudden change in the routing table.\\n\\nThere are no anomalies detected in the other timestamps provided.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 16:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2022-03-28 16:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2022-03-28 16:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2022-03-28 16:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2022-03-28 16:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2022-03-28 16:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2022-03-28 16:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2022-03-28 16:45:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 9: | 2022-03-28 16:50:00 | 8342 | 1 | 0 | 0 | 0 | 0 | 3 | 3.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 10: | 2022-03-28 16:55:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': \"Based on the data provided, there are no anomalies detected during the specified time period of 2022-03-28. All the values are within the expected range, and there are no significant changes or deviations in the data.\\n\\nThe table shows the following values for each column:\\n\\n* timestamp: The timestamp of each BGP monitoring event.\\n* asn: The autonomous system number (ASN) of the peer.\\n* num_routes: The number of routes advertised by the peer.\\n* num_new_routes: The number of new routes advertised by the peer.\\n* num_withdrawals: The number of routes withdrawn by the peer.\\n* num_origin_changes: The number of origin changes in the peer's advertisements.\\n* num_route_changes: The number of route changes in the peer's advertisements.\\n* max_path_length: The maximum path length in the peer's advertisements.\\n* avg_path_length: The average path length in the peer's advertisements.\\n* max_edit_distance: The maximum edit distance in the peer's advertisements.\\n* avg_edit_distance: The average edit distance in the peer's advertisements.\\n* num_announcements: The number of BGP announcements received from the peer.\\n* num_unique_prefixes_announced: The number of unique prefixes announced by the peer.\\n* anomaly_status: A flag indicating whether an anomaly is detected or not.\\n\\nAll the values are within the expected range, and there are no significant changes or deviations in the data. Therefore, no anomalies are detected during the specified time period.\"}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2022-03-28 17:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2019-05-08 14:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2019-05-08 14:05:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2019-05-08 14:10:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2019-05-08 14:15:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2019-05-08 14:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2019-05-08 14:25:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2019-05-08 14:30:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2019-05-08 14:35:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2019-05-08 14:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, no anomalies are detected. All the values for each column are consistent and within the expected range, indicating a normal and stable network condition.\\n\\nThere is no reason to detect any anomalies in the data provided, as all the values are zero or close to zero, indicating a lack of significant changes or events in the BGP monitoring data for the specified time period.\\n\\nTherefore, the answer is \"no anomalies detected\".'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2019-05-08 14:45:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2019-05-08 14:50:00 | 268869 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 8 | 1 | no anomalies detected | [SEP] row 3: | 2019-05-08 14:55:00 | 268869 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2019-05-08 15:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2019-05-08 15:05:00 | 268869 | 7 | 7 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 373 | 7 | anomaly detected at 2019-05-08 15:05:00 due to high value of num_routes=7, num_new_routes=7, num_unique_prefixes_announced=7 | [SEP] row 6: | 2019-05-08 15:10:00 | 268869 | 2 | 0 | 183 | 0 | 2 | 6 | 6.0 | 4 | 4.0 | 580 | 2 | anomaly detected at 2019-05-08 15:10:00 due to high value of num_withdrawals=183, max_path_length=6, avg_path_length=6.0, max_edit_distance=4, avg_edit_distance=4.0 | [SEP] row 7: | 2019-05-08 15:15:00 | 268869 | 0 | 0 | 2 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | anomaly detected at 2019-05-08 15:15:00 due to high value of num_withdrawals=2 | [SEP] row 8: | 2019-05-08 15:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2019-05-08 15:25:00 | 268869 | 5 | 5 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 392 | 5 | no anomalies detected | [SEP] row 10: | 2019-05-08 15:30:00 | 268869 | 5 | 0 | 0 | 0 | 5 | 6 | 5.8 | 3 | 3.0 | 13 | 5 | anomaly detected at 2019-05-08 15:30:00 due to high value of num_route_changes=5, max_path_length=6, avg_path_length=5.8 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Yes, the data indicates an anomaly.\\n\\nThe anomaly is detected at timestamp 2019-05-08 15:05:00. The reason for the anomaly is the high value of num_routes=7, num_new_routes=7, and num_unique_prefixes_announced=7. These values are significantly higher than the previous timestamps, indicating a sudden change or increase in the number of routes, new routes, and unique prefixes announced.\\n\\nAdditionally, the high values of max_path_length=6, avg_path_length=6.0, max_edit_distance=4, and avg_edit_distance=4.0 at timestamp 2019-05-08 15:10:00 also indicate an anomaly. These values are higher than the previous timestamps and indicate a significant increase in the length of the shortest path and the average path length, as well as a higher maximum edit distance.\\n\\nFinally, the high value of num_withdrawals=2 at timestamp 2019-05-08 15:15:00 also indicates an anomaly. This value is significantly higher than the previous timestamps, indicating a sudden increase in the number of withdrawals.\\n\\nIn summary, the data indicates an anomaly at timestamps 2019-05-08 15:05:00, 2019-05-08 15:10:00, and 2019-05-08 15:15:00 due to high values of num_routes, num_new_routes, num_unique_prefixes_announced, max_path_length, avg_path_length, max_edit_distance, and avg_edit_distance.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2019-05-08 15:35:00 | 268869 | 0 | 0 | 5 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2019-05-08 15:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2019-05-08 15:45:00 | 268869 | 4 | 4 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 4 | 4 | no anomalies detected | [SEP] row 4: | 2019-05-08 15:50:00 | 268869 | 0 | 0 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2019-05-08 15:55:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2019-05-08 16:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2017-12-12 04:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2017-12-12 04:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2017-12-12 04:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2017-12-12 04:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are no anomalies detected during the specified time period. All the values fall within the expected range, and there are no significant changes or deviations in any of the columns.\\n\\nThe table shows a consistent pattern of low values for all columns, with no sudden spikes or drops in any of the metrics. The maximum value of num_routes is 4, and the average value is 0.0, indicating that there are no routes announced during the monitoring period. Similarly, the maximum value of num_new_routes is 0, and the average value is 0.0, indicating that no new routes were announced during the monitoring period.\\n\\nThe other columns, such as num_withdrawals, num_origin_changes, num_route_changes, max_path_length, avg_path_length, max_edit_distance, avg_edit_distance, num_announcements, and num_unique_prefixes_announced, all have low values and do not indicate any anomalies.\\n\\nTherefore, based on the data provided, no anomalies are detected during the specified time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2017-12-12 04:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2017-12-12 04:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2017-12-12 04:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2017-12-12 04:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2017-12-12 04:40:00 | 39523 | 77 | 77 | 393 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 12086 | 77 | anomaly detected at 2017-12-12 04:40:00 due to high value of num_routes=77, num_new_routes=77, num_announcements=12086, num_unique_prefixes_announced=77 | [SEP] row 6: | 2017-12-12 04:45:00 | 39523 | 50 | 3 | 1470 | 0 | 47 | 8 | 5.66 | 5 | 2.94 | 3427 | 50 | anomaly detected at 2017-12-12 04:45:00 due to high value of num_new_routes=3, num_route_changes=47, max_path_length=8, avg_path_length=5.66, max_edit_distance=5, avg_edit_distance=2.94 | [SEP] row 7: | 2017-12-12 04:50:00 | 39523 | 0 | 0 | 50 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | anomaly detected at 2017-12-12 04:50:00 due to high value of num_withdrawals=50 | [SEP] row 8: | 2017-12-12 04:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2017-12-12 05:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2017-12-12 05:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are two anomalies detected:\\n\\n1. At timestamp 2017-12-12 04:40:00, there is an anomaly due to high values of num_routes=77, num_new_routes=77, num_announcements=12086, and num_unique_prefixes_announced=77.\\n2. At timestamp 2017-12-12 04:45:00, there is an anomaly due to high values of num_new_routes=3, num_route_changes=47, max_path_length=8, avg_path_length=5.66, max_edit_distance=5, and avg_edit_distance=2.94.\\n\\nThe other timestamps do not indicate any anomalies.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2017-12-12 05:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2017-12-12 05:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2017-12-12 05:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2017-12-12 05:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2017-12-12 05:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 6: | 2017-12-12 05:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2017-12-12 05:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2017-12-12 05:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2017-12-12 05:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2017-12-12 05:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are no anomalies detected during the specified time period of 2017-12-12 05:10:00 to 2017-12-12 05:55:00. All the values for the columns are within the expected range, and there are no significant changes or deviations from the norm.\\n\\nTherefore, the answer is:\\n\\nNo anomalies detected.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2017-12-12 06:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2017-12-12 06:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2017-12-12 06:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2017-12-12 06:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2017-12-12 06:20:00 | 39523 | 31 | 31 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 57 | 31 | no anomalies detected | [SEP] row 6: | 2017-12-12 06:25:00 | 39523 | 0 | 0 | 31 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2017-12-12 06:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2017-12-12 06:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2017-12-12 06:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2017-12-12 06:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are no anomalies detected during the specified time period. All the values for each column are within the expected range, and there are no significant deviations or outliers that would indicate an anomaly.\\n\\nThe table shows a consistent pattern of low values for all columns, with no sudden spikes or changes that would indicate an anomaly. The maximum value for each column is also within the expected range, and there are no values that are significantly higher or lower than the rest of the data.\\n\\nTherefore, based on the data provided, no anomalies are detected during the specified time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2017-12-12 06:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2017-12-12 06:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 3: | 2017-12-12 07:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2017-12-12 07:05:00 | 39523 | 74 | 74 | 2211 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16467 | 74 | anomaly detected at 2017-12-12 07:05:00 due to high value of num_routes=74, num_new_routes=74, num_withdrawals=2211, num_announcements=16467, num_unique_prefixes_announced=74 | [SEP] row 5: | 2017-12-12 07:10:00 | 39523 | 20 | 2 | 96 | 0 | 16 | 8 | 6.3 | 4 | 2.6 | 73 | 20 | anomaly detected at 2017-12-12 07:10:00 due to high value of num_routes=20, num_new_routes=2, num_withdrawals=96, max_path_length=8, avg_path_length=6.3, max_edit_distance=4, avg_edit_distance=2.6, num_announcements=73, num_unique_prefixes_announced=20 | [SEP] row 6: | 2017-12-12 07:15:00 | 39523 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 7: | 2017-12-12 07:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 8: | 2017-12-12 07:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 9: | 2017-12-12 07:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 10: | 2017-12-12 07:35:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 181 | 1 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are two anomalies detected:\\n\\n1. At timestamp 2017-12-12 07:05:00, there is an anomaly due to high values of num_routes, num_new_routes, num_withdrawals, num_announcements, and num_unique_prefixes_announced.\\n2. At timestamp 2017-12-12 07:10:00, there is an anomaly due to high values of max_path_length, avg_path_length, max_edit_distance, and avg_edit_distance.\\n\\nThe reason for the anomalies is that the values of these metrics are significantly higher than the values in the previous time periods (rows 1-4). For example, the number of routes, new routes, and announcements are all much higher at timestamp 07:05:00 than in the previous time periods, indicating an anomaly. Similarly, the values of max_path_length, avg_path_length, max_edit_distance, and avg_edit_distance are all much higher at timestamp 07:10:00 than in the previous time periods, indicating an anomaly.\\n\\nThere are no anomalies detected in the other time periods (rows 5-10).'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | anomaly_status | row 1: | 2017-12-12 07:40:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 2: | 2017-12-12 07:45:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | no anomalies detected | [SEP] row 3: | 2017-12-12 07:50:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 4: | 2017-12-12 07:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP] row 5: | 2017-12-12 08:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | no anomalies detected | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are no anomalies detected during the specified time period. All rows have normal values for all columns, and there are no instances of unexpected or extreme values that could indicate an anomaly.\\n\\nThe data shows a consistent pattern of low values for all columns, with no significant changes or deviations from the expected norm. The maximum value for any column is 1, and the average value for most columns is 0. This suggests that the data is consistent with normal BGP monitoring data and does not indicate any anomalies.\\n\\nTherefore, the answer is \"no anomalies detected\" for the given time period.'}]\n",
      "Results saved to llama-with-outputs-10.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tablular_eval_util import combine_csv_files, split_dataframe, preprocess_data, run_llm_inference\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "\n",
    "# Split the DataFrame into smaller chunks\n",
    "split_size = 10\n",
    "data_list = split_dataframe(combined_df, split_size)\n",
    "\n",
    "# Preprocess the data into the required format\n",
    "formatted_data = [preprocess_data(chunk) for chunk in data_list]\n",
    "\n",
    "formatted_data_file = f'llm_table_bgp_data_test_{split_size}.json'\n",
    "with open(formatted_data_file, 'w') as f:\n",
    "    json.dump(formatted_data, f, indent=4)\n",
    "\n",
    "with open(formatted_data_file, 'r') as f:\n",
    "    formatted_data = json.load(f)\n",
    "\n",
    "output_results_file = f'llama-with-outputs-{split_size}.json'\n",
    "run_llm_inference(formatted_data, model, tokenizer, max_length=3050, output_results_file=output_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 09:25:00', '2017-12-12 04:45:00', '2022-03-28 10:55:00', '2022-03-28 13:30:00', '2019-05-08 15:15:00', '2022-03-28 10:25:00', '2022-03-28 08:40:00', '2022-03-28 14:15:00', '2022-03-28 10:30:00', '2022-03-28 13:35:00', '2022-03-28 10:35:00', '2022-03-28 11:40:00', '2022-03-28 15:55:00', '2022-03-28 11:35:00', '2019-05-08 15:10:00', '2022-03-28 13:25:00', '2022-03-28 14:20:00', '2017-12-12 05:55:00', '2022-03-28 16:05:00', '2017-12-12 05:10:00', '2017-12-12 07:10:00', '2022-03-28 10:45:00', '2019-05-08 15:05:00', '2022-03-28 14:25:00', '2022-03-28 12:00:00', '2022-03-28 14:00:00', '2022-03-28 14:05:00', '2017-12-12 07:05:00', '2022-03-28 10:40:00', '2017-12-12 04:40:00', '2022-03-28 11:00:00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "llama13b_outputs = pd.read_json(f\"/home/hb/LLM-research/LLM_testing/llama-with-outputs-{split_size}.json\")\n",
    "llama13b_outputs = llama13b_outputs[\"output\"]\n",
    "# llama13b_outputs.to_csv(\"llm_13B_bgp_data_with_outputs_10.csv\")\n",
    "\n",
    "timestamps = []\n",
    "\n",
    "timestamp_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}')\n",
    "\n",
    "for output in llama13b_outputs:\n",
    "    matches = timestamp_pattern.findall(output)\n",
    "    timestamps.extend(matches)\n",
    "\n",
    "llama13b_outputs_timestamp = list(set(timestamps))\n",
    "\n",
    "print(llama13b_outputs_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 10:25:00', '2022-03-28 10:30:00', '2022-03-28 10:35:00', '2022-03-28 10:40:00', '2022-03-28 10:55:00', '2022-03-28 11:00:00', '2022-03-28 11:35:00', '2022-03-28 11:40:00', '2022-03-28 11:45:00', '2022-03-28 13:25:00', '2022-03-28 13:30:00', '2022-03-28 13:35:00', '2022-03-28 14:00:00', '2022-03-28 14:05:00', '2022-03-28 14:15:00', '2022-03-28 14:20:00', '2022-03-28 14:25:00', '2022-03-28 15:55:00', '2022-03-28 16:00:00', '2022-03-28 16:05:00', '2019-05-08 15:05:00', '2019-05-08 15:10:00', '2019-05-08 15:15:00', '2019-05-08 15:30:00', '2017-12-12 04:40:00', '2017-12-12 04:45:00', '2017-12-12 04:50:00', '2017-12-12 07:05:00', '2017-12-12 07:10:00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import combine_csv_files\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "combined_df = combined_df[['anomaly_status']]\n",
    "\n",
    "# Filter the rows with \"anomaly detected\" in the anomaly_status\n",
    "filtered_df = combined_df[combined_df['anomaly_status'].str.contains('anomaly detected', na=False)]\n",
    "\n",
    "# Extract the date from the anomaly_status string\n",
    "true_label = filtered_df['anomaly_status'].str.extract(r'anomaly detected at (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})')\n",
    "\n",
    "# Convert the dates to a list\n",
    "true_label = true_label[0].tolist()\n",
    "\n",
    "print(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Precision: 0.81\n",
      "Recall: 0.86\n",
      "F1 Score: 0.83\n",
      "True Positives: 25\n",
      "False Positives: 6\n",
      "False Negatives: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import evaluate_llm_results\n",
    "\n",
    "evaluation_result = evaluate_llm_results(true_anomalies=true_label, llm_results=llama13b_outputs_timestamp)\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Precision: {evaluation_result['precision']:.2f}\")\n",
    "print(f\"Recall: {evaluation_result['recall']:.2f}\")\n",
    "print(f\"F1 Score: {evaluation_result['f1_score']:.2f}\")\n",
    "print(f\"True Positives: {evaluation_result['true_positives']}\")\n",
    "print(f\"False Positives: {evaluation_result['false_positives']}\")\n",
    "print(f\"False Negatives: {evaluation_result['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pcap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Create a Python script with the Scapy library to detect DDoS attacks from a PCAP file. The script should read the file, analyze traffic patterns by monitoring packets per second against a set threshold within defined time windows, and reset counters for each time window. It should also log any potential attacks showing the source IP and packet rate. Include a final check for the last time window at the end of the file. [/INST]  Sure! Here is a Python script using the Scapy library to detect DDoS attacks from a PCAP file:\n",
      "```\n",
      "import scapy\n",
      "import time\n",
      "import datetime\n",
      "\n",
      "# Set parameters\n",
      "pcap_file = \"attack_capture.pcap\"\n",
      "threshold = 1000 # packets per second\n",
      "time_window = 10 # seconds\n",
      "\n",
      "# Open PCAP file\n",
      "pcap = scapy.PCAP(pcap_file)\n",
      "\n",
      "# Initialize counters\n",
      "source_ip_counter = {}\n",
      "packet_counter = {}\n",
      "\n",
      "# Loop through PCAP file\n",
      "for p in pcap:\n",
      "    # Check if packet is from a new source IP\n",
      "    if p.src not in source_ip_counter:\n",
      "        # Initialize source IP counter\n",
      "        source_ip_counter[p.src] = 1\n",
      "    else:\n",
      "        # Increment source IP counter\n",
      "        source_ip_counter[p.src] += 1\n",
      "    \n",
      "    # Check if packet rate exceeds threshold\n",
      "    if source_ip_counter[p.src] > threshold:\n",
      "        # Log potential attack\n",
      "        print(f\"Possible DDoS attack from {p.src}: {source_ip_counter[p.src]} packets per second\")\n",
      "    \n",
      "    # Update packet counter for current time window\n",
      "    packet_counter[p.time] += 1\n",
      "    \n",
      "    # Check if packet rate exceeds threshold for current time window\n",
      "    if packet_counter[p.time] > threshold:\n",
      "        # Log potential attack\n",
      "        print(f\"Possible DDoS attack at {p.time}: {packet_counter[p.time]} packets per second\")\n",
      "    \n",
      "    # Reset counters for next time window\n",
      "    packet_counter[p.time] = 0\n",
      "    \n",
      "# Check for final potential attack in last time window\n",
      "if packet_counter[p.time] > threshold:\n",
      "    print(f\"Possible DDoS attack at end of file: {packet_counter[p.time]} packets per second\")\n",
      "\n",
      "# Close PCAP file\n",
      "pcap.close()\n",
      "```\n",
      "Here's how the script works:\n",
      "\n",
      "1. It initializes three dictionaries: `source_ip_counter` to keep track of the number of packets received from each source IP, `packet_counter` to keep track of the number of packets received in each time window, and `time` to keep track of the current time.\n",
      "2. It loops through each packet in the PCAP file, and for each packet, it checks if the source IP is already in `source_ip_counter`. If it's not, it initializes the counter for that source IP. If it is, it increments the counter.\n",
      "3. It then checks if the number of packets from\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Create a Python script with the Scapy library to detect DDoS attacks from a PCAP file. The script should read the file, analyze traffic patterns by monitoring packets per second against a set threshold within defined time windows, and reset counters for each time window. It should also log any potential attacks showing the source IP and packet rate. Include a final check for the last time window at the end of the file.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Given a n3.pcap file containing network traffic data, create a Python script using scapy library to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Store this data in a pandas DataFrame and display it. [/INST]  Sure! Here is a Python script using the Scapy library to process a PCAP file and extract the source IP, destination IP, source port, destination port, and raw payload data for each packet. The data is then stored in a pandas DataFrame and displayed.\n",
      "```\n",
      "import scapy\n",
      "import pandas as pd\n",
      "\n",
      "# Open the PCAP file\n",
      "pcap = scapy.open(\"n3.pcap\")\n",
      "\n",
      "# Create a list to store the packet data\n",
      "packet_data = []\n",
      "\n",
      "# Iterate over each packet in the PCAP file\n",
      "for packet in pcap:\n",
      "    # Extract the source IP, destination IP, source port, and destination port\n",
      "    src_ip = packet.src_ip\n",
      "    dst_ip = packet.dst_ip\n",
      "    src_port = packet.sport\n",
      "    dst_port = packet.dport\n",
      "    \n",
      "    # Extract the raw payload data\n",
      "    payload = packet.payload\n",
      "    \n",
      "    # Add the packet data to the list\n",
      "    packet_data.append((src_ip, dst_ip, src_port, dst_port, payload))\n",
      "\n",
      "# Convert the list to a pandas DataFrame\n",
      "df = pd.DataFrame(packet_data, columns=[\"Source IP\", \"Destination IP\", \"Source Port\", \"Destination Port\", \"Payload\"])\n",
      "\n",
      "# Display the DataFrame\n",
      "print(df)\n",
      "```\n",
      "This script uses the `scapy` library to open the PCAP file and iterate over each packet. For each packet, it extracts the source IP, destination IP, source port, destination port, and raw payload data using the `sport`, `dport`, and `payload` attributes of the `packet` object.\n",
      "\n",
      "The extracted data is then stored in a list, which is converted to a pandas DataFrame using the `pd.DataFrame` function. Finally, the DataFrame is displayed using the `print` function.\n",
      "\n",
      "Note that this script assumes that the PCAP file contains only Ethernet frames. If the PCAP file contains other types of frames (e.g., IPv6, ARP), you may need to modify the script accordingly.\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Given a n3.pcap file containing network traffic data, create a Python script using scapy library to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Store this data in a pandas DataFrame and display it.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1012)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Create a Python script using PyBGPStream to monitor real-time (project='ris-live') BGP updates, focusing on announcements from AS6830. The script utilizes a dictionary to track the timestamp and count of announcements for each prefix associated with AS6830. Implement a function that checks daily if the data needs to be reset by comparing the current date with the date of the last reset, and if they differ, it clears the dictionary, ensuring data freshness each new day. The script should also alert if any prefix's count exceeds 10,000 to flag significant anomalies in real time. For extracting AS paths from BGP updates, use the code as_path = elem.fields.get('as-path', '').split() to accurately parse the path and identify announcements directly associated with AS6830.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=718)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5G General Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_file_path = \"/home/hb/LLM-research/evaluation/5G/5G_analysis_multi_choice_v2.json\" \n",
    "\n",
    "with open(input_file_path, \"r\") as input_file:\n",
    "    questions_data = json.load(input_file)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "\n",
    "generated_answers = []\n",
    "ground_truth = [q_dict[\"answer\"] for q_dict in questions_data]\n",
    "n_question = 0\n",
    "\n",
    "for q_dict in questions_data:\n",
    "    question = q_dict[\"question\"]\n",
    "    options = q_dict[\"options\"]\n",
    "    \n",
    "    # Construct prompt with question and options\n",
    "    prompt = f\"Choose the correct answer. {question}\\n\" + \"\\n\".join(options)\n",
    "    # print(prompt)\n",
    "    \n",
    "    # Generate answer using the language model\n",
    "    generated_answer = pipe(prompt)[0]['generated_text']\n",
    "    print(f\"Generated Answer: {generated_answer}\")\n",
    "    \n",
    "    # Parse the generated answer\n",
    "    answer_lines = generated_answer.splitlines()\n",
    "    parsed_answer = \"\"\n",
    "    for line in answer_lines:\n",
    "            if line.startswith(\"Answer: \") or line.startswith(\"Correct answer: \"):\n",
    "                match = re.search(r'\\b(\\w)[\\)-]', line)\n",
    "                if match is not None:\n",
    "                    parsed_answer = match.group(1)\n",
    "                    print(f\"Parsed_answer: {parsed_answer}\")\n",
    "                    break\n",
    "                else:\n",
    "                    parsed_answer = \"Couldn't parse the answer\"\n",
    "                    print(f\"Parsed_answer: {parsed_answer}\")\n",
    "    generated_answers.append(parsed_answer)\n",
    "    n_question += 1\n",
    "    print(f\"----------------{n_question}-----------------\")\n",
    "print(generated_answers)\n",
    "\n",
    "\n",
    "total_questions = len(questions_data)\n",
    "correct_answers = 0\n",
    "\n",
    "for ground_answer, generated_answer in zip(ground_truth, generated_answers):\n",
    "    if generated_answer.lower() == ground_answer.lower():\n",
    "        print(\"Correct\")\n",
    "        correct_answers += 1\n",
    "    else:\n",
    "        print(f\"GPT answer: {generated_answer}. Correct answer: {ground_answer}\")\n",
    "        print(\"Incorrect\")\n",
    "\n",
    "accuracy = (correct_answers / total_questions) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Correct answers: {correct_answers}\")\n",
    "print(f\"Incorrect answers: {total_questions - correct_answers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "input_file_path = \"/home/hb/LLM-research/evaluation/5G_SPEC/5G_SPEC_QA.json\" \n",
    "\n",
    "with open(input_file_path, \"r\") as input_file:\n",
    "    questions_data = json.load(input_file)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "generated_answers_qa = []\n",
    "\n",
    "n_question = 0\n",
    "for q_dict in questions_data:\n",
    "    n_question += 1\n",
    "    question = q_dict[\"question\"]\n",
    "    # Generate answer using the language model\n",
    "    prompt = f\"[INST]{question}[/INST]\"\n",
    "    generated_answer = pipe(prompt)[0]['generated_text']\n",
    "    print(f\"Output: {generated_answer}\")\n",
    "    generated_answers_qa.append(generated_answer)\n",
    "    print(f\"---------------------{n_question}-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5G analysis knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Choice\n",
    "`5G configuration analysis v1`:\n",
    "Accuracy: 90%\n",
    "Correct answers: 21 + 7 = 28\n",
    "Incorrect answers: 2\n",
    "\n",
    "`5G configuration analysis v2`:\n",
    "Accuracy: 70.00%\n",
    "Correct answers: 21\n",
    "Incorrect answers: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
