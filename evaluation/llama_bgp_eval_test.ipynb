{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from typing import List\n",
    "import torch\n",
    "from torch import cuda, bfloat16\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c9608b6ee647b2bc14c84c3a5d38f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_id = 'hyonbokan/BGPStream13-10k-cutoff-1024-max-2048'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# bnb_config = transformers.BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,\n",
    "# )\n",
    "\n",
    "# Need auth token for these\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: BGPStream13-10k-cutoff-1024-max-2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Analysis of BGP Table Statistics\n",
    "1. Use PyBGPStream (project=ris-live, exclude from_time and until_time), to preform real-time analysis of the BGP table statistics for AS131072, focusing on the characteristics of advertisements. Print the metrics evaluating the degree of similarity of the AS paths of these specific advertisements to their encompassing aggregate.\n",
    "\n",
    "2. Write a Python script using PyBGPStream to analyze BGP advertisements for AS34549 during a specific time period from 13:00 to 14:00 on 2024-01-01. The script needs to focus on dissecting the characteristics of BGP advertisements for AS34549, especially examining the AS paths. The script is expected to calculate and present metrics assessing how similar the AS paths of individual advertisements are to those of their encompassing aggregate routes. The goal is to detect, analyze, and report any noticeable patterns in AS path similarities, indicating potential routing strategies or policy implementations by AS34549 during the indicated period. This directive aims to guide the script in analyzing a precise segment of historical BGP data, concentrating on advertisements linked to AS34549, to reveal insights into routing patterns or policy applications based on AS path analysis. Do not use filter parameter.\n",
    "\n",
    "3. best\n",
    "Develop a Python script utilizing PyBGPStream to scrutinize BGP advertisements from AS34549 within the timeframe of 13:00 to 14:00 on January 1, 2024 from collectors rrc00. The script's core objective is to compute and elucidate metrics that illustrate the degree of similarity or divergence among the AS paths of these advertisements, in comparison to a broader, aggregate perspective of AS34549's routing behavior. Through this analytical lens, the script should unveil any discernible trends or anomalies in AS path configurations, thereby shedding light on the underlying routing strategies or policy adaptations employed by AS34549. This detailed examination is intended to provide a nuanced understanding of AS34549's network routing dynamics and policy nuances during the specified window, offering a focused exploration of historical BGP advertisement data without applying the PyBGPStream 'filter' parameter.\n",
    "\n",
    "4. \n",
    "Develop a Python script utilizing PyBGPStream to scrutinize BGP advertisements from AS34549 within the timeframe of 13:00 to 14:00 on January 1, 2024 from collectors rrc00. The script's core objective is to compute metrics that illustrate the degree of similarity or divergence among the AS paths of these advertisements, in comparison to a broader, aggregate perspective of AS34549's routing behavior. The script should unveil any discernible trends or anomalies in AS path configurations, thereby showing the underlying routing strategies or policy adaptations employed by AS34549. Do not use PyBGPStream 'filter' parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Develop a Python script utilizing PyBGPStream to scrutinize BGP advertisements from AS34549 within the timeframe of 13:00 to 14:00 on January 1, 2024 from collectors rrc00. The script's core objective is to compute and elucidate metrics that illustrate the degree of similarity or divergence among the AS paths of these advertisements, in comparison to a broader, aggregate perspective of AS34549's routing behavior. Through this analytical lens, the script should unveil any discernible trends or anomalies in AS path configurations, thereby shedding light on the underlying routing strategies or policy adaptations employed by AS34549. This detailed examination is intended to provide a nuanced understanding of AS34549's network routing dynamics and policy nuances during the specified window, offering a focused exploration of historical BGP advertisement data without applying the PyBGPStream 'filter' parameter. [/INST]  Here is a Python script that utilizes PyBGPStream to scrutinize BGP advertisements from AS34549 within the timeframe of 13:00 to 14:00 on January 1, 2024 from collector rrc00:\n",
      "```\n",
      "import pybgpstream\n",
      "\n",
      "# Initialize the BGPStream\n",
      "stream = pybgpstream.BGPStream(\n",
      "    from_time=\"2024-01-01 13:00:00\",\n",
      "    until_time=\"2024-01-01 14:00:00\",\n",
      "    collectors=[\"rrc00\"],\n",
      "    record_type=\"updates\"\n",
      ")\n",
      "\n",
      "# Dictionary to store the AS paths and their corresponding counts\n",
      "as_path_counts = {}\n",
      "\n",
      "# Process BGP records\n",
      "for rec in stream.records():\n",
      "    for elem in rec:\n",
      "        if elem.type == \"A\":  # Check for BGP announcements\n",
      "            as_path = elem.fields[\"as-path\"].split()\n",
      "            origin_as = as_path[-1]\n",
      "            if origin_as == \"34549\":\n",
      "                # Count the number of occurrences of each AS path\n",
      "                if as_path not in as_path_counts:\n",
      "                    as_path_counts[as_path] = 1\n",
      "                else:\n",
      "                    as_path_counts[as_path] += 1\n",
      "\n",
      "# Compute and elucidate metrics that illustrate the degree of similarity or divergence among the AS paths\n",
      "# of these advertisements\n",
      "#... (rest of the code to compute and elucidate metrics)\n",
      "```\n",
      "The script processes BGP records and counts the number of occurrences of each AS path. Then, it computes and elucidates metrics that illustrate the degree of similarity or divergence among the AS paths of these advertisements, in comparison to a broader, aggregate perspective of AS34549's routing behavior.\n",
      "\n",
      "The script can be further modified to compute and elucidate additional metrics, such as the average AS path length, the number of unique AS paths, and the percentage of AS paths that contain a specific AS number.\n",
      "\n",
      "The script can also be modified to analyze the historical BGP data from other collectors, such as rrc01, rrc02, and rrc03, to compare the routing behavior of AS34549 across different collectors.\n",
      "\n",
      "The script can also be modified to analyze the BGP data from other time periods, such as the previous day, the previous week, or the previous month, to study the changes in AS34549's routing behavior over time.\n",
      "\n",
      "The script can also be modified to analyze the BGP data from other AS numbers, such as AS34548, AS34550, and AS34551, to compare the routing behavior of these AS numbers and identify any trends or anomalies.\n",
      "\n",
      "The script can also be modified to analyze the BGP data from other sources, such as RIS, RIPE, and NLNOG, to compare the routing behavior of AS34549 across different sources and identify any trends or anomalies.\n",
      "\n",
      "The script can also be modified to analyze the BGP data from other time periods, such as the previous day, the previous week, or the previous month, to study the changes in AS34549's routing behavior over time.\n",
      "\n",
      "The script\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Develop a Python script utilizing PyBGPStream to scrutinize BGP advertisements from AS34549 within the timeframe of 13:00 to 14:00 on January 1, 2024 from collectors rrc00. The script's core objective is to compute and elucidate metrics that illustrate the degree of similarity or divergence among the AS paths of these advertisements, in comparison to a broader, aggregate perspective of AS34549's routing behavior. Through this analytical lens, the script should unveil any discernible trends or anomalies in AS path configurations, thereby shedding light on the underlying routing strategies or policy adaptations employed by AS34549. This detailed examination is intended to provide a nuanced understanding of AS34549's network routing dynamics and policy nuances during the specified window, offering a focused exploration of historical BGP advertisement data without applying the PyBGPStream 'filter' parameter.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "\n",
    "# Initialize BGPStream\n",
    "stream = pybgpstream.BGPStream(\n",
    "    from_time=\"2024-01-01 13:00:00\", until_time=\"2024-01-01 14:00:00\",\n",
    "    collectors=[\"rrc00\"],\n",
    "    record_type=\"updates\"\n",
    ")\n",
    "\n",
    "# Initialize a dictionary to store the AS paths\n",
    "as_paths = {}\n",
    "\n",
    "# Process BGP records\n",
    "for rec in stream.records():\n",
    "    for elem in rec:\n",
    "        if elem.type == \"A\":  # Check for BGP announcements\n",
    "            as_path = elem.fields[\"as-path\"].split()\n",
    "            prefix = elem.fields[\"prefix\"]\n",
    "            as_paths[prefix] = as_path\n",
    "\n",
    "# Compute metrics to illustrate the degree of similarity or divergence among the AS paths\n",
    "for prefix, as_path in as_paths.items():\n",
    "    # Compute the number of ASes in the AS path\n",
    "    num_ases = len(as_path)\n",
    "\n",
    "    # Compute the number of unique ASes in the AS path\n",
    "    num_unique_ases = len(set(as_path))\n",
    "\n",
    "    # Compute the percentage of unique ASes in the AS path\n",
    "    unique_ases_percentage = (num_unique_ases / num_ases) * 100\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Prefix: {prefix}, AS Path: {as_path}, Number of ASes: {num_ases}, Number of Unique ASes: {num_unique_ases}, Unique ASes Percentage: {unique_ases_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: BGP Path Update Analysis/Report\n",
    "Use PyBGPStream to collect BGP path updates for AS14061 and summarize: origin paths, next-hop paths, transit paths, first-hop changes, and prepend actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Use PyBGPStream to generate code that will collect BGP path updates for AS14061 and summarize: origin paths, next-hop paths, transit paths, first-hop changes, and prepend actions.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=718)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "\n",
    "# Initialize BGPStream\n",
    "stream = pybgpstream.BGPStream(\n",
    "    from_time=\"2024-01-01 13:00:00\", until_time=\"2024-01-01 15:00:00\",\n",
    "    collectors=[\"rrc00\"],\n",
    "    record_type=\"updates\",\n",
    "    filter=\"peer 34549\"\n",
    ")\n",
    "\n",
    "# Initialize variables\n",
    "origin_paths = []\n",
    "next_hop_paths = []\n",
    "transit_paths = []\n",
    "first_hop_changes = []\n",
    "prepend_actions = []\n",
    "\n",
    "# Loop through the stream records\n",
    "for rec in stream.records():\n",
    "    for elem in rec:\n",
    "        # print(elem)\n",
    "        if elem.type == \"A\":\n",
    "            # Origin Paths\n",
    "            if elem.fields[\"as-path\"].startswith(\"34549\"):\n",
    "                origin_paths.append(elem.fields[\"as-path\"])\n",
    "            # Next-Hop Paths\n",
    "            if elem.fields[\"next-hop\"] == \"34549\":\n",
    "                next_hop_paths.append(elem.fields[\"as-path\"])\n",
    "            # Transit Paths\n",
    "            if elem.fields[\"as-path\"].startswith(\"34549\"):\n",
    "                transit_paths.append(elem.fields[\"as-path\"])\n",
    "            # First-Hop Changes\n",
    "            if elem.fields[\"as-path\"].startswith(\"34549\") and elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"next-hop\"]:\n",
    "                first_hop_changes.append(elem.fields[\"as-path\"])\n",
    "            # Prepend Actions\n",
    "            if elem.fields[\"as-path\"].startswith(\"34549\") and elem.fields[\"as-path\"].split()[-1] == elem.fields[\"next-hop\"]:\n",
    "                prepend_actions.append(elem.fields[\"as-path\"])\n",
    "\n",
    "# Print the results\n",
    "print(\"Origin Paths:\")\n",
    "for path in origin_paths:\n",
    "    print(path)\n",
    "\n",
    "print(\"Next-Hop Paths:\")\n",
    "for path in next_hop_paths:\n",
    "    print(path)\n",
    "\n",
    "print(\"Transit Paths:\")\n",
    "for path in transit_paths:\n",
    "    print(path)\n",
    "\n",
    "print(\"First-Hop Changes:\")\n",
    "for path in first_hop_changes:\n",
    "    print(path)\n",
    "\n",
    "print(\"Prepend Actions:\")\n",
    "for path in prepend_actions:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: BGP Path Changes\n",
    "Use PyBGPStream to access live data stream (project='ris-live') and review a series of BGP update messages that show alterations in the AS_PATH attribute for key routes managed by AS14061 on the prefix 198.205.102.0/24. For each identified AS_PATH alteration, the script should detail the change, including the previous and updated AS_PATH, the affected prefix, and the timestamp of the update. Do not use 'filter' parameter.\n",
    "\n",
    "\n",
    "Use PyBGPStream to access live data stream (project='ris-live') to monitor BGP update messages, specifically targeting routes managed by AS14061 with the prefix 198.205.102.0/24. The script should not use the 'filter' parameter. Instead, it should manually inspect each BGP update for the specified prefix and AS number. For every update that shows an alteration in the AS_PATH attribute for this prefix, record and output the details of the change. This includes the previous and updated AS_PATH, the affected prefix, and the timestamp of the update. Implement a way to track the last seen AS_PATH for the specified prefix so you can detect and detail any alterations in subsequent updates.\n",
    "\n",
    "* The code has a minor erro in as-path access: as-path or origin as???\n",
    "* Addition of the second message improved the quality\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Use PyBGPStream to access live data stream (project='ris-live') to monitor BGP update messages, specifically targeting routes managed by AS14061 with the prefix 198.205.102.0/24. The script should not use the 'filter' parameter. Instead, it should manually inspect each BGP update for the specified prefix and AS number. For every update that shows an alteration in the AS_PATH attribute for this prefix, record and output the details of the change. This includes the previous and updated AS_PATH, the affected prefix, and the timestamp of the update. Implement a way to track the last seen AS_PATH for the specified prefix so you can detect and detail any alterations in subsequent updates. [/INST]  Sure! Here's the script that uses PyBGPStream to monitor BGP update messages for the specified prefix and AS number:\n",
      "```\n",
      "import pybgpstream\n",
      "\n",
      "# Initialize the BGPStream\n",
      "stream = pybgpstream.BGPStream(\n",
      "    project=\"ris-live\",\n",
      "    record_type=\"updates\",\n",
      ")\n",
      "\n",
      "# Initialize the last seen AS_PATH\n",
      "last_seen_as_path = None\n",
      "\n",
      "# Loop through the stream records\n",
      "for rec in stream.records():\n",
      "    for elem in rec:\n",
      "        if elem.fields['prefix'] == '198.205.102.0/24' and elem.fields['as-path'].split()[-1] == '14061':\n",
      "            # Check if the AS_PATH has changed\n",
      "            if last_seen_as_path and elem.fields['as-path']!= last_seen_as_path:\n",
      "                # Output the details of the change\n",
      "                print(f\"AS_PATH change detected for prefix 198.205.102.0/24:\")\n",
      "                print(f\"  Previous AS_PATH: {last_seen_as_path}\")\n",
      "                print(f\"  New AS_PATH: {elem.fields['as-path']}\")\n",
      "                print(f\"  Timestamp: {elem.time}\")\n",
      "                # Update the last seen AS_PATH\n",
      "                last_seen_as_path = elem.fields['as-path']\n",
      "\n",
      "# If no changes were detected, print a message\n",
      "if not last_seen_as_path:\n",
      "    print(\"No changes detected for prefix 198.205.102.0/24.\")\n",
      "```\n",
      "This script uses the `pybgpstream` library to access the live stream of BGP records. It initializes the `BGPStream` object with the `project` parameter set to \"ris-live\" to indicate that it should use the RIS live stream. It then sets the `record_type` parameter to \"updates\" to indicate that it should only process BGP update records.\n",
      "\n",
      "The script then initializes the `last_seen_as_path` variable to None to indicate that no changes have been detected yet.\n",
      "\n",
      "The script then loops through the stream records and checks each record for the specified prefix and AS number. If the AS_PATH has changed, it outputs the details of the change, including the previous and updated AS_\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Use PyBGPStream to access live data stream (project='ris-live') to monitor BGP update messages, specifically targeting routes managed by AS14061 with the prefix 198.205.102.0/24. The script should not use the 'filter' parameter. Instead, it should manually inspect each BGP update for the specified prefix and AS number. For every update that shows an alteration in the AS_PATH attribute for this prefix, record and output the details of the change. This includes the previous and updated AS_PATH, the affected prefix, and the timestamp of the update. Implement a way to track the last seen AS_PATH for the specified prefix so you can detect and detail any alterations in subsequent updates.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=718)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "\n",
    "# Initialize the BGPStream\n",
    "stream = pybgpstream.BGPStream(\n",
    "    project=\"ris-live\",\n",
    "    record_type=\"updates\",\n",
    ")\n",
    "\n",
    "# Initialize the last seen AS_PATH\n",
    "last_seen_as_path = None\n",
    "\n",
    "# Loop through the stream records\n",
    "for rec in stream.records():\n",
    "    for elem in rec:\n",
    "        as_path = elem.fields.get('as-path', '').split()\n",
    "        prefix = elem.fields['prefix']\n",
    "        # print(elem)\n",
    "        if prefix == '67.211.53.0/24' and as_path == '6233':\n",
    "            print(elem)\n",
    "            # Check if the AS_PATH has changed\n",
    "            if last_seen_as_path and elem.fields['as-path']!= last_seen_as_path:\n",
    "                # Output the details of the change\n",
    "                print(f\"AS_PATH change detected for prefix 67.211.53.0/24:\")\n",
    "                print(f\"  Previous AS_PATH: {last_seen_as_path}\")\n",
    "                print(f\"  New AS_PATH: {elem.fields['as-path']}\")\n",
    "                print(f\"  Timestamp: {elem.time}\")\n",
    "                # Update the last seen AS_PATH\n",
    "                last_seen_as_path = elem.fields['as-path']\n",
    "\n",
    "# If no changes were detected, print a message\n",
    "if not last_seen_as_path:\n",
    "    print(\"No changes detected for prefix 67.211.53.0/24.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tast 3.2: Path Updates - Breakdown by Update Type\n",
    "Design a script that utilizes PyBGPStream to examine BGP path updates for AS44103 from 'rrc00' collector over the period 03-02-2024 13:00 to 14:59:59, categorizing the updates by type of change in the AS Path: changes in the origin AS, changes in the origin's next-hop AS, changes in the transit AS path, changes in the first-hop AS, and changes due to AS prepending. Do not include 'fileter in the parameter.\n",
    "\n",
    "Avoid using pronouns! - categorizing the updates, not them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Design a script that utilizes PyBGPStream to examine BGP path updates for AS44103 from 'rrc00' collector over the period 03-02-2024 13:00 to 14:59:59, categorizing the updates by type of change in the AS Path: changes in the origin AS, changes in the origin's next-hop AS, changes in the transit AS path, changes in the first-hop AS, and changes due to AS prepending. Do not include 'fileter in the parameter. [/INST]  Sure! Here's the script:\n",
      "\n",
      "import pybgpstream\n",
      "\n",
      "# Initialize BGPStream\n",
      "stream = pybgpstream.BGPStream(\n",
      "    from_time=\"2024-02-03 13:00:00\", until_time=\"2024-02-03 14:59:59\",\n",
      "    collectors=[\"rrc00\"],\n",
      "    record_type=\"updates\"\n",
      ")\n",
      "\n",
      "# Counter for each type of change\n",
      "origin_as_changes = 0\n",
      "origin_next_hop_changes = 0\n",
      "transit_as_path_changes = 0\n",
      "first_hop_changes = 0\n",
      "as_prepending_changes = 0\n",
      "\n",
      "# Loop through the stream records\n",
      "for rec in stream.records():\n",
      "    for elem in rec:\n",
      "        if elem.type == \"A\":\n",
      "            # Check if the update is for AS44103\n",
      "            if elem.fields[\"as-path\"].split()[-1] == \"44103\":\n",
      "                # Check the type of change\n",
      "                if elem.fields[\"as-path\"].split()[0]!= elem.fields[\"as-path\"].split()[-1]:\n",
      "                    origin_as_changes += 1\n",
      "                elif elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-2]:\n",
      "                    origin_next_hop_changes += 1\n",
      "                elif elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-2] and elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-3]:\n",
      "                    transit_as_path_changes += 1\n",
      "                elif elem.fields[\"as-path\"].split()[-1] == elem.fields[\"as-path\"].split()[-2] and elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-3]:\n",
      "                    first_hop_changes += 1\n",
      "                elif elem.fields[\"as-path\"].split()[-1] == elem.fields[\"as-path\"].split()[-2] and elem.fields[\"as-path\"].split()[-1] == elem.fields[\"as-path\"].split()[-3]:\n",
      "                    as_prepending_changes += 1\n",
      "\n",
      "# Print the results\n",
      "print(f\"Number of changes in the origin AS: {origin_as_changes}\")\n",
      "print(f\"Number of changes in the origin's next-hop AS: {origin_next_hop_changes}\")\n",
      "print(f\"Number of changes in the transit AS path: {transit_as_path_changes}\")\n",
      "print(f\"Number of changes in the first-hop AS: {first_hop_changes}\")\n",
      "print(f\"Number of changes due to AS prepending: {as_prepending_changes}\")\n",
      "\n",
      "# If there are no changes, print a message\n",
      "if origin_as_changes == 0 and origin_next_hop_changes == 0 and transit_as_path_changes == 0 and first_hop_changes == 0 and as_prepending_changes == 0:\n",
      "    print(\"No changes found.\")\n",
      "\n",
      "# If there are changes, print the details\n",
      "else:\n",
      "    print(\"Changes found:\")\n",
      "    print(f\"Origin AS changes: {origin_as_changes}\")\n",
      "    print(f\"Origin's next-hop AS changes: {origin_next_hop_changes}\")\n",
      "    print(f\"Transit AS path changes: {transit_as_path_changes}\")\n",
      "    print(f\"First-hop AS changes: {first_hop_changes}\")\n",
      "    print(f\"AS prepending changes: {as_prepending_changes}\")\n",
      "    print()\n",
      "    print(\"The changes are\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Design a script that utilizes PyBGPStream to examine BGP path updates for AS44103 from 'rrc00' collector over the period 03-02-2024 13:00 to 14:59:59, categorizing the updates by type of change in the AS Path: changes in the origin AS, changes in the origin's next-hop AS, changes in the transit AS path, changes in the first-hop AS, and changes due to AS prepending. Do not include 'fileter in the parameter.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of changes in the origin AS: 288\n",
      "Number of changes in the origin's next-hop AS: 0\n",
      "Number of changes in the transit AS path: 0\n",
      "Number of changes in the first-hop AS: 0\n",
      "Number of changes due to AS prepending: 0\n"
     ]
    }
   ],
   "source": [
    "import pybgpstream\n",
    "\n",
    "# Initialize BGPStream\n",
    "stream = pybgpstream.BGPStream(\n",
    "    from_time=\"2024-02-03 13:00:00\", until_time=\"2024-02-03 14:59:59\",\n",
    "    collectors=[\"rrc00\"],\n",
    "    record_type=\"updates\"\n",
    ")\n",
    "\n",
    "# Counter for each type of change\n",
    "origin_as_changes = 0\n",
    "origin_next_hop_changes = 0\n",
    "transit_as_path_changes = 0\n",
    "first_hop_changes = 0\n",
    "as_prepending_changes = 0\n",
    "\n",
    "# Loop through the stream records\n",
    "for rec in stream.records():\n",
    "    for elem in rec:\n",
    "        if elem.type == \"A\":\n",
    "            # Check if the update is for AS44103\n",
    "            if elem.fields[\"as-path\"].split()[-1] == \"44103\":\n",
    "                # Check the type of change\n",
    "                if elem.fields[\"as-path\"].split()[0]!= elem.fields[\"as-path\"].split()[-1]:\n",
    "                    origin_as_changes += 1\n",
    "                elif elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-2]:\n",
    "                    origin_next_hop_changes += 1\n",
    "                elif elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-2] and elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-3]:\n",
    "                    transit_as_path_changes += 1\n",
    "                elif elem.fields[\"as-path\"].split()[-1] == elem.fields[\"as-path\"].split()[-2] and elem.fields[\"as-path\"].split()[-1]!= elem.fields[\"as-path\"].split()[-3]:\n",
    "                    first_hop_changes += 1\n",
    "                elif elem.fields[\"as-path\"].split()[-1] == elem.fields[\"as-path\"].split()[-2] and elem.fields[\"as-path\"].split()[-1] == elem.fields[\"as-path\"].split()[-3]:\n",
    "                    as_prepending_changes += 1\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of changes in the origin AS: {origin_as_changes}\")\n",
    "print(f\"Number of changes in the origin's next-hop AS: {origin_next_hop_changes}\")\n",
    "print(f\"Number of changes in the transit AS path: {transit_as_path_changes}\")\n",
    "print(f\"Number of changes in the first-hop AS: {first_hop_changes}\")\n",
    "print(f\"Number of changes due to AS prepending: {as_prepending_changes}\")\n",
    "\n",
    "# If there are no changes, print a message\n",
    "if origin_as_changes == 0 and origin_next_hop_changes == 0 and transit_as_path_changes == 0 and first_hop_changes == 0 and as_prepending_changes == 0:\n",
    "    print(\"No changes found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: AS Announcement Trend Reporting\n",
    "\n",
    "Create a PyBGPStream script that generates reports on the time trend of the total span of address space advertised by AS7296. The script should collect data from BGP announcements from 'rrc00', calculate the span of address space from 02-03-2024 13:00 to 14:59:59, and aggregate this data into a time-series report. Do not add ASN to 'filter' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] script should collect data from BGP announcements from 'rrc00', calculate the span of address space from 02-03-2024 13:00 to 14:59:59, and aggregate this data into a time-series report. Do not add ASN in 'filter' parameter. [/INST]  Sure! Here's the script that collects BGP announcements from 'rrc00' and calculates the span of address space from 02-03-2024 13:00 to 14:59:59:\n",
      "```\n",
      "import pybgpstream\n",
      "\n",
      "# Initialize BGPStream\n",
      "stream = pybgpstream.BGPStream(\n",
      "    from_time=\"2024-03-02 13:00:00\",\n",
      "    until_time=\"2024-03-02 14:59:59\",\n",
      "    collectors=[\"rrc00\"],\n",
      "    record_type=\"updates\"\n",
      ")\n",
      "\n",
      "# Dictionary to store the time-series data\n",
      "time_series_data = {}\n",
      "\n",
      "# Process BGP records\n",
      "for rec in stream.records():\n",
      "    for elem in rec:\n",
      "        if elem.type == \"A\":  # Check for BGP announcements\n",
      "            prefix = elem.fields[\"prefix\"]\n",
      "            as_path = elem.fields[\"as-path\"].split()\n",
      "            origin_as = as_path[-1]\n",
      "            time = rec.time\n",
      "\n",
      "            # Check if the prefix is already in the dictionary\n",
      "            if prefix in time_series_data:\n",
      "                # If it is, add the new record to the list\n",
      "                time_series_data[prefix].append((time, origin_as))\n",
      "            else:\n",
      "                # If it's not, create a new list\n",
      "                time_series_data[prefix] = [(time, origin_as)]\n",
      "\n",
      "# Print the time-series report\n",
      "for prefix, data in time_series_data.items():\n",
      "    print(f\"Prefix: {prefix}\")\n",
      "    for time, origin_as in data:\n",
      "        print(f\"Time: {time}, Origin AS: {origin_as}\")\n",
      "```\n",
      "This script uses the `pybgpstream` library to collect BGP records from the 'rrc00' collector. It then processes the records and stores the data in a dictionary. Finally, it prints the time-series report for each prefix.\n",
      "\n",
      "Note that the script does not add the ASN in the 'filter' parameter because it is not necessary. The collector is already set to collect records from the 'rrc00' collector.\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Create a PyBGPStream script that generates reports on the time trend of the total span of address space advertised by AS7296. The script should collect data from BGP announcements from 'rrc00', calculate the span of address space from 02-03-2024 13:00 to 14:59:59, and aggregate this data into a time-series report. Do not add ASN in 'filter' parameter.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=718)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: 2606:6e00:8000::/35, Count: 9132\n",
      "Prefix: 2606:6e00:4000::/35, Count: 8468\n",
      "Prefix: 2606:6e00::/32, Count: 9784\n",
      "Prefix: 2606:6e00:c000::/35, Count: 3466\n",
      "Prefix: 23.26.72.0/24, Count: 1\n",
      "Prefix: 66.171.240.0/24, Count: 1\n",
      "Prefix: 66.171.241.0/24, Count: 1\n",
      "Prefix: 66.171.242.0/24, Count: 1\n",
      "Prefix: 66.171.243.0/24, Count: 1\n",
      "Prefix: 66.171.244.0/24, Count: 1\n",
      "Prefix: 66.171.245.0/24, Count: 1\n",
      "Prefix: 66.171.246.0/24, Count: 1\n",
      "Prefix: 66.171.247.0/24, Count: 1\n",
      "Prefix: 66.171.248.0/24, Count: 1\n",
      "Prefix: 66.171.249.0/24, Count: 1\n",
      "Prefix: 66.171.250.0/24, Count: 1\n",
      "Prefix: 66.171.251.0/24, Count: 1\n",
      "Prefix: 66.171.252.0/24, Count: 1\n",
      "Prefix: 66.171.253.0/24, Count: 1\n",
      "Prefix: 66.171.254.0/24, Count: 1\n",
      "Prefix: 66.171.255.0/24, Count: 1\n",
      "Prefix: 66.186.0.0/24, Count: 1\n",
      "Prefix: 66.186.1.0/24, Count: 1\n",
      "Prefix: 66.186.2.0/24, Count: 1\n",
      "Prefix: 66.186.3.0/24, Count: 1\n",
      "Prefix: 66.186.4.0/24, Count: 1\n",
      "Prefix: 66.186.5.0/24, Count: 1\n",
      "Prefix: 66.186.6.0/24, Count: 1\n",
      "Prefix: 66.186.7.0/24, Count: 1\n",
      "Prefix: 66.186.8.0/24, Count: 1\n",
      "Prefix: 66.186.9.0/24, Count: 1\n",
      "Prefix: 66.186.10.0/24, Count: 1\n",
      "Prefix: 66.186.11.0/24, Count: 1\n",
      "Prefix: 66.186.12.0/24, Count: 1\n",
      "Prefix: 66.186.13.0/24, Count: 1\n",
      "Prefix: 66.186.14.0/24, Count: 1\n",
      "Prefix: 66.186.15.0/24, Count: 1\n",
      "Prefix: 66.186.16.0/24, Count: 1\n",
      "Prefix: 66.186.17.0/24, Count: 1\n",
      "Prefix: 66.186.18.0/24, Count: 1\n",
      "Prefix: 66.186.20.0/24, Count: 1\n",
      "Prefix: 66.186.21.0/24, Count: 1\n",
      "Prefix: 66.186.22.0/24, Count: 1\n",
      "Prefix: 66.186.23.0/24, Count: 1\n",
      "Prefix: 66.186.24.0/24, Count: 1\n",
      "Prefix: 66.186.25.0/24, Count: 1\n",
      "Prefix: 66.186.26.0/24, Count: 1\n",
      "Prefix: 66.186.27.0/24, Count: 1\n",
      "Prefix: 66.186.28.0/24, Count: 1\n",
      "Prefix: 66.186.29.0/24, Count: 1\n",
      "Prefix: 66.186.30.0/24, Count: 1\n",
      "Prefix: 66.186.31.0/24, Count: 1\n",
      "Prefix: 66.226.0.0/24, Count: 1\n",
      "Prefix: 66.226.1.0/24, Count: 1\n",
      "Prefix: 66.226.2.0/24, Count: 1\n",
      "Prefix: 66.226.3.0/24, Count: 1\n",
      "Prefix: 66.226.4.0/24, Count: 1\n",
      "Prefix: 66.226.5.0/24, Count: 1\n",
      "Prefix: 66.226.6.0/24, Count: 1\n",
      "Prefix: 66.226.7.0/24, Count: 1\n",
      "Prefix: 66.226.8.0/24, Count: 1\n",
      "Prefix: 66.226.9.0/24, Count: 1\n",
      "Prefix: 66.226.10.0/24, Count: 1\n",
      "Prefix: 66.226.11.0/24, Count: 1\n",
      "Prefix: 66.226.12.0/24, Count: 1\n",
      "Prefix: 66.226.13.0/24, Count: 1\n",
      "Prefix: 66.226.14.0/24, Count: 1\n",
      "Prefix: 66.226.15.0/24, Count: 1\n",
      "Prefix: 66.226.16.0/24, Count: 1\n",
      "Prefix: 66.226.17.0/24, Count: 1\n",
      "Prefix: 66.226.18.0/24, Count: 1\n",
      "Prefix: 66.226.19.0/24, Count: 1\n",
      "Prefix: 66.226.20.0/24, Count: 1\n",
      "Prefix: 66.226.21.0/24, Count: 1\n",
      "Prefix: 66.226.22.0/24, Count: 1\n",
      "Prefix: 66.226.23.0/24, Count: 1\n",
      "Prefix: 66.226.24.0/24, Count: 1\n",
      "Prefix: 66.226.25.0/24, Count: 1\n",
      "Prefix: 66.226.26.0/24, Count: 1\n",
      "Prefix: 66.226.27.0/24, Count: 1\n",
      "Prefix: 66.226.28.0/24, Count: 1\n",
      "Prefix: 66.226.29.0/24, Count: 1\n",
      "Prefix: 66.226.30.0/24, Count: 1\n",
      "Prefix: 66.226.31.0/24, Count: 1\n",
      "Prefix: 72.26.96.0/24, Count: 1\n",
      "Prefix: 72.26.97.0/24, Count: 1\n",
      "Prefix: 72.26.98.0/24, Count: 1\n",
      "Prefix: 72.26.99.0/24, Count: 1\n",
      "Prefix: 72.26.100.0/24, Count: 1\n",
      "Prefix: 72.26.102.0/24, Count: 1\n",
      "Prefix: 72.26.103.0/24, Count: 1\n",
      "Prefix: 72.26.104.0/24, Count: 1\n",
      "Prefix: 72.26.105.0/24, Count: 1\n",
      "Prefix: 72.26.106.0/24, Count: 1\n",
      "Prefix: 72.26.107.0/24, Count: 1\n",
      "Prefix: 72.26.108.0/24, Count: 1\n",
      "Prefix: 72.26.109.0/24, Count: 1\n",
      "Prefix: 72.26.110.0/24, Count: 1\n",
      "Prefix: 72.26.111.0/24, Count: 1\n",
      "Prefix: 72.26.112.0/24, Count: 1\n",
      "Prefix: 72.26.113.0/24, Count: 1\n",
      "Prefix: 72.26.114.0/24, Count: 1\n",
      "Prefix: 72.26.115.0/24, Count: 1\n",
      "Prefix: 72.26.116.0/24, Count: 1\n",
      "Prefix: 72.26.117.0/24, Count: 1\n",
      "Prefix: 72.26.118.0/24, Count: 1\n",
      "Prefix: 72.26.119.0/24, Count: 1\n",
      "Prefix: 72.26.120.0/24, Count: 1\n",
      "Prefix: 72.26.121.0/24, Count: 1\n",
      "Prefix: 72.26.122.0/24, Count: 1\n",
      "Prefix: 72.26.123.0/24, Count: 1\n",
      "Prefix: 72.26.124.0/24, Count: 1\n",
      "Prefix: 72.26.125.0/24, Count: 1\n",
      "Prefix: 72.26.126.0/24, Count: 1\n",
      "Prefix: 72.26.127.0/24, Count: 1\n",
      "Prefix: 172.110.96.0/24, Count: 1\n",
      "Prefix: 172.110.97.0/24, Count: 1\n",
      "Prefix: 172.110.98.0/24, Count: 1\n",
      "Prefix: 172.110.99.0/24, Count: 1\n",
      "Prefix: 172.110.100.0/24, Count: 1\n",
      "Prefix: 172.110.101.0/24, Count: 1\n",
      "Prefix: 172.110.102.0/24, Count: 1\n",
      "Prefix: 172.110.103.0/24, Count: 1\n",
      "Prefix: 172.110.104.0/24, Count: 1\n",
      "Prefix: 172.110.105.0/24, Count: 1\n",
      "Prefix: 172.110.106.0/24, Count: 1\n",
      "Prefix: 172.110.107.0/24, Count: 1\n",
      "Prefix: 172.110.108.0/24, Count: 1\n",
      "Prefix: 172.110.109.0/24, Count: 1\n",
      "Prefix: 172.110.110.0/24, Count: 1\n",
      "Prefix: 172.110.111.0/24, Count: 1\n",
      "Prefix: 172.110.112.0/24, Count: 1\n",
      "Prefix: 172.110.113.0/24, Count: 1\n",
      "Prefix: 172.110.114.0/24, Count: 1\n",
      "Prefix: 172.110.115.0/24, Count: 1\n",
      "Prefix: 172.110.116.0/24, Count: 1\n",
      "Prefix: 172.110.117.0/24, Count: 1\n",
      "Prefix: 172.110.118.0/24, Count: 1\n",
      "Prefix: 172.110.119.0/24, Count: 1\n",
      "Prefix: 172.110.120.0/24, Count: 1\n",
      "Prefix: 172.110.121.0/24, Count: 1\n",
      "Prefix: 172.110.122.0/24, Count: 1\n",
      "Prefix: 172.110.123.0/24, Count: 1\n",
      "Prefix: 172.110.124.0/24, Count: 1\n",
      "Prefix: 172.110.125.0/24, Count: 1\n",
      "Prefix: 172.110.126.0/24, Count: 1\n",
      "Prefix: 172.110.127.0/24, Count: 1\n",
      "Prefix: 173.255.0.0/24, Count: 1\n",
      "Prefix: 173.255.1.0/24, Count: 1\n",
      "Prefix: 173.255.4.0/24, Count: 1\n",
      "Prefix: 173.255.5.0/24, Count: 1\n",
      "Prefix: 173.255.6.0/24, Count: 1\n",
      "Prefix: 173.255.7.0/24, Count: 1\n",
      "Prefix: 173.255.9.0/24, Count: 1\n",
      "Prefix: 173.255.10.0/24, Count: 1\n",
      "Prefix: 173.255.12.0/24, Count: 1\n",
      "Prefix: 173.255.13.0/24, Count: 1\n",
      "Prefix: 173.255.14.0/24, Count: 1\n",
      "Prefix: 173.255.15.0/24, Count: 1\n",
      "Prefix: 192.131.21.0/24, Count: 1\n",
      "Prefix: 192.152.10.0/24, Count: 1\n",
      "Prefix: 205.144.160.0/24, Count: 1\n",
      "Prefix: 205.144.161.0/24, Count: 1\n",
      "Prefix: 205.144.162.0/24, Count: 1\n",
      "Prefix: 205.144.163.0/24, Count: 1\n",
      "Prefix: 205.144.164.0/24, Count: 1\n",
      "Prefix: 205.144.165.0/24, Count: 1\n",
      "Prefix: 205.144.166.0/24, Count: 1\n",
      "Prefix: 205.144.167.0/24, Count: 1\n",
      "Prefix: 205.144.168.0/24, Count: 1\n",
      "Prefix: 205.144.169.0/24, Count: 1\n",
      "Prefix: 205.144.170.0/24, Count: 1\n",
      "Prefix: 205.144.172.0/24, Count: 1\n",
      "Prefix: 205.144.173.0/24, Count: 1\n",
      "Prefix: 205.144.174.0/24, Count: 1\n",
      "Prefix: 205.144.175.0/24, Count: 1\n",
      "Prefix: 206.221.208.0/24, Count: 1\n",
      "Prefix: 206.221.209.0/24, Count: 1\n",
      "Prefix: 206.221.210.0/24, Count: 1\n",
      "Prefix: 206.221.211.0/24, Count: 1\n",
      "Prefix: 206.221.212.0/24, Count: 1\n",
      "Prefix: 206.221.214.0/24, Count: 1\n",
      "Prefix: 206.221.216.0/24, Count: 1\n",
      "Prefix: 206.221.217.0/24, Count: 1\n",
      "Prefix: 206.221.218.0/24, Count: 1\n",
      "Prefix: 206.221.219.0/24, Count: 1\n",
      "Prefix: 206.221.220.0/24, Count: 1\n",
      "Prefix: 206.221.221.0/24, Count: 1\n",
      "Prefix: 206.221.222.0/24, Count: 1\n",
      "Prefix: 208.118.48.0/24, Count: 1\n",
      "Prefix: 208.118.49.0/24, Count: 1\n",
      "Prefix: 208.118.50.0/24, Count: 1\n",
      "Prefix: 208.118.51.0/24, Count: 1\n",
      "Prefix: 208.118.52.0/24, Count: 1\n",
      "Prefix: 208.118.53.0/24, Count: 1\n",
      "Prefix: 208.118.54.0/24, Count: 1\n",
      "Prefix: 208.118.55.0/24, Count: 1\n",
      "Prefix: 208.118.56.0/24, Count: 1\n",
      "Prefix: 208.118.57.0/24, Count: 1\n",
      "Prefix: 208.118.58.0/24, Count: 1\n",
      "Prefix: 208.118.59.0/24, Count: 1\n",
      "Prefix: 208.118.60.0/24, Count: 1\n",
      "Prefix: 208.118.61.0/24, Count: 1\n",
      "Prefix: 208.118.62.0/24, Count: 1\n",
      "Prefix: 209.132.192.0/24, Count: 1\n",
      "Prefix: 209.132.193.0/24, Count: 1\n",
      "Prefix: 209.132.194.0/24, Count: 1\n",
      "Prefix: 209.132.195.0/24, Count: 1\n",
      "Prefix: 209.132.196.0/24, Count: 1\n",
      "Prefix: 209.132.197.0/24, Count: 1\n",
      "Prefix: 209.132.198.0/24, Count: 1\n",
      "Prefix: 209.132.199.0/24, Count: 1\n",
      "Prefix: 209.132.200.0/24, Count: 1\n",
      "Prefix: 209.132.201.0/24, Count: 1\n",
      "Prefix: 209.132.202.0/24, Count: 1\n",
      "Prefix: 209.132.203.0/24, Count: 1\n",
      "Prefix: 209.132.204.0/24, Count: 1\n",
      "Prefix: 209.132.205.0/24, Count: 1\n",
      "Prefix: 209.132.206.0/24, Count: 1\n",
      "Prefix: 209.132.207.0/24, Count: 1\n",
      "Prefix: 209.132.208.0/24, Count: 1\n",
      "Prefix: 209.132.209.0/24, Count: 1\n",
      "Prefix: 209.132.210.0/24, Count: 1\n",
      "Prefix: 209.132.211.0/24, Count: 1\n",
      "Prefix: 209.132.212.0/24, Count: 1\n",
      "Prefix: 209.132.213.0/24, Count: 1\n",
      "Prefix: 209.132.214.0/24, Count: 1\n",
      "Prefix: 209.132.215.0/24, Count: 1\n",
      "Prefix: 209.132.216.0/24, Count: 1\n",
      "Prefix: 209.132.217.0/24, Count: 1\n",
      "Prefix: 209.132.218.0/24, Count: 1\n",
      "Prefix: 209.132.219.0/24, Count: 1\n",
      "Prefix: 209.132.220.0/24, Count: 1\n",
      "Prefix: 209.132.221.0/24, Count: 1\n",
      "Prefix: 209.132.222.0/24, Count: 1\n",
      "Prefix: 209.132.223.0/24, Count: 1\n",
      "Prefix: 209.132.224.0/24, Count: 1\n",
      "Prefix: 209.132.225.0/24, Count: 1\n",
      "Prefix: 209.132.226.0/24, Count: 1\n",
      "Prefix: 209.132.227.0/24, Count: 1\n",
      "Prefix: 209.132.228.0/24, Count: 1\n",
      "Prefix: 209.132.229.0/24, Count: 1\n",
      "Prefix: 209.132.230.0/24, Count: 1\n",
      "Prefix: 209.132.231.0/24, Count: 1\n",
      "Prefix: 209.132.232.0/24, Count: 1\n",
      "Prefix: 209.132.233.0/24, Count: 1\n",
      "Prefix: 209.132.234.0/24, Count: 1\n",
      "Prefix: 209.132.235.0/24, Count: 1\n",
      "Prefix: 209.132.236.0/24, Count: 1\n",
      "Prefix: 209.132.237.0/24, Count: 1\n",
      "Prefix: 209.132.238.0/24, Count: 1\n",
      "Prefix: 209.132.239.0/24, Count: 1\n",
      "Prefix: 209.132.240.0/24, Count: 1\n",
      "Prefix: 209.132.241.0/24, Count: 1\n",
      "Prefix: 209.132.242.0/24, Count: 1\n",
      "Prefix: 209.132.243.0/24, Count: 1\n",
      "Prefix: 209.132.244.0/24, Count: 1\n",
      "Prefix: 209.132.245.0/24, Count: 1\n",
      "Prefix: 209.132.246.0/24, Count: 1\n",
      "Prefix: 209.132.247.0/24, Count: 1\n",
      "Prefix: 209.132.248.0/24, Count: 1\n",
      "Prefix: 209.132.249.0/24, Count: 1\n",
      "Prefix: 209.132.250.0/24, Count: 1\n",
      "Prefix: 209.132.251.0/24, Count: 1\n",
      "Prefix: 209.132.253.0/24, Count: 1\n",
      "Prefix: 209.132.254.0/24, Count: 1\n",
      "Prefix: 209.132.255.0/24, Count: 1\n"
     ]
    }
   ],
   "source": [
    "import pybgpstream\n",
    "\n",
    "# Initialize BGPStream\n",
    "stream = pybgpstream.BGPStream(\n",
    "    from_time=\"2024-02-02 13:00:00\", until_time=\"2024-02-02 13:59:59\",\n",
    "    collectors=[\"rrc00\"],\n",
    "    record_type=\"updates\",\n",
    ")\n",
    "\n",
    "# Initialize a dictionary to store the time-series data\n",
    "time_series_data = {}\n",
    "\n",
    "# Loop through the stream records\n",
    "for rec in stream.records():\n",
    "    for elem in rec:\n",
    "        # print(elem)\n",
    "        if elem.type == \"A\":\n",
    "            prefix = elem.fields[\"prefix\"]\n",
    "            as_path = elem.fields[\"as-path\"].split()\n",
    "            origin_as = as_path[-1]\n",
    "            if origin_as == \"7296\":\n",
    "                if prefix not in time_series_data:\n",
    "                    time_series_data[prefix] = 0\n",
    "                time_series_data[prefix] += 1\n",
    "\n",
    "# Generate the time-series report\n",
    "for prefix, count in time_series_data.items():\n",
    "    print(f\"Prefix: {prefix}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: BGP Update Reports \n",
    "Write a PyBGPStream script that analyzes BGP updates for AS59919 during the period from 03-02-2024 13:00 to 13:59:59, focusing specifically on IPv4 updates from collectors 'rrc00' and 'rrc01'. The script needs to report the total number of changes in the Forwarding Information Base (FIB). Break down the changes into three main categories: announcements, withdrawals, and path changes as well as classifying them by their IPv4 prefix lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Write a PyBGPStream script that analyzes BGP updates for AS59919 during the period from 03-02-2024 13:00 to 13:59:59, focusing specifically on IPv4 updates from collectors 'rrc00' and 'rrc01'. The script needs to report the total number of changes in the Forwarding Information Base (FIB). Break down the changes into three main categories: announcements, withdrawals, and path changes as well as classifying them by their IPv4 prefix lengths. [/INST]  Sure! Here's the PyBGPStream script that analyzes BGP updates for AS59919 during the specified period:\n",
      "```\n",
      "import pybgpstream\n",
      "\n",
      "# Initialize the BGPStream\n",
      "stream = pybgpstream.BGPStream(\n",
      "    from_time=\"2024-02-03 13:00:00\",\n",
      "    until_time=\"2024-02-03 13:59:59\",\n",
      "    collectors=[\"rrc00\", \"rrc01\"],\n",
      "    record_type=\"updates\"\n",
      ")\n",
      "\n",
      "# Initialize a dictionary to store the results\n",
      "results = {}\n",
      "\n",
      "# Process BGP records\n",
      "for rec in stream.records():\n",
      "    for elem in rec:\n",
      "        if elem.type == \"A\":  # BGP announcements\n",
      "            prefix = elem.fields[\"prefix\"]\n",
      "            as_path = elem.fields[\"as-path\"].split()\n",
      "            origin_as = as_path[-1]\n",
      "            if origin_as == \"59919\":\n",
      "                if prefix in results:\n",
      "                    results[prefix][\"announcements\"] += 1\n",
      "                else:\n",
      "                    results[prefix] = {\n",
      "                        \"announcements\": 1,\n",
      "                        \"withdrawals\": 0,\n",
      "                        \"path_changes\": 0\n",
      "                    }\n",
      "        elif elem.type == \"W\":  # BGP withdrawals\n",
      "            prefix = elem.fields[\"prefix\"]\n",
      "            if prefix in results:\n",
      "                results[prefix][\"withdrawals\"] += 1\n",
      "        elif elem.type == \"R\":  # BGP path changes\n",
      "            prefix = elem.fields[\"prefix\"]\n",
      "            if prefix in results:\n",
      "                results[prefix][\"path_changes\"] += 1\n",
      "\n",
      "# Analyze the results\n",
      "for prefix, data in results.items():\n",
      "    print(f\"Prefix: {prefix}\")\n",
      "    print(f\"  Announcements: {data['announcements']}\")\n",
      "    print(f\"  Withdrawals: {data['withdrawals']}\")\n",
      "    print(f\"  Path Changes: {data['path_changes']}\")\n",
      "    print()\n",
      "\n",
      "# Summarize the results\n",
      "total_changes = 0\n",
      "for prefix, data in results.items():\n",
      "    total_changes += data[\"announcements\"] + data[\"withdrawals\"] + data[\"path_changes\"]\n",
      "\n",
      "print(f\"Total number of changes in the Forwarding Information Base (FIB): {total_changes}\")\n",
      "\n",
      "# Break down the changes into three main categories\n",
      "announcements = 0\n",
      "withdrawals = 0\n",
      "path_changes = 0\n",
      "for prefix, data in results.items():\n",
      "    announcements += data[\"announcements\"]\n",
      "    withdrawals += data[\"withdrawals\"]\n",
      "    path_changes += data[\"path_changes\"]\n",
      "\n",
      "print(f\"Announcements: {announcements}\")\n",
      "print(f\"Withdrawals: {withdrawals}\")\n",
      "print(f\"Path Changes: {path_changes}\")\n",
      "\n",
      "# Classify the changes by their IPv4 prefix lengths\n",
      "for prefix, data in results.items():\n",
      "    if len(prefix.split(\"/\")) == 1:\n",
      "        print(f\"IPv4 Prefix Length: /32\")\n",
      "    elif len(prefix.split(\"/\")) == 2:\n",
      "        print(f\"IPv4 Prefix Length: /24\")\n",
      "    else:\n",
      "        print(f\"IPv4 Prefix Length: /16 or longer\")\n",
      "```\n",
      "This script uses the `pybgpstream` library to collect BGP records from the specified collectors. It then processes the records and stores the results in a dictionary. Finally, it analyzes the results and summarizes the total number of changes in the Forwarding Information Base (FIB). It also breaks down\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Write a PyBGPStream script that analyzes BGP updates for AS59919 during the period from 03-02-2024 13:00 to 13:59:59, focusing specifically on IPv4 updates from collectors 'rrc00' and 'rrc01'. The script needs to report the total number of changes in the Forwarding Information Base (FIB). Break down the changes into three main categories: announcements, withdrawals, and path changes as well as classifying them by their IPv4 prefix lengths.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: 5.178.88.0/21\n",
      "  Announcements: 3\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 185.248.240.0/22\n",
      "  Announcements: 4\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 45.152.144.0/22\n",
      "  Announcements: 4\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 2a01:9ac0::/32\n",
      "  Announcements: 4\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 185.204.220.0/22\n",
      "  Announcements: 2\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 185.136.136.0/22\n",
      "  Announcements: 2\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 185.187.172.0/22\n",
      "  Announcements: 2\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 2.59.140.0/22\n",
      "  Announcements: 2\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Prefix: 185.60.188.0/22\n",
      "  Announcements: 2\n",
      "  Withdrawals: 0\n",
      "  Path Changes: 0\n",
      "\n",
      "Total number of changes in the Forwarding Information Base (FIB): 25\n",
      "Announcements: 25\n",
      "Withdrawals: 0\n",
      "Path Changes: 0\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n",
      "IPv4 Prefix Length: /24\n"
     ]
    }
   ],
   "source": [
    "import pybgpstream\n",
    "\n",
    "# Initialize the BGPStream\n",
    "stream = pybgpstream.BGPStream(\n",
    "    from_time=\"2024-02-03 13:00:00\",\n",
    "    until_time=\"2024-02-03 13:59:59\",\n",
    "    collectors=[\"rrc00\", \"rrc01\"],\n",
    "    record_type=\"updates\"\n",
    ")\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Process BGP records\n",
    "for rec in stream.records():\n",
    "    for elem in rec:\n",
    "        if elem.type == \"A\":  # BGP announcements\n",
    "            prefix = elem.fields[\"prefix\"]\n",
    "            as_path = elem.fields[\"as-path\"].split()\n",
    "            origin_as = as_path[-1]\n",
    "            if origin_as == \"59919\":\n",
    "                if prefix in results:\n",
    "                    results[prefix][\"announcements\"] += 1\n",
    "                else:\n",
    "                    results[prefix] = {\n",
    "                        \"announcements\": 1,\n",
    "                        \"withdrawals\": 0,\n",
    "                        \"path_changes\": 0\n",
    "                    }\n",
    "        elif elem.type == \"W\":  # BGP withdrawals\n",
    "            prefix = elem.fields[\"prefix\"]\n",
    "            if prefix in results:\n",
    "                results[prefix][\"withdrawals\"] += 1\n",
    "        elif elem.type == \"R\":  # BGP path changes\n",
    "            prefix = elem.fields[\"prefix\"]\n",
    "            if prefix in results:\n",
    "                results[prefix][\"path_changes\"] += 1\n",
    "\n",
    "# Analyze the results\n",
    "for prefix, data in results.items():\n",
    "    print(f\"Prefix: {prefix}\")\n",
    "    print(f\"  Announcements: {data['announcements']}\")\n",
    "    print(f\"  Withdrawals: {data['withdrawals']}\")\n",
    "    print(f\"  Path Changes: {data['path_changes']}\")\n",
    "    print()\n",
    "\n",
    "# Summarize the results\n",
    "total_changes = 0\n",
    "for prefix, data in results.items():\n",
    "    total_changes += data[\"announcements\"] + data[\"withdrawals\"] + data[\"path_changes\"]\n",
    "\n",
    "print(f\"Total number of changes in the Forwarding Information Base (FIB): {total_changes}\")\n",
    "\n",
    "# Break down the changes into three main categories\n",
    "announcements = 0\n",
    "withdrawals = 0\n",
    "path_changes = 0\n",
    "for prefix, data in results.items():\n",
    "    announcements += data[\"announcements\"]\n",
    "    withdrawals += data[\"withdrawals\"]\n",
    "    path_changes += data[\"path_changes\"]\n",
    "\n",
    "print(f\"Announcements: {announcements}\")\n",
    "print(f\"Withdrawals: {withdrawals}\")\n",
    "print(f\"Path Changes: {path_changes}\")\n",
    "\n",
    "# Classify the changes by their IPv4 prefix lengths\n",
    "for prefix, data in results.items():\n",
    "    if len(prefix.split(\"/\")) == 1:\n",
    "        print(f\"IPv4 Prefix Length: /32\")\n",
    "    elif len(prefix.split(\"/\")) == 2:\n",
    "        print(f\"IPv4 Prefix Length: /24\")\n",
    "    else:\n",
    "        print(f\"IPv4 Prefix Length: /16 or longer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "Use PyBGPStream to access ris-live and monitor BGP announcements, focusing on the five most advertised prefixes for AS7262. The script should collect data in five-minute intervals. After gathering the data, create a bar graph to visualize the frequency of announcements for each of these top prefixes. \n",
    "\n",
    "Write a Python script using PyBGPStream to access the 'ris-live' project and monitor BGP announcements for AS7262, specifically aiming to identify the five most advertised prefixes. The script should collect data over a specified period, tracking both announcements and withdrawals in real-time. Utilize pandas DataFrames to organize the collected data, categorizing records by time, prefix, and count. After the data collection phase - 72000 seconds, aggregate the data to highlight the most frequently announced prefixes. Finally, use matplotlib to create bar graphs visualizing the frequency of announcements and withdrawals for these top prefixes. Do not include from_time and until_time parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Develop a Python script leveraging PyBGPStream to tap into the 'ris-live' data stream, focusing on analyzing BGP announcements for AS7262. The objective is to pinpoint the five most frequently advertised prefixes. Instead of configuring the time duration directly in PyBGPStream parameters, implement the timing mechanism within the script to manage a data collection window of 72000 seconds. Use pandas DataFrames to systematically record and categorize each BGP update by timestamp, prefix, and type (announcement or withdrawal). Post-collection, process this data to ascertain and rank the top advertised prefixes. Conclude with generating bar graphs via matplotlib, showcasing the advertisement and withdrawal frequencies of these prefixes, thus providing a visual summary of the BGP activity for AS7262 over the specified period. [/INST]  Sure! Here's the Python script leveraging PyBGPStream to analyze BGP announcements for AS7262 over a 72000-second window:\n",
      "```\n",
      "import pybgpstream\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Initialize PyBGPStream\n",
      "stream = pybgpstream.BGPStream(\n",
      "    from_time=\"2021-01-01 00:00:00\", until_time=\"2021-01-01 00:00:72000\",\n",
      "    project=\"ris\",\n",
      "    collectors=\"rrc00\",\n",
      "    record_type=\"updates\",\n",
      "    filter=\"peer 7262\"\n",
      ")\n",
      "\n",
      "# Create a DataFrame to store the BGP updates\n",
      "df = pd.DataFrame(columns=['timestamp', 'prefix', 'type'])\n",
      "\n",
      "# Loop through the stream records\n",
      "for rec in stream.records():\n",
      "    for elem in rec:\n",
      "        if elem.type == \"A\":\n",
      "            df = df.append({'timestamp': rec.time, 'prefix': elem.fields['prefix'], 'type': 'announcement'}, ignore_index=True)\n",
      "        elif elem.type == \"W\":\n",
      "            df = df.append({'timestamp': rec.time, 'prefix': elem.fields['prefix'], 'type': 'withdrawal'}, ignore_index=True)\n",
      "\n",
      "# Group the DataFrame by prefix and type\n",
      "df_grouped = df.groupby(['prefix', 'type']).size().reset_index(name='counts')\n",
      "\n",
      "# Sort the DataFrame by counts in descending order\n",
      "df_grouped.sort_values(by='counts', inplace=True, ascending=False)\n",
      "\n",
      "# Generate bar graphs for each prefix\n",
      "for prefix, type in df_grouped.groupby('prefix'):\n",
      "    plt.bar(prefix, type, align='center')\n",
      "    plt.xlabel(f\"Prefixes Announced/Withdrawn by AS7262\")\n",
      "    plt.ylabel(f\"Number of Updates ({type})\")\n",
      "    plt.title(f\"Top 5 Most Frequently Advertised Prefixes for AS7262\")\n",
      "    plt.show()\n",
      "```\n",
      "The script first initializes PyBGPStream with the specified parameters. Then, it creates a DataFrame to store the BGP updates. The script then loops through the stream records and appends the updates to the DataFrame.\n",
      "\n",
      "Next, the script groups the DataFrame by prefix and type, and sorts the DataFrame by counts in descending order. Finally, the script generates bar graphs for each prefix using matplotlib.\n",
      "\n",
      "The output of the script is a set of bar graphs showing the advertisement and withdrawal frequencies of the top five most frequently advertised prefixes for AS7262 over the specified period. The bar graphs provide a visual summary of the BGP activity for AS7262, allowing for easy identification of the most frequently advertised prefixes.\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Develop a Python script leveraging PyBGPStream to tap into the 'ris-live' data stream, focusing on analyzing BGP announcements for AS7262. The objective is to pinpoint the five most frequently advertised prefixes. Instead of configuring the time duration directly in PyBGPStream parameters, implement the timing mechanism within the script to manage a data collection window of 72000 seconds. Use pandas DataFrames to systematically record and categorize each BGP update by timestamp, prefix, and type (announcement or withdrawal). Post-collection, process this data to ascertain and rank the top advertised prefixes. Conclude with generating bar graphs via matplotlib, showcasing the advertisement and withdrawal frequencies of these prefixes, thus providing a visual summary of the BGP activity for AS7262 over the specified period. Do not include from_time and until_time parameters.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize PyBGPStream\n",
    "stream = pybgpstream.BGPStream(\n",
    "    # from_time=\"2021-01-01 00:00:00\", until_time=\"2021-01-01 00:00:72000\",\n",
    "    project=\"ris\",\n",
    "    collectors=\"rrc00\",\n",
    "    record_type=\"updates\",\n",
    "    filter=\"peer 7262\"\n",
    ")\n",
    "\n",
    "# Create a DataFrame to store the BGP updates\n",
    "df = pd.DataFrame(columns=['timestamp', 'prefix', 'type'])\n",
    "\n",
    "# Loop through the stream records\n",
    "for rec in stream.records():\n",
    "    for elem in rec:\n",
    "        if elem.type == \"A\":\n",
    "            df = df.append({'timestamp': rec.time, 'prefix': elem.fields['prefix'], 'type': 'announcement'}, ignore_index=True)\n",
    "        elif elem.type == \"W\":\n",
    "            df = df.append({'timestamp': rec.time, 'prefix': elem.fields['prefix'], 'type': 'withdrawal'}, ignore_index=True)\n",
    "\n",
    "# Group the DataFrame by prefix and type\n",
    "df_grouped = df.groupby(['prefix', 'type']).size().reset_index(name='counts')\n",
    "\n",
    "# Sort the DataFrame by counts in descending order\n",
    "df_grouped.sort_values(by='counts', inplace=True, ascending=False)\n",
    "\n",
    "# Generate bar graphs for each prefix\n",
    "for prefix, type in df_grouped.groupby('prefix'):\n",
    "    plt.bar(prefix, type, align='center')\n",
    "    plt.xlabel(f\"Prefixes Announced/Withdrawn by AS7262\")\n",
    "    plt.ylabel(f\"Number of Updates ({type})\")\n",
    "    plt.title(f\"Top 5 Most Frequently Advertised Prefixes for AS7262\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Prefix announcements report 60 sec\n",
    "Create a Python script using PyBGPStream and pandas to track and visualize BGP announcements for AS7262 from 'ris-live' every 60 seconds. The script should collect updates, segregate announcements and withdrawals into DataFrames, and aggregate this data to identify the top advertised prefixes. At the end of each interval, use matplotlib to generate bar graphs showing the frequency of updates per prefix. Implement threading to automate the collection and visualization process in 60-second cycles for a predetermined duration. Ensure DataFrames are cleared after each plotting to accurately reflect new data in subsequent intervals.\n",
    "\n",
    "\n",
    "Construct a Python script with PyBGPStream and pandas to monitor BGP announcements for AS7262, aiming to identify the top advertised prefixes. The script should initiate a BGPStream instance focused on 'ris-live' updates. Rather than setting a static time frame within PyBGPStream's parameters, employ a dynamic approach to manage data collection over a duration, such as 72000 seconds, directly in your code logic. Accumulate update data in a pandas DataFrame, tracking each prefix occurrence. After collecting data, aggregate and sort this information to determine the most frequently announced prefixes. Utilize matplotlib to periodically generate and display bar graphs, visualizing the count of announcements per prefix. Implement threading to facilitate continuous data collection and visualization in 60-second intervals, refreshing the DataFrame after each cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`With visualization`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\"Write a Python script utilizing PyBGPStream and pandas to dynamically monitor and analyze BGP updates for AS7262, capturing both announcements and withdrawals. The script should operate within an infinite loop, continuously fetching data from the 'ris-live' project stream without pre-set time filters. Initialize a pandas DataFrame to log each relevant update's prefix and a count placeholder. Implement a threading mechanism to periodically collect this data in real time. Within the data collection function, filter updates by checking for AS7262 in the AS path of each update message. After collecting the data, clear the DataFrame for the next data collection cycle to avoid duplication. Additionally, set up a separate function to visualize the aggregated data using matplotlib, creating bar graphs to display the frequency of announcements for the top advertised prefixes by AS7262. This visualization should occur at regular intervals, every 60 seconds, to provide an ongoing analysis. Ensure the visualization function is called outside the data collection thread to maintain continuous monitoring and reporting. Include safety checks to terminate the script gracefully if the data collection thread stops running.\"\n",
    "\n",
    "Develop a Python script leveraging PyBGPStream and pandas to monitor BGP updates from AS7262 in real time, focusing on capturing both announcements and withdrawals. Start by setting up a BGPStream instance for the 'ris-live' project, ensuring real-time updates are fetched without time constraints. Initialize two pandas DataFrames for logging prefix announcements and withdrawals, each with 'Time', 'Prefix', and 'Count' columns. Create a function to process BGP data, filtering for updates related to AS7262 by checking the AS path, and update the DataFrames accordingly. This function should collect data, then visualize the frequency of announcements and withdrawals for top prefixes, and it should reset the DataFrames after each visualization to avoid data duplication. Utilize threading to allow this function to run in a loop, ensuring continuous data monitoring and visualization every 60 seconds over a predefined total period of 180 seconds. Include necessary checks to gracefully exit if the data collection thread stops, ensuring the script maintains continuous, updated analysis of BGP activity for AS7262.\n",
    "\n",
    "\n",
    "Create a Python script using PyBGPStream and pandas to dynamically monitor BGP updates from AS7262, capturing both announcements and withdrawals in real time. Begin by setting up a BGPStream instance targeting the 'ris-live' project to fetch updates continuously, without imposing time constraints. Then, initialize two pandas DataFrames named announcements and withdrawals, each with columns for 'Time', 'Prefix', and 'Count', to log the events. Write a process_bgp_data function that iterates through BGP records, filtering for AS7262 by checking the AS path in each update message. Update the respective DataFrame with each announcement or withdrawal, appending new data with the current time, prefix, and incrementing the count for occurrences. After data collection, call a visualize_data function to display the aggregated data using matplotlib bar graphs, showing the frequency of events for top prefixes. Use threading to run process_bgp_data in a continuous loop, allowing for data collection and visualization every 60 seconds over a predefined total duration of 180 seconds. Ensure the script includes checks to gracefully exit if the data collection thread stops and to reset the DataFrames after each visualization cycle to avoid data duplication, maintaining an updated analysis of BGP activity for AS7262. This structured approach ensures the script provides continuous monitoring and timely insights into BGP updates related to AS7262.\n",
    "\n",
    "\n",
    "\n",
    "Develop a Python script that utilizes PyBGPStream and pandas to continuously monitor BGP updates for AS7262, focusing on both announcements and withdrawals. The script will set up a BGPStream instance to fetch updates from the 'ris-live' project without specifying 'from_time' and 'until_time', enabling real-time data capture. Two pandas DataFrames, announcements and withdrawals, will be initialized with columns for 'Time', 'Prefix', and 'Count' to log respective events. Create a function, process_bgp_data, to iterate over the BGP records fetched by PyBGPStream. This function should filter updates by examining the AS path within each message, checking for the presence of AS7262. For relevant updates, increment the count of occurrences in the respective DataFrame and annotate the event with the current time and involved prefix. To ensure continuous monitoring and analysis, employ threading to run process_bgp_data in an infinite loop, executing every 60 seconds. In parallel, set up a visualization function, visualize_data, which aggregates data from the DataFrames to calculate the total count of announcements and withdrawals per prefix. Use matplotlib to generate bar graphs displaying these frequencies, updating the visualization in a separate loop also running every 60 seconds. Incorporate logic to reset the DataFrames after each visualization cycle to prevent data duplication and ensure the script provides up-to-date analysis. Finally, include checks to gracefully handle the termination of the data collection thread, ensuring the script exits cleanly if data collection is interrupted or continues seamlessly otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Develop a Python script that utilizes PyBGPStream and pandas to continuously monitor BGP updates for AS7262, focusing on both announcements and withdrawals. The script will set up a BGPStream instance to fetch updates from the 'ris-live' project without specifying 'from_time' and 'until_time', enabling real-time data capture. Two pandas DataFrames, announcements and withdrawals, will be initialized with columns for 'Time', 'Prefix', and 'Count' to log respective events. Create a function, process_bgp_data, to iterate over the BGP records fetched by PyBGPStream. This function should filter updates by examining the AS path within each message, checking for the presence of AS7262. For relevant updates, increment the count of occurrences in the respective DataFrame and annotate the event with the current time and involved prefix. To ensure continuous monitoring and analysis, employ threading to run process_bgp_data in an infinite loop, executing every 60 seconds. In parallel, set up a visualization function, visualize_data, which aggregates data from the DataFrames to calculate the total count of announcements and withdrawals per prefix. Use matplotlib to generate bar graphs displaying these frequencies, updating the visualization in a separate loop also running every 60 seconds. Incorporate logic to reset the DataFrames after each visualization cycle to prevent data duplication and ensure the script provides up-to-date analysis. Finally, include checks to gracefully handle the termination of the data collection thread, ensuring the script exits cleanly if data collection is interrupted or continues seamlessly otherwise.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1500)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize BGPStream instance\n",
    "stream = pybgpstream.BGPStream(\n",
    "    project=\"ris-live\",\n",
    "    record_type=\"updates\",\n",
    ")\n",
    "\n",
    "# Initialize DataFrames for announcements and withdrawals\n",
    "announcements = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "withdrawals = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "\n",
    "# Define function to process BGP data\n",
    "def process_bgp_data():\n",
    "    global announcements, withdrawals\n",
    "    while True:\n",
    "        # Fetch BGP records\n",
    "        for rec in stream.records():\n",
    "            for elem in rec: # mannually added\n",
    "                # Filter records with AS7262 in the AS path\n",
    "                as_path = elem.fields.get('as-path', '').split() # mannually added\n",
    "                if '24482' in as_path:\n",
    "                    print(\"\\n 24482 as path found... \\n\")\n",
    "                    # Correctly format the time string using the record's timestamp\n",
    "                    time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(rec.time))\n",
    "                    prefix = elem.fields['prefix']\n",
    "                    print(f\"\\n 24482 prefix: {prefix}; type: {elem.type} \\n\")\n",
    "                    # Determine the correct DataFrame based on the type of update\n",
    "                    df = announcements if elem.type == 'A' else withdrawals\n",
    "                    # Check if a row exists for this time and prefix\n",
    "                    row_index = df[(df['Time'] == time_str) & (df['Prefix'] == prefix)].index\n",
    "                    if row_index.empty:\n",
    "                        df.loc[len(df)] = [time_str, prefix, 1]\n",
    "                    else:\n",
    "                        df.loc[row_index, 'Count'] += 1\n",
    "                    print(announcements)\n",
    "\n",
    "        # Visualize data\n",
    "        visualize_data()\n",
    "        # Sleep for 60 seconds\n",
    "        time.sleep(60)\n",
    "\n",
    "\n",
    "def visualize_data():\n",
    "    # Ensure global DataFrames are accessible\n",
    "    global announcements, withdrawals\n",
    "    \n",
    "    # Aggregate counts by prefix for announcements and withdrawals\n",
    "    agg_announcements = announcements.groupby('Prefix')['Count'].sum().reset_index()\n",
    "    agg_withdrawals = withdrawals.groupby('Prefix')['Count'].sum().reset_index()\n",
    "\n",
    "    # Sort and get the top 5 prefixes for announcements and withdrawals\n",
    "    top_announcements = agg_announcements.sort_values(by='Count', ascending=False).head(5)\n",
    "    top_withdrawals = agg_withdrawals.sort_values(by='Count', ascending=False).head(5)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot the top 5 announcements\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "    plt.bar(top_announcements['Prefix'], top_announcements['Count'], color='blue')\n",
    "    plt.title('Top 5 Announced Prefixes')\n",
    "    plt.xlabel('Prefix')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Plot the top 5 withdrawals\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "    plt.bar(top_withdrawals['Prefix'], top_withdrawals['Count'], color='red')\n",
    "    plt.title('Top 5 Withdrawn Prefixes')\n",
    "    plt.xlabel('Prefix')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Reset DataFrames for the next iteration to ensure freshness of data\n",
    "    announcements = announcements.iloc[0:0]\n",
    "    withdrawals = withdrawals.iloc[0:0]\n",
    "\n",
    "# Start data collection thread\n",
    "thread = threading.Thread(target=process_bgp_data)\n",
    "thread.start()\n",
    "\n",
    "while True:\n",
    "    # Visualize data\n",
    "    visualize_data()\n",
    "    # Sleep for 60 seconds\n",
    "    time.sleep(60)\n",
    "\n",
    "# Gracefully handle termination\n",
    "if thread.is_alive():\n",
    "    thread.terminate()\n",
    "    print(\"Data collection thread terminated.\")\n",
    "else:\n",
    "    print(\"Data collection thread already terminated.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`no visual`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Best  \n",
    "Create a Python script that leverages the PyBGPStream library for real-time monitoring of BGP updates, focusing specifically on the announcements and withdrawals related to a particular Autonomous System (AS), here marked as '24482'. Initialize the script by setting up a BGPStream instance configured to fetch updates from the 'ris-live' project. Prepare two pandas DataFrames, one each for tracking announcements and withdrawals, with columns for the time of the update, the prefix involved, and a count of occurrences. Design a function called process_bgp_data that operates continuously for a predetermined duration, here 180 seconds, to collect BGP updates. Within this function, filter the updates to identify those related to the AS of interest and update the respective DataFrame by either adding a new row for each unique prefix occurrence or incrementing the count for existing entries. Implement a mechanism to print out the top 5 prefixes by count from each DataFrame every 60 seconds, showcasing the most frequent announcements and withdrawals during that period before resetting the DataFrames for the next cycle of data collection. Initiate this data collection process in a separate thread to allow for concurrent execution without blocking other operations. Ensure that the entire script is designed to provide insights into the most active prefixes related to the specified AS within the live BGP feed, offering valuable information on BGP dynamics over a short, specified timeframe.\n",
    "\n",
    "1.1 filter and get AS path method:\n",
    "\n",
    "\n",
    "2. Fail. Confusing prompt for LLM.\n",
    "Develop a Python script using PyBGPStream to monitor BGP updates in real time, with a focus on a specific AS '24482'. Begin by initializing a BGPStream instance to collect updates from the 'ris-live' project. Do not use from_time and until_time in PyBGPStream parameters. Set up two pandas DataFrames for recording BGP announcements and withdrawals. Each DataFrame should include columns to record the time of the update, the involved prefix, and a count of how often each prefix occurs. Create a function named process_bgp_data, designed to run for a set duration of 180 seconds by implementing a mechanism using time.time() to capture the start timestamp and gather BGP update data continuously throughout this period. In this function, use as_path = elem.fields.get('as-path', '').split() to filter updates related to the AS of interest. Instead of appending new rows to the DataFrame directly, identify existing entries by filtering on both the time and prefix. If an entry exists, increment its count; if not, use the DataFrame's .loc method to add a new row, avoiding the use of the append method. Every 60 seconds, the script should print the top 5 prefixes by count for both announcements and withdrawals. After printing, reset the DataFrames to ensure fresh data for the next collection cycle. Launch process_bgp_data function in a separate thread, enabling it to run alongside other operations without interference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Create a Python script that leverages the PyBGPStream library for real-time monitoring of BGP updates, focusing specifically on the announcements and withdrawals related to a particular Autonomous System (AS), here marked as '24482'. Initialize the script by setting up a BGPStream instance configured to fetch updates from the 'ris-live' project. Prepare two pandas DataFrames, one each for tracking announcements and withdrawals, with columns for the time of the update, the prefix involved, and a count of occurrences. Design a function called process_bgp_data that operates continuously for a predetermined duration, here 180 seconds, to collect BGP updates. Within this function, filter the updates to identify those related to the AS of interest and update the respective DataFrame by either adding a new row for each unique prefix occurrence or incrementing the count for existing entries. Implement a mechanism to print out the top 5 prefixes by count from each DataFrame every 60 seconds, showcasing the most frequent announcements and withdrawals during that period before resetting the DataFrames for the next cycle of data collection. Initiate this data collection process in a separate thread to allow for concurrent execution without blocking other operations. Ensure that the entire script is designed to provide insights into the most active prefixes related to the specified AS within the live BGP feed, offering valuable information on BGP dynamics over a short, specified timeframe. [/INST]  Sure! Here is the Python script that leverages the PyBGPStream library for real-time monitoring of BGP updates related to the specified AS:\n",
      "```\n",
      "import pybgpstream\n",
      "import pandas as pd\n",
      "import threading\n",
      "import time\n",
      "\n",
      "# Initialize BGPStream instance\n",
      "stream = pybgpstream.BGPStream(\n",
      "    from_time=\"2023-03-10 15:00:00\", until_time=\"2023-03-10 16:00:00\",\n",
      "    project=\"ris-live\",\n",
      "    record_type=\"updates\",\n",
      "    filter=\"type announcement and collector ris-live and prefix more 24482\"\n",
      ")\n",
      "\n",
      "# Initialize DataFrames for announcements and withdrawals\n",
      "announcements = pd.DataFrame(columns=['time', 'prefix', 'count'])\n",
      "withdrawals = pd.DataFrame(columns=['time', 'prefix', 'count'])\n",
      "\n",
      "# Process BGP data\n",
      "def process_bgp_data():\n",
      "    global announcements, withdrawals\n",
      "    while True:\n",
      "        # Fetch BGP updates\n",
      "        for rec in stream.records():\n",
      "            for elem in rec:\n",
      "                if elem.type == 'A':\n",
      "                    # Add new row for each unique prefix occurrence\n",
      "                    if elem.fields['prefix'] not in announcements['prefix'].values:\n",
      "                        announcements = announcements.append({'time': time.time(), 'prefix': elem.fields['prefix'], 'count': 1}, ignore_index=True)\n",
      "                    else:\n",
      "                        announcements.loc[announcements['prefix'] == elem.fields['prefix'], 'count'] += 1\n",
      "                elif elem.type == 'W':\n",
      "                    # Increment count for existing entries\n",
      "                    withdrawals.loc[withdrawals['prefix'] == elem.fields['prefix'], 'count'] += 1\n",
      "\n",
      "        # Print top 5 prefixes by count every 60 seconds\n",
      "        print(\"Top 5 Announcements:\")\n",
      "        print(announcements.sort_values(by='count', ascending=False).head(5))\n",
      "        print(\"Top 5 Withdrawals:\")\n",
      "        print(withdrawals.sort_values(by='count', ascending=False).head(5))\n",
      "        # Reset DataFrames\n",
      "        announcements = announcements.reset_index(drop=True)\n",
      "        withdrawals = withdrawals.reset_index(drop=True)\n",
      "        # Wait for 60 seconds\n",
      "        time.sleep(60)\n",
      "\n",
      "# Start thread for concurrent execution\n",
      "thread = threading.Thread(target=process_bgp_data)\n",
      "thread.start()\n",
      "\n",
      "# Run for 180 seconds\n",
      "total_time = 180\n",
      "while time.time() < total_time:\n",
      "    thread.run()\n",
      "    # Wait for 60 seconds\n",
      "    time.sleep(60)\n",
      "\n",
      "# Print final results\n",
      "print(\"Top 5 Announcements:\")\n",
      "print(announcements.sort_values(by='count', ascending=False).head(5))\n",
      "print(\"Top 5 Withdrawals:\")\n",
      "print(withdrawals.sort_values(by='count', ascending=False).head(5))\n",
      "```\n",
      "This script uses the `pybgpstream` library to collect BGP updates from the 'ris-live' project. It then filters the updates to only include those related to the specified AS (24482) and stores the results in two separate DataFrames for announcements and withdrawals.\n",
      "\n",
      "The script then starts a separate thread to run the `process_bgp_data` function, which continuously collects BGP updates and updates the DataFrames. The script also includes a mechanism to print out the top 5 prefixes by count every 60 seconds.\n",
      "\n",
      "Finally, the script runs for 180 seconds and prints out the final results, including the top 5 announcements and withdrawals. This provides valuable insights into the most active prefixes related to the specified AS within the live BGP feed, offering information on BGP dynamics over a short, specified timeframe.\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Create a Python script that leverages the PyBGPStream library for real-time monitoring of BGP updates, focusing specifically on the announcements and withdrawals related to a particular Autonomous System (AS), here marked as '24482'. Initialize the script by setting up a BGPStream instance configured to fetch updates from the 'ris-live' project. Prepare two pandas DataFrames, one each for tracking announcements and withdrawals, with columns for the time of the update, the prefix involved, and a count of occurrences. Design a function called process_bgp_data that operates continuously for a predetermined duration, here 180 seconds, to collect BGP updates. Within this function, filter the updates to identify those related to the AS of interest and update the respective DataFrame by either adding a new row for each unique prefix occurrence or incrementing the count for existing entries. Implement a mechanism to print out the top 5 prefixes by count from each DataFrame every 60 seconds, showcasing the most frequent announcements and withdrawals during that period before resetting the DataFrames for the next cycle of data collection. Initiate this data collection process in a separate thread to allow for concurrent execution without blocking other operations. Ensure that the entire script is designed to provide insights into the most active prefixes related to the specified AS within the live BGP feed, offering valuable information on BGP dynamics over a short, specified timeframe.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1424)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 13:23:27 1000701: bgpstream_filter.c:307: ERROR: record-type filter must be one of \"ribs\" or \"updates\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid filter string: type announcement and collector ris-live and prefix more 24482",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize BGPStream instance\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[43mpybgpstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBGPStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-03-10 15:00:00\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muntil_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-03-10 16:00:00\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mris-live\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecord_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype announcement and collector ris-live and prefix more 24482\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize DataFrames for announcements and withdrawals\u001b[39;00m\n\u001b[1;32m     15\u001b[0m announcements \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pybgpstream/pybgpstream.py:70\u001b[0m, in \u001b[0;36mBGPStream.__init__\u001b[0;34m(self, from_time, until_time, data_interface, project, projects, collector, collectors, record_type, record_types, filter)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_add_filter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecord-type\u001b[39m\u001b[38;5;124m\"\u001b[39m, record_type, record_types)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_filter_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid filter string: type announcement and collector ris-live and prefix more 24482"
     ]
    }
   ],
   "source": [
    "import pybgpstream\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize BGPStream instance\n",
    "stream = pybgpstream.BGPStream(\n",
    "    from_time=\"2023-03-10 15:00:00\", until_time=\"2023-03-10 16:00:00\",\n",
    "    project=\"ris-live\",\n",
    "    record_type=\"updates\",\n",
    "    # filter=\"type announcement and collector ris-live and prefix more 24482\"\n",
    ")\n",
    "\n",
    "# Initialize DataFrames for announcements and withdrawals\n",
    "announcements = pd.DataFrame(columns=['time', 'prefix', 'count'])\n",
    "withdrawals = pd.DataFrame(columns=['time', 'prefix', 'count'])\n",
    "\n",
    "# Process BGP data\n",
    "def process_bgp_data():\n",
    "    global announcements, withdrawals\n",
    "    while True:\n",
    "        # Fetch BGP updates\n",
    "        for rec in stream.records():\n",
    "            for elem in rec:\n",
    "                if elem.type == 'A':\n",
    "                    # Add new row for each unique prefix occurrence\n",
    "                    if elem.fields['prefix'] not in announcements['prefix'].values:\n",
    "                        announcements = announcements.append({'time': time.time(), 'prefix': elem.fields['prefix'], 'count': 1}, ignore_index=True)\n",
    "                    else:\n",
    "                        announcements.loc[announcements['prefix'] == elem.fields['prefix'], 'count'] += 1\n",
    "                elif elem.type == 'W':\n",
    "                    # Increment count for existing entries\n",
    "                    withdrawals.loc[withdrawals['prefix'] == elem.fields['prefix'], 'count'] += 1\n",
    "\n",
    "        # Print top 5 prefixes by count every 60 seconds\n",
    "        print(\"Top 5 Announcements:\")\n",
    "        print(announcements.sort_values(by='count', ascending=False).head(5))\n",
    "        print(\"Top 5 Withdrawals:\")\n",
    "        print(withdrawals.sort_values(by='count', ascending=False).head(5))\n",
    "        # Reset DataFrames\n",
    "        announcements = announcements.reset_index(drop=True)\n",
    "        withdrawals = withdrawals.reset_index(drop=True)\n",
    "        # Wait for 60 seconds\n",
    "        time.sleep(60)\n",
    "\n",
    "# Start thread for concurrent execution\n",
    "thread = threading.Thread(target=process_bgp_data)\n",
    "thread.start()\n",
    "\n",
    "# Run for 180 seconds\n",
    "total_time = 180\n",
    "while time.time() < total_time:\n",
    "    thread.run()\n",
    "    # Wait for 60 seconds\n",
    "    time.sleep(60)\n",
    "\n",
    "# Print final results\n",
    "print(\"Top 5 Announcements:\")\n",
    "print(announcements.sort_values(by='count', ascending=False).head(5))\n",
    "print(\"Top 5 Withdrawals:\")\n",
    "print(withdrawals.sort_values(by='count', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Change the AS number to 7812 and total run time to 500. Add a function that will plot the top prefix announcements and withdrawals along with print statements.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize BGPStream instance\n",
    "stream = pybgpstream.BGPStream(\n",
    "    project=\"ris-live\",\n",
    "    record_type=\"updates\",\n",
    ")\n",
    "\n",
    "# Initialize DataFrames for announcements and withdrawals\n",
    "announcements = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "withdrawals = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "\n",
    "def process_bgp_data(stop_time):\n",
    "    global announcements, withdrawals\n",
    "    end_time = time.time() + stop_time  # Calculate end time based on stop_time duration\n",
    "    last_print_time = time.time()\n",
    "\n",
    "    while time.time() < end_time:\n",
    "        for rec in stream.records():\n",
    "            for elem in rec:\n",
    "                # Filter records with AS7262 in the AS path\n",
    "                as_path = elem.fields.get('as-path', '').split()\n",
    "                if '24482' in as_path:\n",
    "                    time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(rec.time))\n",
    "                    prefix = elem.fields['prefix']\n",
    "                    df = announcements if elem.type == 'A' else withdrawals\n",
    "                    row_index = df[(df['Time'] == time_str) & (df['Prefix'] == prefix)].index\n",
    "                    if row_index.empty:\n",
    "                        df.loc[len(df)] = [time_str, prefix, 1]\n",
    "                    else:\n",
    "                        df.loc[row_index, 'Count'] += 1\n",
    "\n",
    "            # Check if it's time to print and reset DataFrames (every 60 seconds)\n",
    "            if time.time() - last_print_time >= 60:\n",
    "                # Sort and get the top 5 prefixes by count for announcements\n",
    "                top_announcements = announcements.sort_values(by='Count', ascending=False).head(5)\n",
    "                # Sort and get the top 5 prefixes by count for withdrawals\n",
    "                top_withdrawals = withdrawals.sort_values(by='Count', ascending=False).head(5)\n",
    "                \n",
    "                print(\"Top 5 Announcements:\\n\", top_announcements)\n",
    "                print(\"Top 5 Withdrawals:\\n\", top_withdrawals)\n",
    "                \n",
    "                announcements = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "                withdrawals = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "                last_print_time = time.time()  # Update last_print_time\n",
    "\n",
    "    print(\"Data collection finished.\")\n",
    "\n",
    "# Define the total running time (180 seconds)\n",
    "total_running_time = 180\n",
    "\n",
    "# Start data collection thread\n",
    "data_collection_thread = threading.Thread(target=process_bgp_data, args=(total_running_time,))\n",
    "data_collection_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 1; 47.31 GiB total capacity; 11.98 GiB already allocated; 39.00 MiB free; 11.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 66\u001b[0m\n\u001b[1;32m      5\u001b[0m prompt_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mimport pybgpstream\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mimport pandas as pd\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124mdata_collection_thread.start()\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     65\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2056\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<s>[INST] \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt_input\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt_output\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m [/INST]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/text_generation.py:204\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1121\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1115\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         )\n\u001b[1;32m   1119\u001b[0m     )\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1128\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1127\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1128\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1129\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1027\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1026\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1027\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/text_generation.py:265\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1559\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_return_sequences has to be 1 when doing greedy search, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1560\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1561\u001b[0m         )\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/utils.py:2457\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2454\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2456\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2457\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2460\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2461\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2465\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:810\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    807\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 810\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:698\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    690\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    691\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    692\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    696\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:413\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    410\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:322\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    320\u001b[0m     kv_seq_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m past_key_value[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    321\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(value_states, seq_len\u001b[38;5;241m=\u001b[39mkv_seq_len)\n\u001b[0;32m--> 322\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# reuse k, v, self_attention\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m0\u001b[39m], key_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:186\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids)\u001b[0m\n\u001b[1;32m    184\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [bs, 1, seq_len, dim]\u001b[39;00m\n\u001b[1;32m    185\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [bs, 1, seq_len, dim]\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m)\n\u001b[1;32m    187\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 1; 47.31 GiB total capacity; 11.98 GiB already allocated; 39.00 MiB free; 11.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt_input = \"Change the AS number to 7812 and total run time to 500. Add a function that will plot a bar graph with the top 5 prefix announcements and withdrawals along with print statements.\"\n",
    "prompt_output = \"\"\"\n",
    "import pybgpstream\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize BGPStream instance\n",
    "stream = pybgpstream.BGPStream(\n",
    "    project=\"ris-live\",\n",
    "    record_type=\"updates\",\n",
    ")\n",
    "\n",
    "# Initialize DataFrames for announcements and withdrawals\n",
    "announcements = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "withdrawals = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "\n",
    "def process_bgp_data(stop_time):\n",
    "    global announcements, withdrawals\n",
    "    end_time = time.time() + stop_time  # Calculate end time based on stop_time duration\n",
    "    last_print_time = time.time()\n",
    "\n",
    "    while time.time() < end_time:\n",
    "        for rec in stream.records():\n",
    "            for elem in rec:\n",
    "                # Filter records with 24482 in the AS path\n",
    "                as_path = elem.fields.get('as-path', '').split()\n",
    "                if '24482' in as_path:\n",
    "                    time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(rec.time))\n",
    "                    prefix = elem.fields['prefix']\n",
    "                    df = announcements if elem.type == 'A' else withdrawals\n",
    "                    row_index = df[(df['Time'] == time_str) & (df['Prefix'] == prefix)].index\n",
    "                    if row_index.empty:\n",
    "                        df.loc[len(df)] = [time_str, prefix, 1]\n",
    "                    else:\n",
    "                        df.loc[row_index, 'Count'] += 1\n",
    "\n",
    "            # Check if it's time to print and reset DataFrames (every 60 seconds)\n",
    "            if time.time() - last_print_time >= 60:\n",
    "                # Sort and get the top 5 prefixes by count for announcements\n",
    "                top_announcements = announcements.sort_values(by='Count', ascending=False).head(5)\n",
    "                # Sort and get the top 5 prefixes by count for withdrawals\n",
    "                top_withdrawals = withdrawals.sort_values(by='Count', ascending=False).head(5)\n",
    "                \n",
    "                print(\"Top 5 Announcements:\\n\", top_announcements)\n",
    "                print(\"Top 5 Withdrawals:\\n\", top_withdrawals)\n",
    "                \n",
    "                announcements = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "                withdrawals = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "                last_print_time = time.time()  # Update last_print_time\n",
    "\n",
    "    print(\"Data collection finished.\")\n",
    "\n",
    "# Define the total running time (180 seconds)\n",
    "total_running_time = 180\n",
    "\n",
    "# Start data collection thread\n",
    "data_collection_thread = threading.Thread(target=, args=(total_running_time,))\n",
    "data_collection_thread.start()\n",
    "\"\"\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=2056)\n",
    "result = pipe(f\"<s>[INST] {prompt_input} {prompt_output} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Define the total running time (180 seconds)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m total_running_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mprocess_bgp_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_running_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mprocess_bgp_data\u001b[0;34m(stop_time)\u001b[0m\n\u001b[1;32m     31\u001b[0m row_index \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m time_str) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrefix\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m prefix)]\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_index\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m [time_str, prefix, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[row_index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 849\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1825\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1822\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1825\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1829\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:2180\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m   2179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[1;32m   2181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:9537\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   9526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   9527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only append a Series if ignore_index=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9528\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor if the Series has a name\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9529\u001b[0m     )\n\u001b[1;32m   9531\u001b[0m index \u001b[38;5;241m=\u001b[39m Index(\n\u001b[1;32m   9532\u001b[0m     [other\u001b[38;5;241m.\u001b[39mname],\n\u001b[1;32m   9533\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[1;32m   9534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex)\n\u001b[1;32m   9535\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   9536\u001b[0m )\n\u001b[0;32m-> 9537\u001b[0m row_df \u001b[38;5;241m=\u001b[39m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m   9538\u001b[0m \u001b[38;5;66;03m# infer_objects is needed for\u001b[39;00m\n\u001b[1;32m   9539\u001b[0m \u001b[38;5;66;03m#  test_append_empty_frame_to_series_with_dateutil_tz\u001b[39;00m\n\u001b[1;32m   9540\u001b[0m other \u001b[38;5;241m=\u001b[39m row_df\u001b[38;5;241m.\u001b[39minfer_objects(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mrename_axis(\n\u001b[1;32m   9541\u001b[0m     index\u001b[38;5;241m.\u001b[39mnames, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   9542\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3634\u001b[0m, in \u001b[0;36mDataFrame.T\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3607\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mT\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   3609\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3610\u001b[0m \u001b[38;5;124;03m    The transpose of the DataFrame.\u001b[39;00m\n\u001b[1;32m   3611\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;124;03m    col2  3  4\u001b[39;00m\n\u001b[1;32m   3633\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3566\u001b[0m, in \u001b[0;36mDataFrame.transpose\u001b[0;34m(self, copy, *args)\u001b[0m\n\u001b[1;32m   3563\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_transpose(args, {})\n\u001b[1;32m   3564\u001b[0m \u001b[38;5;66;03m# construct the args\u001b[39;00m\n\u001b[0;32m-> 3566\u001b[0m dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m)\n\u001b[1;32m   3568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_fast_transpose:\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;66;03m# Note: tests pass without this, but this improves perf quite a bit.\u001b[39;00m\n\u001b[1;32m   3570\u001b[0m     new_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:6158\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6130\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   6131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtypes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   6132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;124;03m    Return the dtypes in the DataFrame.\u001b[39;00m\n\u001b[1;32m   6134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6156\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   6157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6158\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(data, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py:278\u001b[0m, in \u001b[0;36mBaseBlockManager.get_dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dtypes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    277\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks])\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblknos\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py:179\u001b[0m, in \u001b[0;36mBaseBlockManager.blknos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03mSuppose we want to find the array corresponding to our i'th column.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03mself.blocks[self.blknos[i]]\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# Note: these can be altered by other BlockManager methods.\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rebuild_blknos_and_blklocs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/internals.pyx:749\u001b[0m, in \u001b[0;36mpandas._libs.internals.BlockManager._rebuild_blknos_and_blklocs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/base.py:54\u001b[0m, in \u001b[0;36mDataManager.shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mndim\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Shape:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ax) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pybgpstream\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Initialize BGPStream instance\n",
    "stream = pybgpstream.BGPStream(\n",
    "    project=\"ris-live\",\n",
    "    record_type=\"updates\",\n",
    ")\n",
    "\n",
    "# Initialize DataFrames for announcements and withdrawals\n",
    "announcements = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "withdrawals = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "\n",
    "def process_bgp_data(stop_time):\n",
    "    global announcements, withdrawals\n",
    "    end_time = time.time() + stop_time  # Calculate end time based on stop_time duration\n",
    "    last_print_time = time.time()\n",
    "\n",
    "    while time.time() < end_time:\n",
    "        for rec in stream.records():\n",
    "            for elem in rec:\n",
    "                # Filter records with 7812 in the AS path\n",
    "                as_path = elem.fields.get('as-path', '').split()\n",
    "                if '24482' in as_path:\n",
    "                    time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(rec.time))\n",
    "                    prefix = elem.fields['prefix']\n",
    "                    df = announcements if elem.type == 'A' else withdrawals\n",
    "                    row_index = df[(df['Time'] == time_str) & (df['Prefix'] == prefix)].index\n",
    "                    if row_index.empty:\n",
    "                        df.loc[len(df)] = [time_str, prefix, 1]\n",
    "                    else:\n",
    "                        df.loc[row_index, 'Count'] += 1\n",
    "\n",
    "            # Check if it's time to print and reset DataFrames (every 60 seconds)\n",
    "            if time.time() - last_print_time >= 60:\n",
    "                # Sort and get the top 5 prefixes by count for announcements\n",
    "                top_announcements = announcements.sort_values(by='Count', ascending=False).head(5)\n",
    "                # Sort and get the top 5 prefixes by count for withdrawals\n",
    "                top_withdrawals = withdrawals.sort_values(by='Count', ascending=False).head(5)\n",
    "                \n",
    "                # Plot the top prefix announcements and withdrawals\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.plot(top_announcements['Time'], top_announcements['Prefix'], 'bo-', label='Announcements')\n",
    "                plt.plot(top_withdrawals['Time'], top_withdrawals['Prefix'], 'ro-', label='Withdrawals')\n",
    "                plt.xlabel('Time')\n",
    "                plt.ylabel('Prefix')\n",
    "                plt.title('Top 5 Prefixes')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                \n",
    "                announcements = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "                withdrawals = pd.DataFrame(columns=['Time', 'Prefix', 'Count'])\n",
    "                last_print_time = time.time()  # Update last_print_time\n",
    "\n",
    "    print(\"Data collection finished.\")\n",
    "\n",
    "# Define the total running time (180 seconds)\n",
    "total_running_time = 180\n",
    "process_bgp_data(total_running_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: When analyzing BGP route propagation, which attribute provides information about the path that the BGP update has traversed?\n",
      "a) AS-Path\n",
      "b) MED (Multi-Exit Discriminator)\n",
      "c) Local Preference\n",
      "d) Next Hop\n",
      "\n",
      "Answer: a) AS-Path\n",
      "\n",
      "Explanation: The AS-Path attribute is used to track the path that a BGP update has traversed. It is a list of Autonomous System (AS) numbers that the update has passed through. This attribute helps in identifying the path that the update has\n",
      "Parsed_answer: a\n",
      "----------------1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Which of the following is a primary purpose of BGP?\n",
      "a) Establishing communication between devices within a LAN\n",
      "b) Exchanging routing information between autonomous systems\n",
      "c) Optimizing local network traffic\n",
      "d) Assigning IP addresses to devices\n",
      "\n",
      "Answer: b) Exchanging routing information between autonomous systems.\n",
      "\n",
      "Explanation: BGP (Border Gateway Protocol) is a protocol used to exchange routing information between autonomous systems. It is used to establish communication between devices within a LAN, optimize local network traffic, and assign IP\n",
      "Parsed_answer: b\n",
      "----------------2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the main function of the AS-Path attribute in BGP?\n",
      "a) Identifying the IP address of the next hop\n",
      "b) Preventing route hijacking\n",
      "c) Specifying the exit point from an AS\n",
      "d) Tracking the ASes a route has traversed\n",
      "\n",
      "Answer: d) Tracking the ASes a route has traversed. The AS-Path attribute is used to track the ASes a route has traversed, allowing BGP routers to determine the best path to a destination. It is not used to identify the IP address of the next\n",
      "Parsed_answer: d\n",
      "----------------3-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Which BGP attribute indicates the preferred exit point from an AS?\n",
      "a) ORIGIN\n",
      "b) LOCAL-PREF\n",
      "c) NEXT-HOP\n",
      "d) AS-PATH\n",
      "\n",
      "Answer: c) NEXT-HOP\n",
      "\n",
      "Explanation: The NEXT-HOP attribute indicates the IP address of the next-hop router for a particular route. This attribute is used to determine the preferred exit point from an Autonomous System (AS). The NEXT-HOP attribute is used by BGP routers to determine the best path to a\n",
      "Parsed_answer: c\n",
      "----------------4-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Which BGP message is used to establish a BGP session?\n",
      "a) KEEPALIVE\n",
      "b) OPEN\n",
      "c) UPDATE\n",
      "d) NOTIFICATION\n",
      "\n",
      "Answer: b) OPEN\n",
      "\n",
      "Explanation: The OPEN message is used to establish a BGP session between two BGP peers. It is sent by the initiator of the session and contains information about the BGP version, the BGP identifier, and the BGP hold timer. The OPEN message is used to establish a BGP session and is the first message exchanged between two B\n",
      "Parsed_answer: b\n",
      "----------------5-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the primary purpose of the BGP NEXT-HOP attribute?\n",
      "a) Specifies the IP address of the sender\n",
      "b) Indicates the preferred exit point from an AS\n",
      "c) Defines the next router in the path\n",
      "d) Specifies the route's origin\n",
      "\n",
      "Answer: c) Defines the next router in the path\n",
      "\n",
      "Explanation: The BGP NEXT-HOP attribute is used to specify the next router in the path of a BGP route. It is used to indicate the IP address of the next router in the path,\n",
      "Parsed_answer: c\n",
      "----------------6-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Which BGP message is used to advertise new or withdrawn routes?\n",
      "a) KEEPALIVE\n",
      "b) OPEN\n",
      "c) UPDATE\n",
      "d) NOTIFICATION\n",
      "\n",
      "Answer: c) UPDATE\n",
      "\n",
      "Explanation: The UPDATE message is used to advertise new or withdrawn routes. It is sent by a router to its peers to inform them of changes in the network. The KEEPALIVE message is used to maintain the connection between BGP peers, the OPEN message is used to establish a BGP session, and the NOTIF\n",
      "Parsed_answer: c\n",
      "----------------7-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the purpose of BGP route aggregation?\n",
      "a) Breaking down large routes into smaller subnets\n",
      "b) Combining multiple routes into a single summarized route\n",
      "c) Assigning priority to specific routes\n",
      "d) Applying policies to routes\n",
      "\n",
      "Answer: b) Combining multiple routes into a single summarized route.\n",
      "\n",
      "Explanation: BGP route aggregation is the process of combining multiple routes into a single summarized route. This helps reduce the size of the routing table and improve network performance. By combining multiple routes into a single summarized\n",
      "Parsed_answer: b\n",
      "----------------8-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the term for maliciously advertising IP prefixes an AS doesn't own?\n",
      "a) BGP Route Hijacking\n",
      "b) BGP Anomaly Detection\n",
      "c) BGP Route Flap\n",
      "d) BGP Route Aggregation\n",
      "\n",
      "Answer: a) BGP Route Hijacking.\n",
      "\n",
      "Explanation: BGP Route Hijacking is the term used to describe the malicious advertisement of IP prefixes an AS does not own. This can be done by an attacker to redirect traffic away from its intended destination, or\n",
      "Parsed_answer: a\n",
      "----------------9-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: BGP Prefix Origin Validation (ROV) is primarily aimed at preventing:\n",
      "a) BGP route damping\n",
      "b) BGP session establishment\n",
      "c) BGP route leaks and hijacks\n",
      "d) BGP route aggregation\n",
      "\n",
      "Answer: c) BGP route leaks and hijacks.\n",
      "\n",
      "Explanation: BGP Prefix Origin Validation (ROV) is a security feature that helps prevent route leaks and hijacks by verifying the origin of BGP routes. It ensures that routes are not propagated from an unexpected source\n",
      "Parsed_answer: c\n",
      "----------------10-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Which BGP attribute is used to group routes into categories?\n",
      "a) LOCAL-PREF\n",
      "b) MED\n",
      "c) AS-PATH\n",
      "d) COMMUNITY\n",
      "\n",
      "Answer: d) COMMUNITY\n",
      "\n",
      "Explanation: The COMMUNITY attribute is used to group routes into categories. It is used to identify routes that are part of a specific community, such as a specific AS or a specific group of ASes. This attribute is used to influence route selection and to control the propagation of routes within a network.\n",
      "\n",
      "Note: The other\n",
      "Parsed_answer: d\n",
      "----------------11-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: BGP confederations are used to:\n",
      "a) Optimize local network traffic\n",
      "b) Divide an AS into sub-ASes for scalability\n",
      "c) Group routes into categories\n",
      "d) Handle BGP session establishment\n",
      "\n",
      "Answer: b) Divide an AS into sub-ASes for scalability. BGP confederations are used to divide an Autonomous System (AS) into sub-ASes, allowing for better scalability and improved performance. This is done by grouping multiple ASes into a single confederation, allowing them to share a single BGP\n",
      "Parsed_answer: b\n",
      "----------------12-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Which BGP attribute is used to influence route selection by assigning a value to the route?\n",
      "a) ORIGIN\n",
      "b) MED\n",
      "c) AS-PATH\n",
      "d) LOCAL-PREF\n",
      "\n",
      "Answer: d) LOCAL-PREF\n",
      "\n",
      "Explanation: The LOCAL-PREF attribute is used to influence route selection by assigning a value to the route. This attribute is used to indicate the preference of a route within a single autonomous system. The higher the value, the more preferred the route is. This attribute is used to influence route selection\n",
      "Parsed_answer: d\n",
      "----------------13-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the purpose of the BGP NOTIFICATION message?\n",
      "a) Establish a BGP session\n",
      "b) Advertise new routes\n",
      "c) Signal an error or event in the BGP session\n",
      "d) Request a route refresh\n",
      "\n",
      "Answer: c) Signal an error or event in the BGP session.\n",
      "\n",
      "Explanation: The BGP NOTIFICATION message is used to signal an error or event in the BGP session. It is used to inform the other BGP peer of an error or event that has occurred in the session, such as a\n",
      "Parsed_answer: c\n",
      "----------------14-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the primary purpose of the BGP Community attribute?\n",
      "a) Indicate the preferred exit point\n",
      "b) Prevent route flapping\n",
      "c) Define route policies based on grouping\n",
      "d) Determine the AS-Path length\n",
      "\n",
      "Answer: c) Define route policies based on grouping. The BGP Community attribute is used to group routes and define policies based on those groups. It allows for more granular control over route selection and can be used to influence the path taken by traffic. The other options are incorrect because the primary purpose of the BGP Community attribute is not to indicate the\n",
      "Parsed_answer: c\n",
      "----------------15-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: BGP Route Reflectors are used to address the scalability issues associated with:\n",
      "a) Excessive route dampening\n",
      "b) Route summarization\n",
      "c) Full mesh BGP peering\n",
      "d) BGP prefix hijacking\n",
      "\n",
      "Answer: b) Route summarization. BGP Route Reflectors are used to address the scalability issues associated with route summarization. They reduce the number of BGP updates by summarizing routes and propagating them to other BGP peers. This helps to reduce the number of BGP updates and improve scalability.\n",
      "\n",
      "Question\n",
      "Parsed_answer: b\n",
      "----------------16-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the primary purpose of the BGP Path Attribute?\n",
      "a) Identify the exit point from an AS\n",
      "b) Indicate the origin of a route\n",
      "c) Determine the optimal route\n",
      "d) Filter BGP routes\n",
      "\n",
      "Answer: c) Determine the optimal route\n",
      "\n",
      "Explanation: The primary purpose of the BGP Path Attribute is to determine the optimal route for a given destination. It contains information about the route, such as the origin AS, the AS path, the next hop, and the local preference. This information is used by BGP routers\n",
      "Parsed_answer: c\n",
      "----------------17-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: BGP Prefix Filtering is used to:\n",
      "a) Prevent route hijacking\n",
      "b) Optimize route propagation\n",
      "c) Establish BGP sessions\n",
      "d) Calculate BGP AS-Paths\n",
      "\n",
      "Answer: a) Prevent route hijacking\n",
      "\n",
      "Explanation: BGP Prefix Filtering is used to prevent route hijacking by allowing an administrator to filter out routes that are not desired. This is done by configuring a prefix list that specifies which routes should be accepted or rejected. By using prefix filtering, an administrator can prevent\n",
      "Parsed_answer: a\n",
      "----------------18-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: In BGP, what is the primary purpose of the ORIGIN attribute?\n",
      "a) Identify the exit point from an AS\n",
      "b) Determine the preferred route within an AS\n",
      "c) Indicate the origin of a route\n",
      "d) Assign values for path selection\n",
      "\n",
      "Answer: c) Indicate the origin of a route. The ORIGIN attribute is used to indicate the origin of a route, such as an IGP or an EGP. It is used to identify the source of a route and to determine the preferred route within an AS. It is not used to\n",
      "Parsed_answer: c\n",
      "----------------19-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What does the BGP Maximum Prefix Limit control?\n",
      "a) The number of BGP routes that can be aggregated\n",
      "b) The maximum length of the AS-Path attribute\n",
      "c) The number of prefixes a BGP router will accept\n",
      "d) The BGP route redistribution process\n",
      "\n",
      "Answer: c) The number of prefixes a BGP router will accept. The BGP Maximum Prefix Limit controls the number of prefixes a BGP router will accept from its peers. This limit is used to prevent the router from accepting too many prefixes\n",
      "Parsed_answer: c\n",
      "----------------20-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the purpose of the BGP Large Communities attribute?\n",
      "a) Determine the optimal route path\n",
      "b) Prevent BGP session timeouts\n",
      "c) Provide more efficient route summarization\n",
      "d) Group routes into categories based on policies\n",
      "\n",
      "Answer: c) Provide more efficient route summarization. The BGP Large Communities attribute is used to group routes into categories based on policies, allowing for more efficient route summarization. It is not used to determine the optimal route path, prevent BGP session timeouts, or group routes into categories based on policies.\n",
      "Parsed_answer: c\n",
      "----------------21-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: In BGP, what is the significance of the BGP Weight attribute?\n",
      "a) It determines the exit point from an AS\n",
      "b) It influences the route selection within an AS\n",
      "c) It specifies the BGP session timeout value\n",
      "d) It defines the route origin\n",
      "\n",
      "Answer: b) It influences the route selection within an AS\n",
      "\n",
      "Explanation: The BGP Weight attribute is used to influence the route selection within an Autonomous System (AS). It is used to prioritize routes within an AS, allowing the network administrator to control the\n",
      "Parsed_answer: b\n",
      "----------------22-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: How does the BGP AS Confederation help address the full mesh peering challenge?\n",
      "a) It reduces the number of AS-Path segments\n",
      "b) It introduces hierarchical routing within a single AS\n",
      "c) It increases the number of BGP sessions between routers\n",
      "d) It optimizes the BGP Weight attribute\n",
      "\n",
      "Answer: b) It introduces hierarchical routing within a single AS.\n",
      "\n",
      "Explanation: BGP AS Confederation is a technique used to address the full mesh peering challenge by introducing hierarchical routing within a single AS.\n",
      "Parsed_answer: b\n",
      "----------------23-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is BGPsec and how does it enhance BGP security?\n",
      "a) BGPsec is a protocol for secure BGP session establishment\n",
      "b) BGPsec is an extension to BGP that adds cryptographic verification to BGP route announcements\n",
      "c) BGPsec is a mechanism for prefix aggregation in BGP\n",
      "d) BGPsec is used to prevent BGP route leaks\n",
      "\n",
      "Answer: b) BGPsec is an extension to BGP that adds cryptographic verification to BGP route announcements. BGPsec is a protocol that\n",
      "Parsed_answer: b\n",
      "----------------24-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: When is the BGP Extended Community attribute used, and what information does it convey?\n",
      "a) It is used for route summarization within a single AS\n",
      "b) It conveys policy information and inter-domain actions associated with a route\n",
      "c) It determines the local preference of a BGP route\n",
      "d) It specifies the AS-Path segment of a route\n",
      "\n",
      "Answer: b) It conveys policy information and inter-domain actions associated with a route.\n",
      "\n",
      "Explanation: The BGP Extended Community attribute is used to convey policy information and inter-\n",
      "Parsed_answer: b\n",
      "----------------25-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Input length of input_ids is 141, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the concept of BGP Flowspec, and how does it enhance BGP routing control?\n",
      "a) BGP Flowspec is a mechanism to advertise real-time network traffic statistics\n",
      "b) BGP Flowspec is used for route aggregation in large networks\n",
      "c) BGP Flowspec allows the dissemination of traffic filtering rules using BGP updates\n",
      "d) BGP Flowspec determines the AS-Path of a route\n",
      "\n",
      "Answer: c) BGP Flowspec allows the dissemination of traffic filtering rules using BGP updates. BGP Flowspec is a\n",
      "Parsed_answer: c\n",
      "----------------26-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Explain the difference between BGP Route Reflection and BGP Confederations.\n",
      "a) BGP Route Reflection optimizes BGP sessions within an AS, while BGP Confederations divide an AS into smaller sub-ASes for scalability\n",
      "b) BGP Route Reflection is used to group BGP routes, while BGP Confederations enhance BGP security\n",
      "c) BGP Route Reflection is a method to prevent BGP route hijacking, while BGP Confederations manage BGP community attributes\n",
      "d) BGP Route Reflection establishes BGP sessions between ASes, while BGP Confederations control the BGP Weight attribute\n",
      "\n",
      "----------------27-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is BGP Route Damping, and how does it impact BGP routing stability?\n",
      "a) BGP Route Damping is a mechanism to prevent BGP prefix aggregation, ensuring route granularity\n",
      "b) BGP Route Damping is a technique to mitigate the impact of BGP prefix hijacking\n",
      "c) BGP Route Damping is used to reduce the rate of BGP route updates in response to route flapping\n",
      "d) BGP Route Damping is a security feature that encrypts BGP updates to prevent eavesdropping\n",
      "\n",
      "----------------28-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Input length of input_ids is 133, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: How does BGP Prefix Hijacking occur, and what are the potential consequences?\n",
      "a) BGP Prefix Hijacking occurs when BGP sessions are established without proper authentication, leading to data leaks\n",
      "b) BGP Prefix Hijacking involves advertising IP prefixes an AS doesn't own, potentially redirecting traffic to unauthorized paths\n",
      "c) BGP Prefix Hijacking is a result of BGP session timeouts causing route instability\n",
      "d) BGP Prefix Hijacking is a technique to achieve BGP route summarization\n",
      "\n",
      "\n",
      "----------------29-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the purpose of the BGP RPKI (Resource Public Key Infrastructure) framework, and how does it enhance BGP security?\n",
      "a) BGP RPKI is used for route reflection in BGP Confederations, enhancing scalability\n",
      "b) BGP RPKI provides cryptographic verification of BGP route announcements, preventing prefix hijacking\n",
      "c) BGP RPKI optimizes the BGP Local Preference attribute for route selection\n",
      "d) BGP RPKI is a mechanism for BGP prefix aggregation, reducing the number of routes exchanged\n",
      "\n",
      "----------------30-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Input length of input_ids is 140, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: Describe the purpose of the BGP FlowSpec Redirect action and how it affects network traffic.\n",
      "a) BGP FlowSpec Redirect is used to filter incoming BGP routes based on their AS-Path\n",
      "b) BGP FlowSpec Redirect redirects incoming network traffic matching specified criteria to a designated next-hop\n",
      "c) BGP FlowSpec Redirect increases the BGP session timeout value, reducing BGP convergence time\n",
      "d) BGP FlowSpec Redirect optimizes the BGP Weight attribute for route selection\n",
      "\n",
      "Answer: b) BGP FlowSpec Redirect redirects\n",
      "Parsed_answer: b\n",
      "----------------31-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What is the difference between BGP Route Refresh and BGP Full Withdraw?\n",
      "a) BGP Route Refresh is used to advertise new routes, while BGP Full Withdraw indicates route errors\n",
      "b) BGP Route Refresh is a mechanism for re-advertising BGP routes, while BGP Full Withdraw removes all prefixes associated with a peer\n",
      "c) BGP Route Refresh is used for BGP prefix aggregation, while BGP Full Withdraw triggers route convergence\n",
      "d) BGP Route Refresh optimizes the BGP LOCAL-PREF attribute, while BGP Full Withdraw prevents route flapping\n",
      "\n",
      "----------------32-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Input length of input_ids is 128, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: How does the BGP Add-Path feature enhance BGP route selection and convergence?\n",
      "a) BGP Add-Path enables BGP routers to advertise multiple alternate paths for a given prefix\n",
      "b) BGP Add-Path decreases the BGP session establishment time, enhancing route convergence\n",
      "c) BGP Add-Path optimizes the BGP Weight attribute for route selection\n",
      "d) BGP Add-Path prevents BGP prefix hijacking by adding cryptographic signatures to BGP updates\n",
      "\n",
      "Answer: a) BGP Add-Path enables BGP rou\n",
      "Parsed_answer: a\n",
      "----------------33-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer: Choose the correct answer: What are BGP Route Reflection Clusters, and how do they contribute to BGP scalability?\n",
      "a) BGP Route Reflection Clusters are used to enhance BGP security by encrypting BGP updates\n",
      "b) BGP Route Reflection Clusters group routers within an AS, reducing the number of BGP sessions needed for route reflection\n",
      "c) BGP Route Reflection Clusters prevent BGP prefix hijacking by using cryptographic verification\n",
      "d) BGP Route Reflection Clusters optimize the BGP MED attribute for efficient route selection\n",
      "\n",
      "----------------34-----------------\n",
      "Generated Answer: Choose the correct answer: Explain the concept of BGP PIC (Prefix Independent Convergence) and its significance in enhancing network reliability.\n",
      "a) BGP PIC ensures that BGP routers converge to the same routing table in the event of network failures\n",
      "b) BGP PIC introduces route summarization to improve BGP scalability\n",
      "c) BGP PIC reduces the BGP session establishment time, enhancing route convergence\n",
      "d) BGP PIC optimizes the BGP AS-Path attribute for efficient route selection\n",
      "\n",
      "Answer: a) BGP P\n",
      "Parsed_answer: a\n",
      "----------------35-----------------\n",
      "['a', 'b', 'd', 'c', 'b', 'c', 'c', 'b', 'a', 'c', 'd', 'b', 'd', 'c', 'c', 'b', 'c', 'a', 'c', 'c', 'c', 'b', 'b', 'b', 'b', 'c', '', '', '', '', 'b', '', 'a', '', 'a']\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "GPT answer: c. Correct answer: b\n",
      "Incorrect\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "GPT answer: d. Correct answer: b\n",
      "Incorrect\n",
      "Correct\n",
      "Correct\n",
      "GPT answer: b. Correct answer: c\n",
      "Incorrect\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "GPT answer: c. Correct answer: d\n",
      "Incorrect\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "Correct\n",
      "GPT answer: . Correct answer: a\n",
      "Incorrect\n",
      "GPT answer: . Correct answer: c\n",
      "Incorrect\n",
      "GPT answer: . Correct answer: b\n",
      "Incorrect\n",
      "GPT answer: . Correct answer: b\n",
      "Incorrect\n",
      "Correct\n",
      "GPT answer: . Correct answer: b\n",
      "Incorrect\n",
      "Correct\n",
      "GPT answer: . Correct answer: b\n",
      "Incorrect\n",
      "Correct\n",
      "Accuracy: 71.43%\n",
      "Correct answers: 25\n",
      "Incorrect answers: 10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_file_path = \"/home/hb/LLM-research/evaluation/BGP/bgp_test_multiple_choice_v2.json\" \n",
    "\n",
    "with open(input_file_path, \"r\") as input_file:\n",
    "    questions_data = json.load(input_file)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "\n",
    "generated_answers = []\n",
    "ground_truth = [q_dict[\"answer\"] for q_dict in questions_data]\n",
    "n_question = 0\n",
    "\n",
    "for q_dict in questions_data:\n",
    "    question = q_dict[\"question\"]\n",
    "    options = q_dict[\"options\"]\n",
    "    \n",
    "    # Construct prompt with question and options\n",
    "    prompt = f\"Choose the correct answer: {question}\\n\" + \"\\n\".join(options)\n",
    "    # print(prompt)\n",
    "    \n",
    "    # Generate answer using the language model\n",
    "    generated_answer = pipe(prompt)[0]['generated_text']\n",
    "    print(f\"Generated Answer: {generated_answer}\")\n",
    "    \n",
    "    # Parse the generated answer\n",
    "    answer_lines = generated_answer.splitlines()\n",
    "    parsed_answer = \"\"\n",
    "    for line in answer_lines:\n",
    "            if line.startswith(\"Answer: \") or line.startswith(\"Correct answer: \"):\n",
    "                parsed_answer = re.search(r'\\b(\\w)\\)', line).group(1)\n",
    "                print(f\"Parsed_answer: {parsed_answer}\")\n",
    "                break\n",
    "    generated_answers.append(parsed_answer)\n",
    "    n_question += 1\n",
    "    print(f\"----------------{n_question}-----------------\")\n",
    "print(generated_answers)\n",
    "\n",
    "\n",
    "total_questions = len(questions_data)\n",
    "correct_answers = 0\n",
    "\n",
    "for ground_answer, generated_answer in zip(ground_truth, generated_answers):\n",
    "    if generated_answer.lower() == ground_answer.lower():\n",
    "        print(\"Correct\")\n",
    "        correct_answers += 1\n",
    "    else:\n",
    "        print(f\"GPT answer: {generated_answer}. Correct answer: {ground_answer}\")\n",
    "        print(\"Incorrect\")\n",
    "\n",
    "accuracy = (correct_answers / total_questions) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Correct answers: {correct_answers}\")\n",
    "print(f\"Incorrect answers: {total_questions - correct_answers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_file_path = \"/home/hb/LLM-research/evaluation/bgp_test_fill_the_blank.json\" \n",
    "\n",
    "with open(input_file_path, \"r\") as input_file:\n",
    "    questions_data = json.load(input_file)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "\n",
    "generated_answers_fb = []\n",
    "filled_answers = []\n",
    "\n",
    "n_question = 0\n",
    "for q_dict in questions_data:\n",
    "    question = q_dict[\"question\"]\n",
    "    answer = q_dict[\"answer\"]\n",
    "\n",
    "    # Generate answer using the language model\n",
    "    prompt = f\"[INST]{question} \\n Fill the blank: \\n [/INST]\"\n",
    "    generated_answer = pipe(prompt)[0]['generated_text']\n",
    "    print(f\"Output: {generated_answer}\")\n",
    "    generated_answers_fb.append(generated_answer)\n",
    "    \n",
    "    generated_answer = re.search(r'\\[/INST\\]\\s+(.*)', generated_answer).group(1).strip()\n",
    "    if \"Sure\" in generated_answer:\n",
    "        generated_lines = generated_answer.split('\\n')\n",
    "        if len(generated_lines) > 1:\n",
    "            generated_answer = '\\n'.join(generated_lines[1:])  # Skip the first line\n",
    "    # generated_answers_fb.append(generated_answer)\n",
    "    # print(f\"Generated answer: {generated_answer}\")\n",
    "    # Find the position of the placeholder in the first string\n",
    "    placeholder_position = question.find(\"________\")\n",
    "\n",
    "    # Extract the content filled in the placeholder\n",
    "    filled_content = generated_answer[placeholder_position:placeholder_position + len(\"autonomous systems (ASes)\")]\n",
    "    filled_answers.append(filled_content)\n",
    "    n_question += 1\n",
    "    print(f\"Filled content: {filled_content}\")\n",
    "    print(f\"---------------------{n_question}-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"/home/hb/LLM-research/evaluation/bgp_test_QA_val.json\" \n",
    "\n",
    "with open(input_file_path, \"r\") as input_file:\n",
    "    questions_data = json.load(input_file)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "generated_answers_qa = []\n",
    "\n",
    "n_question = 0\n",
    "for q_dict in questions_data:\n",
    "    n_question += 1\n",
    "    question = q_dict[\"question\"]\n",
    "    # Generate answer using the language model\n",
    "    prompt = f\"[INST]{question}[/INST]\"\n",
    "    generated_answer = pipe(prompt)[0]['generated_text']\n",
    "    print(f\"Output: {generated_answer}\")\n",
    "    generated_answers_qa.append(generated_answer)\n",
    "    print(f\"---------------------{n_question}-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLaMA2-7B:\n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 48.57%\n",
    "    Correct answers: 17\n",
    "    Incorrect answers: 18\n",
    "\n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 51.43%\n",
    "    Correct answers: 18\n",
    "    Incorrect answers: 17\n",
    "\n",
    "### LLaMA2-13B:\n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 60.00%\n",
    "    Correct answers: 21\n",
    "    Incorrect answers: 14\n",
    "\n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 71.43%\n",
    "    Correct answers: 25\n",
    "    Incorrect answers: 10\n",
    "\n",
    "### BGPtest9- cosine - `Best`:\n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 68.57%\n",
    "    Correct answers: 24\n",
    "    Incorrect answers: 11\n",
    "\n",
    "`Multiple Choice v1`:\n",
    "    - Accuracy: 82.86%\n",
    "    - Correct answers: 29\n",
    "    - Incorrect answers: 6\n",
    "\n",
    "### BGPtest10- constant:\n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 62.86%\n",
    "    Correct answers: 22\n",
    "    Incorrect answers: 13\n",
    "\n",
    "`Multiple Choice v1`:\n",
    "    - Accuracy: 71.43%\n",
    "    - Correct answers: 25\n",
    "    - Incorrect answers: 10\n",
    "\n",
    "`Fill the blank v1`:\n",
    "    - Accuracy: 88.57%\n",
    "    - Correct answers: 31\n",
    "    - Incorrect answers: 4\n",
    "\n",
    "`Fill the blank v2`:\n",
    "    - Accuracy: 91.42%\n",
    "    - Correct answers: 33\n",
    "    - Incorrect answers: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGP-LLaMA-1-cosine-2k-alpha64:\n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 51.43%\n",
    "    Correct answers: 18\n",
    "    Incorrect answers: 17\n",
    "\n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 68.57%\n",
    "    Correct answers: 24\n",
    "    Incorrect answers: 11\n",
    "\n",
    "### BGP-LLaMA-2-cosine-20k-alpha16:\n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 68.57%\n",
    "    Correct answers: 24\n",
    "    Incorrect answers: 11\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 54.29%\n",
    "    Correct answers: 19\n",
    "    Incorrect answers: 16\n",
    "\n",
    "\n",
    "### BGP-LLaMA-2(combined)-cosine-20k-alpha16:\n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 80.00%\n",
    "    Correct answers: 28\n",
    "    Incorrect answers: 7\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "\n",
    "    Accuracy: 65.71%\n",
    "    Correct answers: 23\n",
    "    Incorrect answers: 12\n",
    "\n",
    "### BGP-LLaMA-13b-2iter-40k-cutoff-max-2048: ??\n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 77.14%\n",
    "    Correct answers: 27\n",
    "    Incorrect answers: 8\n",
    "\n",
    "    \n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 62.86%\n",
    "    Correct answers: 22\n",
    "    Incorrect answers: 13\n",
    "\n",
    "`PyBGPStream`: not pass\n",
    "\n",
    "### BGP-LLaMA-13b-3-30k-cutoff-max-2048:\n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 57.14%\n",
    "    Correct answers: 20\n",
    "    Incorrect answers: 15\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "    Accuracy: 54%\n",
    "\n",
    "`PyBGPStream`: pass\n",
    "\n",
    "### BGP-LLaMA-13b-50k-cutoff-max-2048: \n",
    "`Multiple Choice v1`:\n",
    "    Accuracy: 60.00%\n",
    "    Correct answers: 21\n",
    "    Incorrect answers: 14\n",
    "`PyBGPStream`: pass\n",
    "\n",
    "### BGP-LLaMA-13b-20k-cutoff-max-2048: \n",
    "`Multiple Choice v1`\n",
    "    Accuracy: 48.57%\n",
    "    Correct answers: 17\n",
    "    Incorrect answers: 18\n",
    "`PyBGPStream`: pass\n",
    "\n",
    "\n",
    "### BGP-LLaMA-13b-20k-cutoff-1024-max-none:\n",
    "`Multiple Choice v1`\n",
    "    Accuracy: 45.71%\n",
    "    Correct answers: 16\n",
    "    Incorrect answers: 19\n",
    "`PyBGPStream`: pass\n",
    "\n",
    "\n",
    "### BGP-LLaMA-13b-30k-cutoff-1024-max-none:\n",
    "`Multiple Choice v1`\n",
    "Accuracy: 62.86%\n",
    "Correct answers: 22\n",
    "Incorrect answers: 13\n",
    "\n",
    "`PyBGPStream`: pass\n",
    "\n",
    "\n",
    "### BGP-LLaMA-13b-40k-cutoff-1024-max-none:\n",
    "`Multiple Choice v1`\n",
    "    Accuracy: 48.57%\n",
    "    Correct answers: 17\n",
    "    Incorrect answers: 18\n",
    "`PyBGPStream`: not pass\n",
    "\n",
    "### BGP-LLaMA-13b-50k-cutoff-1024-max-none:\n",
    "`Multiple Choice v1`\n",
    "    Accuracy: 40.00%\n",
    "    Correct answers: 14\n",
    "    Incorrect answers: 21\n",
    "`PyBGPStream`: not pass\n",
    "\n",
    "\n",
    "### BGP-LLaMA26k-13b-30k-cutoff-1024-max-None:\n",
    "`Multiple Choice v1`: not pass\n",
    "\n",
    "`PyBGPStream`: pass\n",
    "\n",
    "### BGP-LLaMA26k-13b-20k-cutoff-1024-max-None:\n",
    "`Multiple Choice v1`:\n",
    "Incorrect\n",
    "Accuracy: 37.14%\n",
    "Correct answers: 13\n",
    "Incorrect answers: 22\n",
    "`PyBGPStream`: pass\n",
    "\n",
    "### BGP-LLaMA26k-13b-10k-cutoff-1024-max-2048\n",
    "`Multiple Choice v1`:\n",
    "Accuracy: 62.86%\n",
    "Correct answers: 22\n",
    "Incorrect answers: 13\n",
    "`PyBGPStream`: pass (better than previous)\n",
    "\n",
    "\n",
    "### BGP-LLaMA26k-13b-5k-cutoff-1024-max-2048 - `Best Combined`\n",
    "`Multiple Choice v1`:\n",
    "Accuracy: 82.86%\n",
    "Correct answers: 29\n",
    "Incorrect answers: 6\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "Accuracy: 71.43%\n",
    "Correct answers: 25\n",
    "Incorrect answers: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGP-LLaMA-knowledge-20k-cutoff-1024-max-2048\n",
    "`Multiple Choice v1`:\n",
    "Accuracy: 62.86%\n",
    "Correct answers: 22\n",
    "Incorrect answers: 13\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "Accuracy: 48.57%\n",
    "Correct answers: 17\n",
    "Incorrect answers: 18\n",
    "\n",
    "### BGP-LLaMA-knowledge-5k-cutoff-1024-max-2048 `best knowledge`\n",
    "`Multiple Choice v1`:\n",
    "Accuracy: 85.71%\n",
    "Correct answers: 30\n",
    "Incorrect answers: 5\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "Accuracy: 71.43%\n",
    "Correct answers: 25\n",
    "Incorrect answers: 10\n",
    "\n",
    "### BGP-LLaMA-knowledge-3k-cutoff-1024-max-2048\n",
    "`Multiple Choice v1`:\n",
    "Accuracy: 82.86%\n",
    "Correct answers: 29\n",
    "Incorrect answers: 6\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "Accuracy: 74.29%\n",
    "Correct answers: 26\n",
    "Incorrect answers: 9\n",
    "\n",
    "### BGP-LLaMA-knowledge-2k-cutoff-1024-max-2048\n",
    "`Multiple Choice v1`:\n",
    "Accuracy: 82.86%\n",
    "Correct answers: 29\n",
    "Incorrect answers: 6\n",
    "\n",
    "`Multiple Choice v2`:\n",
    "Accuracy: 71.43%\n",
    "Correct answers: 25\n",
    "Incorrect answers: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
