{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from typing import List\n",
    "import torch\n",
    "from torch import cuda, bfloat16\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5daf6a6eeea40eca7604d0130a0c2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865b13c185aa42a09052703d79e8e3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419963b9a5114576aee7d577ceb638f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e1b221aae848c38a22d494c8f967b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b298f22c15bc4b848090b14edd8bc323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc273706bbb543c99ac0d6dc65954dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c6fc6abcf4be3a2ab55b27ce160cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_id = 'hyonbokan/llama_5G_pcap_5kEpoch'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Need auth token for these\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b46b12005740938617a07697abb724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1debfaf11c3244daa0dc7083dda533e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15438ebe943a4c5d93b697d67fef5f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347bedf2fac44c75a7fe7fd56646174a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Given a n3.pcap file containing network traffic data, create a Python script to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Store this data in a pandas DataFrame and display it. [/INST]  Sure, here is a Python script that processes a PCAP file containing 5G network traffic and extracts the source IP, destination IP, source port, destination port, and the raw payload data for each packet:\n",
      "\n",
      "import pandas as pd\n",
      "import scapy\n",
      "\n",
      "# Load the PCAP file\n",
      "packets = scapy.rdpcap('5g_traffic.pcap')\n",
      "\n",
      "# Initialize an empty DataFrame\n",
      "df = pd.DataFrame(columns=['Source IP', 'Destination IP', 'Source Port', 'Destination Port', 'Payload'])\n",
      "\n",
      "# Iterate over all the packets\n",
      "for packet in packets:\n",
      "\n",
      "    # Extract the source and destination IPs\n",
      "    src_ip = packet[IP].src\n",
      "    dst_ip = packet[IP].dst\n",
      "\n",
      "    # Extract the source and destination ports\n",
      "    src_port = packet[TCP].sport if TCP in packet else packet[UDP].sport\n",
      "    dst_port = packet[TCP].dport if TCP in packet else packet[UDP].dport\n",
      "\n",
      "    # Extract the payload\n",
      "    payload = packet[Raw].load\n",
      "\n",
      "    # Append the data to the DataFrame\n",
      "    df = df.append({'Source IP': src_ip, 'Destination IP': dst_ip, 'Source Port': src_port, 'Destination Port': dst_port, 'Payload': payload}, ignore_index=True)\n",
      "\n",
      "# Display the DataFrame\n",
      "df\n",
      "\n",
      "Out[4]:\n",
      "   Source IP    Destination IP    Source Port    Destination Port  Payload\n",
      "0 192.168.1.1   192.168.2.1   255       0\n",
      "1 192.168.2.1   192.168.1.1   6      b'Hello world!'\n",
      "2 192.168.2.1   192.168.2.1   255       0\n",
      "3 192.168.2.1   192.168.1.1   6      b'Hello world!'\n",
      "4 192.168.1.1   192.168.2.1   255       0\n",
      "5 192.168.2.1   192.168.2.1   255       0\n",
      "6 192.168.2.1   192.168.1.1   6      b'Hello world!'\n",
      "7 192.168.1.1   192.168.2.1   255       0\n",
      "8 192.168.2.1   192.168.2.1   255\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Given a n3.pcap file containing network traffic data, create a Python script to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Store this data in a pandas DataFrame and display it.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Generate Python code to calculate and visualize 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns. [/INST]  Sure! Here is an example of how you can use Python to calculate and visualize 5G network performance KPIs from a CSV file:\n",
      "\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Load the CSV file\n",
      "df = pd.read_csv('5G_Infrastructure/demand_driven_postcode_data_results.csv')\n",
      "\n",
      "# Identify relevant columns\n",
      "capacity_columns = [col for col in df.columns if 'capacity' in col.lower()]\n",
      "cost_columns = [col for col in df.columns if 'cost' in col.lower()]\n",
      "area_columns = [col for col in df.columns if 'area' in col.lower()]\n",
      "numpoints_columns = [col for col in df.columns if 'numpoints' in col.lower()]\n",
      "\n",
      "# Calculate total network capacity\n",
      "total_capacity = df[capacity_columns].sum(axis=1)\n",
      "\n",
      "# Calculate capacity per area\n",
      "capacity_per_area = total_capacity / df['area']\n",
      "\n",
      "# Calculate capacity per point\n",
      "capacity_per_point = total_capacity / df['numpoints']\n",
      "\n",
      "# Calculate cost per capacity\n",
      "cost_per_capacity = df[cost_columns].mean(axis=1) / total_capacity\n",
      "\n",
      "# Calculate cost per area\n",
      "cost_per_area = cost_per_capacity * df['area']\n",
      "\n",
      "# Calculate surplus per area\n",
      "surplus_per_area = total_capacity - cost_per_area\n",
      "\n",
      "# Plot the results\n",
      "fig, ax = plt.subplots(figsize=(10, 6))\n",
      "ax.plot(df['area'], total_capacity, label='Total Network Capacity')\n",
      "ax.plot(df['area'], capacity_per_area, label='Capacity per Area')\n",
      "ax.plot(df['area'], capacity_per_point, label='Capacity per Point')\n",
      "ax.plot(df['area'], cost_per_area, label='Cost per Area')\n",
      "ax.plot(df['area'], surplus_per_area, label='Surplus per Area')\n",
      "ax.set_xlabel('Area (km²)')\n",
      "ax.set_ylabel('Capacity (Mbps)')\n",
      "ax.legend()\n",
      "plt.show()\n",
      "\n",
      "# Output the results\n",
      "print('Total Network Capacity: ', total_capacity)\n",
      "print('Capacity per Area: ', capacity_per_area)\n",
      "print('Capacity per Point: ', capacity_per_point)\n",
      "print('Cost per Area: ', cost_per_area)\n",
      "print('Surplus per Area: ', surplus_per_area)\n",
      "print('\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Generate Python code to calculate and visualize 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "input_file_path = \"/home/hb/LLM-research/evaluation/5G/5G_analysis_multi_choice_v2.json\" \n",
    "\n",
    "with open(input_file_path, \"r\") as input_file:\n",
    "    questions_data = json.load(input_file)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=128)\n",
    "\n",
    "generated_answers = []\n",
    "ground_truth = [q_dict[\"answer\"] for q_dict in questions_data]\n",
    "n_question = 0\n",
    "\n",
    "for q_dict in questions_data:\n",
    "    question = q_dict[\"question\"]\n",
    "    options = q_dict[\"options\"]\n",
    "    \n",
    "    # Construct prompt with question and options\n",
    "    prompt = f\"Choose the correct answer. {question}\\n\" + \"\\n\".join(options)\n",
    "    # print(prompt)\n",
    "    \n",
    "    # Generate answer using the language model\n",
    "    generated_answer = pipe(prompt)[0]['generated_text']\n",
    "    print(f\"Generated Answer: {generated_answer}\")\n",
    "    \n",
    "    # Parse the generated answer\n",
    "    answer_lines = generated_answer.splitlines()\n",
    "    parsed_answer = \"\"\n",
    "    for line in answer_lines:\n",
    "            if line.startswith(\"Answer: \") or line.startswith(\"Correct answer: \"):\n",
    "                match = re.search(r'\\b(\\w)[\\)-]', line)\n",
    "                if match is not None:\n",
    "                    parsed_answer = match.group(1)\n",
    "                    print(f\"Parsed_answer: {parsed_answer}\")\n",
    "                    break\n",
    "                else:\n",
    "                    parsed_answer = \"Couldn't parse the answer\"\n",
    "                    print(f\"Parsed_answer: {parsed_answer}\")\n",
    "    generated_answers.append(parsed_answer)\n",
    "    n_question += 1\n",
    "    print(f\"----------------{n_question}-----------------\")\n",
    "print(generated_answers)\n",
    "\n",
    "\n",
    "total_questions = len(questions_data)\n",
    "correct_answers = 0\n",
    "\n",
    "for ground_answer, generated_answer in zip(ground_truth, generated_answers):\n",
    "    if generated_answer.lower() == ground_answer.lower():\n",
    "        print(\"Correct\")\n",
    "        correct_answers += 1\n",
    "    else:\n",
    "        print(f\"GPT answer: {generated_answer}. Correct answer: {ground_answer}\")\n",
    "        print(\"Incorrect\")\n",
    "\n",
    "accuracy = (correct_answers / total_questions) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Correct answers: {correct_answers}\")\n",
    "print(f\"Incorrect answers: {total_questions - correct_answers}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
