{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from typing import List\n",
    "import torch\n",
    "from torch import cuda, bfloat16\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84566388152b48ed8b8a4f8f0814d99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/myenv/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_id = 'hyonbokan/mobile_llama_10k'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Need auth token for these\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Given a n3.pcap file containing network traffic data, create a Python script using Scapy to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Impletent try-except blocks for errors if expected layers IP, TCP/UDP, Raw. Store this data in a pandas DataFrame and display it. [/INST]  Sure! Here is a Python script using Scapy to process a n3.pcap file and extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP:\n",
      "```\n",
      "import pandas as pd\n",
      "import scapy.all as scapy\n",
      "\n",
      "# Load the PCAP file\n",
      "def load_pcap(file_path):\n",
      "    try:\n",
      "        # Read the PCAP file\n",
      "        packets = rdpcap(file_path)\n",
      "        return packets\n",
      "    except Exception as e:\n",
      "        print(f\"An error occurred: {str(e)}\")\n",
      "        return None\n",
      "\n",
      "# Extract IP, TCP/UDP, and Raw layers\n",
      "def extract_layers(packets):\n",
      "    layer_data = []\n",
      "    for packet in packets:\n",
      "        # Extract IP layer\n",
      "        src_ip = packet[IP].src\n",
      "        dst_ip = packet[IP].dst\n",
      "        # Extract TCP/UDP layer\n",
      "        src_port = packet[TCP].sport if TCP in packet else packet[UDP].sport\n",
      "        dst_port = packet[TCP].dport if TCP in packet else packet[UDP].dport\n",
      "        # Extract Raw layer\n",
      "        raw_payload = packet[Raw].load\n",
      "        # Append the data to the list\n",
      "        layer_data.append([src_ip, dst_ip, src_port, dst_port, raw_payload])\n",
      "    return layer_data\n",
      "\n",
      "# Create a DataFrame from the layer data\n",
      "def to_dataframe(layer_data):\n",
      "    df = pd.DataFrame(layer_data, columns=['Source IP', 'Destination IP', 'Source Port', 'Destination Port', 'Raw Payload'])\n",
      "    return df\n",
      "\n",
      "# Main function to process the PCAP file\n",
      "def process_pcap(file_path):\n",
      "    packets = load_pcap(file_path)\n",
      "    layer_data = extract_layers(packets)\n",
      "    df = to_dataframe(layer_data)\n",
      "    print(df.head())\n",
      "\n",
      "# Specify the PCAP file path\n",
      "pcap_file = '/home/dnlab/Data-B/5G_LLM/5G_data/n3.pcap'\n",
      "process_pcap(pcap_file)\n",
      "```\n",
      "This script loads the PCAP file using the `rdpcap` function of Scapy, extracts the IP, TCP/UDP, and Raw layers using Scapy's built-in functions, and then creates a pandas DataFrame from the extracted data. Finally, it prints the DataFrame.\n",
      "\n",
      "Note that the script uses try-except blocks to handle any errors that may occur during the processing of the PCAP file. This ensures that the script continues to run smooth\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Given a n3.pcap file containing network traffic data, create a Python script using Scapy to process the PCAP. The script should extract the source IP, destination IP, source port, destination port, and the raw payload data for each packet in the PCAP. Impletent try-except blocks for errors if expected layers IP, TCP/UDP, Raw. Store this data in a pandas DataFrame and display it.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Specify the PCAP file path\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mprocess_pcap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/hb/5G_dataset/n3_example.pcap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mprocess_pcap\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_pcap\u001b[39m(file_path):\n\u001b[1;32m     32\u001b[0m     packets \u001b[38;5;241m=\u001b[39m load_pcap(file_path)\n\u001b[0;32m---> 33\u001b[0m     packet_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_packet_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     df \u001b[38;5;241m=\u001b[39m to_dataframe(packet_data)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mextract_packet_info\u001b[0;34m(packets)\u001b[0m\n\u001b[1;32m     15\u001b[0m packet_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m packet \u001b[38;5;129;01min\u001b[39;00m packets:\n\u001b[0;32m---> 17\u001b[0m     source_ip \u001b[38;5;241m=\u001b[39m packet[\u001b[43mIP\u001b[49m]\u001b[38;5;241m.\u001b[39msrc\n\u001b[1;32m     18\u001b[0m     dest_ip \u001b[38;5;241m=\u001b[39m packet[IP]\u001b[38;5;241m.\u001b[39mdst\n\u001b[1;32m     19\u001b[0m     src_port \u001b[38;5;241m=\u001b[39m packet[TCP]\u001b[38;5;241m.\u001b[39msport \u001b[38;5;28;01mif\u001b[39;00m TCP \u001b[38;5;129;01min\u001b[39;00m packet \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IP' is not defined"
     ]
    }
   ],
   "source": [
    "import scapy.all as scapy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the PCAP file\n",
    "def load_pcap(file_path):\n",
    "    try:\n",
    "        packets = scapy.rdpcap(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "    return packets\n",
    "\n",
    "# Extract packet information\n",
    "def extract_packet_info(packets):\n",
    "    packet_data = []\n",
    "    for packet in packets:\n",
    "        source_ip = packet[IP].src\n",
    "        dest_ip = packet[IP].dst\n",
    "        src_port = packet[TCP].sport if TCP in packet else 0\n",
    "        dst_port = packet[TCP].dport if TCP in packet else 0\n",
    "        payload = packet[Raw].load if Raw in packet else b''\n",
    "        packet_data.append([source_ip, dest_ip, src_port, dst_port, payload])\n",
    "    return packet_data\n",
    "\n",
    "# Create a DataFrame from the packet data\n",
    "def to_dataframe(packet_data):\n",
    "    df = pd.DataFrame(packet_data, columns=['Source IP', 'Destination IP', 'Source Port', 'Destination Port', 'Raw Payload'])\n",
    "    return df\n",
    "\n",
    "# Main function to process the PCAP file\n",
    "def process_pcap(file_path):\n",
    "    packets = load_pcap(file_path)\n",
    "    packet_data = extract_packet_info(packets)\n",
    "    df = to_dataframe(packet_data)\n",
    "    print(df.head())\n",
    "\n",
    "# Specify the PCAP file path\n",
    "process_pcap('/home/hb/5G_dataset/n3_example.pcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Layer [TCP] not found\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scapy.all as scapy\n",
    "\n",
    "# Specify the PCAP file path\n",
    "pcap_file = '/home/hb/5G_dataset/n3_example.pcap'\n",
    "\n",
    "try:\n",
    "    packets = scapy.rdpcap(pcap_file)  # Read the PCAP file\n",
    "\n",
    "    # Initialize an empty DataFrame\n",
    "    df = pd.DataFrame(columns=['Source IP', 'Destination IP', 'Source Port', 'Destination Port', 'Raw Payload'])\n",
    "\n",
    "    for packet in packets:\n",
    "        # Extract the source IP and destination IP\n",
    "        source_ip = packet[IP].src\n",
    "        destination_ip = packet[IP].dst\n",
    "\n",
    "        # Extract the source port and destination port\n",
    "        source_port = packet[TCP].sport\n",
    "        destination_port = packet[TCP].dport\n",
    "\n",
    "        # Extract the raw payload data\n",
    "        payload = packet.show()\n",
    "\n",
    "        # Add the data to the DataFrame\n",
    "        df = df.append({'Source IP': source_ip, 'Destination IP': destination_ip, 'Source Port': source_port, 'Destination Port': destination_port, 'Raw Payload': payload}, ignore_index=True)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Generate Python code to calculate 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns. [/INST]  Here is a Python script that calculates the 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area.\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Load the CSV file\n",
      "df = pd.read_csv('5G_Infrastructure/demand_driven_postcode_data_results.csv')\n",
      "\n",
      "# Identify relevant columns\n",
      "capacity_columns = [col for col in df.columns if 'capacity' in col.lower()]\n",
      "cost_columns = [col for col in df.columns if 'cost' in col.lower()]\n",
      "area_columns = [col for col in df.columns if 'area' in col.lower()]\n",
      "numpoints_columns = [col for col in df.columns if 'numpoints' in col.lower()]\n",
      "\n",
      "# Calculate Total Network Capacity\n",
      "total_capacity = df[capacity_columns].sum(axis=1)\n",
      "\n",
      "# Calculate Capacity per Area\n",
      "capacity_per_area = total_capacity / df[area_columns].sum(axis=1)\n",
      "\n",
      "# Calculate Capacity per Point\n",
      "capacity_per_point = total_capacity / df[numpoints_columns].sum(axis=1)\n",
      "\n",
      "# Calculate Cost per Capacity\n",
      "cost_per_capacity = df[cost_columns] / total_capacity\n",
      "\n",
      "# Calculate Cost per Area\n",
      "cost_per_area = df[cost_columns] / df[area_columns].sum(axis=1)\n",
      "\n",
      "# Calculate Surplus per Area\n",
      "surplus_per_area = total_capacity - df[cost_columns].sum(axis=1)\n",
      "\n",
      "# Print the results\n",
      "print(\"Total Network Capacity: \", total_capacity)\n",
      "print(\"Capacity per Area: \", capacity_per_area)\n",
      "print(\"Capacity per Point: \", capacity_per_point)\n",
      "print(\"Cost per Capacity: \", cost_per_capacity)\n",
      "print(\"Cost per Area: \", cost_per_area)\n",
      "print(\"Surplus per Area: \", surplus_per_area)\n",
      "\n",
      "# Output\n",
      "Total Network Capacity:  10000.0\n",
      "Capacity per Area:  10000.0\n",
      "Capacity per Point:  10000.0\n",
      "Cost per Capacity:  0.0\n",
      "Cost per Area:  0.0\n",
      "Surplus per Area:  0.0\n",
      "\n",
      "Total Network Capacity:  10000.0\n",
      "Capacity per Area:  10000.0\n",
      "Capacity per Point:  10000.0\n",
      "Cost per Capacity:  0.0\n",
      "Cost per Area:  0.0\n",
      "Surplus per Area:  0.0\n",
      "\n",
      "Total Network Capacity:  10000.0\n",
      "Capacity per Area:  10000.0\n",
      "Capacity per Point:  10000.0\n",
      "Cost per Capacity:  0.0\n",
      "Cost per Area:  0.0\n",
      "Surplus per Area:  0.0\n",
      "\n",
      "Total Network Capacity:  10000.0\n",
      "Capacity per Area:  10000.0\n",
      "Capacity per Point:  10000.0\n",
      "Cost per Capacity:  0.0\n",
      "Cost per Area:  0.0\n",
      "Surplus per Area:  0.0\n",
      "\n",
      "Total Network Capacity:  10000.0\n",
      "Capacity per Area:  10000.0\n",
      "Capacity per Point:  10000.0\n",
      "Cost per Capacity:  0.0\n",
      "Cost per Area:  0.0\n",
      "Surplus per Area:  0.0\n",
      "\n",
      "Total Network Capacity:  10000.0\n",
      "Capacity per Area:  10000.0\n",
      "Capacity per Point:  10000.0\n",
      "Cost per Capacity:  0.0\n",
      "Cost per Area:  0.0\n",
      "Surplus per Area:  0.0\n",
      "\n",
      "Total\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Generate Python code to calculate 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Perform BGP analysis using PyBGPStream and detect anomalies in AS path lengths for IPv4 prefixes over two time periods: from January 15, 2020, 15:00 to January 15, 2020, 17:00, and January 18, 2020, 12:00 to January 18, 2020, 13:00. [/INST]  Sure! Here's an example of how you could perform BGP analysis using PyBGPStream and detect anomalies in AS path lengths for IPv4 prefixes over two time periods:\n",
      "\n",
      "1. Install PyBGPStream:\n",
      "```\n",
      "pip install pybgpstream\n",
      "```\n",
      "2. Initialize PyBGPStream:\n",
      "```\n",
      "stream = pybgpstream.BGPStream(\n",
      "    from_time=\"2020-01-15 15:00:00\",\n",
      "    until_time=\"2020-01-15 17:00:00\",\n",
      "    collectors=[\"rrc00\"],\n",
      "    record_type=\"updates\",\n",
      "    filter=\"ipversion 4\"\n",
      ")\n",
      "```\n",
      "3. Initialize a list to store the AS path lengths:\n",
      "```\n",
      "as_path_lengths = []\n",
      "```\n",
      "4. Loop through the stream records:\n",
      "```\n",
      "for rec in stream.records():\n",
      "    for elem in rec:\n",
      "        if elem.type == \"A\":\n",
      "            as_path = elem.fields[\"as-path\"].split()\n",
      "            as_path_length = len(as_path)\n",
      "            as_path_lengths.append(as_path_length)\n",
      "```\n",
      "5. Calculate the average AS path length for each time period:\n",
      "```\n",
      "avg_as_path_length_15_17 = sum(as_path_lengths) / len(as_path_lengths)\n",
      "avg_as_path_length_18_13 = sum(as_path_lengths) / len(as_path_lengths)\n",
      "```\n",
      "6. Detect anomalies in AS path lengths:\n",
      "```\n",
      "anomalies_15_17 = []\n",
      "for i in range(len(as_path_lengths)):\n",
      "    if as_path_lengths[i] > avg_as_path_length_15_17 + 2:\n",
      "        anomalies_15_17.append(as_path_lengths[i])\n",
      "\n",
      "anomalies_18_13 = []\n",
      "for i in range(len(as_path_lengths)):\n",
      "    if as_path_lengths[i] > avg_as_path_length_18_13 + 2:\n",
      "        anomalies_18_13.append(as_path_lengths[i])\n",
      "```\n",
      "7. Visualize the results:\n",
      "```\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "plt.plot(as_path_lengths, label=\"Average AS Path Length\")\n",
      "plt.scatter(anomalies_1\n"
     ]
    }
   ],
   "source": [
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Perform BGP analysis using PyBGPStream and detect anomalies in AS path lengths for IPv4 prefixes over two time periods: from January 15, 2020, 15:00 to January 15, 2020, 17:00, and January 18, 2020, 12:00 to January 18, 2020, 13:00.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=718)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Pcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scapy.all import *\n",
    "\n",
    "# Specify the PCAP file path\n",
    "pcap_file = '5G_data/n3_example.pcap'\n",
    "\n",
    "try:\n",
    "    packets = rdpcap(pcap_file)  # Read the PCAP file\n",
    "    print(f\"Total packets in the capture: {len(packets)}\\n\")\n",
    "\n",
    "    # Create a list to store packet data\n",
    "    packet_data = []\n",
    "\n",
    "    for packet in packets:\n",
    "        src_ip, dst_ip, src_port, dst_port, raw_data = '', '', '', '', ''\n",
    "        \n",
    "        if IP in packet:\n",
    "            print(\"IP found\")\n",
    "            # Extract IP information\n",
    "            src_ip = packet[IP].src\n",
    "            dst_ip = packet[IP].dst\n",
    "\n",
    "        if TCP in packet:\n",
    "            print(\"TCP found\")\n",
    "            # Extract TCP information\n",
    "            src_port = packet[TCP].sport\n",
    "            dst_port = packet[TCP].dport\n",
    "\n",
    "        if Raw in packet:\n",
    "            print(\"Raw found\")\n",
    "            # Extract and append raw data (payload)\n",
    "            raw_data = packet[Raw].load\n",
    "        packet_data.append([src_ip, dst_ip, src_port, dst_port, raw_data])\n",
    "    \n",
    "    # Create a DataFrame from the packet data\n",
    "    df = pd.DataFrame(packet_data, columns=['Source IP', 'Destination IP', 'Source Port', 'Destination Port', 'Raw Data'])\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    display(df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total packets in the capture: 92\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Source MAC</th>\n",
       "      <th>Destination MAC</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Packet Type</th>\n",
       "      <th>Length</th>\n",
       "      <th>Raw Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1615905754.602072</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1615905754.603009</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%RT\\x00\\x85\\x01\\x10\\x05\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1615905754.604011</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%RT\\x00\\x85\\x01\\x10\\x05\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1615905754.605010</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1615905754.606004</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1615905754.653013</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%\\x07\\x17\\x00\\x85\\x01\\x10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1615905754.653530</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>61458</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x85\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1615905754.654010</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1615905754.654535</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>61458</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x85\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1615905754.655008</td>\n",
       "      <td>52:54:00:e2:36:87</td>\n",
       "      <td>40:de:ad:d9:ed:d9</td>\n",
       "      <td>172.16.12.2</td>\n",
       "      <td>10.200.11.70</td>\n",
       "      <td>2152</td>\n",
       "      <td>2152</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;class 'scapy.layers.l2.Ether'&gt;</td>\n",
       "      <td>936</td>\n",
       "      <td>b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp         Source MAC    Destination MAC     Source IP  \\\n",
       "0   1615905754.602072  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "1   1615905754.603009  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "2   1615905754.604011  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "3   1615905754.605010  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "4   1615905754.606004  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "..                ...                ...                ...           ...   \n",
       "87  1615905754.653013  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "88  1615905754.653530  40:de:ad:d9:ed:d9  52:54:00:e2:36:87  10.200.11.70   \n",
       "89  1615905754.654010  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "90  1615905754.654535  40:de:ad:d9:ed:d9  52:54:00:e2:36:87  10.200.11.70   \n",
       "91  1615905754.655008  52:54:00:e2:36:87  40:de:ad:d9:ed:d9   172.16.12.2   \n",
       "\n",
       "   Destination IP  Source Port  Destination Port  Protocol  \\\n",
       "0    10.200.11.70         2152              2152        17   \n",
       "1    10.200.11.70         2152              2152        17   \n",
       "2    10.200.11.70         2152              2152        17   \n",
       "3    10.200.11.70         2152              2152        17   \n",
       "4    10.200.11.70         2152              2152        17   \n",
       "..            ...          ...               ...       ...   \n",
       "87   10.200.11.70         2152              2152        17   \n",
       "88    172.16.12.2        61458              2152        17   \n",
       "89   10.200.11.70         2152              2152        17   \n",
       "90    172.16.12.2        61458              2152        17   \n",
       "91   10.200.11.70         2152              2152        17   \n",
       "\n",
       "                        Packet Type  Length  \\\n",
       "0   <class 'scapy.layers.l2.Ether'>     936   \n",
       "1   <class 'scapy.layers.l2.Ether'>     936   \n",
       "2   <class 'scapy.layers.l2.Ether'>     936   \n",
       "3   <class 'scapy.layers.l2.Ether'>     936   \n",
       "4   <class 'scapy.layers.l2.Ether'>     936   \n",
       "..                              ...     ...   \n",
       "87  <class 'scapy.layers.l2.Ether'>     936   \n",
       "88  <class 'scapy.layers.l2.Ether'>     936   \n",
       "89  <class 'scapy.layers.l2.Ether'>     936   \n",
       "90  <class 'scapy.layers.l2.Ether'>     936   \n",
       "91  <class 'scapy.layers.l2.Ether'>     936   \n",
       "\n",
       "                                             Raw Data  \n",
       "0   b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...  \n",
       "1   b'4\\xff\\x03v@\\x02\\x01%RT\\x00\\x85\\x01\\x10\\x05\\x...  \n",
       "2   b'4\\xff\\x03v@\\x02\\x01%RT\\x00\\x85\\x01\\x10\\x05\\x...  \n",
       "3   b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...  \n",
       "4   b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...  \n",
       "..                                                ...  \n",
       "87  b'4\\xff\\x03v@\\x02\\x01%\\x07\\x17\\x00\\x85\\x01\\x10...  \n",
       "88  b'4\\xff\\x03v\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x85\\x...  \n",
       "89  b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...  \n",
       "90  b'4\\xff\\x03v\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x85\\x...  \n",
       "91  b'4\\xff\\x03v@\\x02\\x01%\\x00\\x00\\x00\\x85\\x01\\x10...  \n",
       "\n",
       "[92 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scapy.all import *\n",
    "\n",
    "# Specify the PCAP file path\n",
    "pcap_file = '/home/hb/5G_dataset/n3_example.pcap'\n",
    "\n",
    "try:\n",
    "    packets = rdpcap(pcap_file)  # Read the PCAP file\n",
    "    print(f\"Total packets in the capture: {len(packets)}\\n\")\n",
    "\n",
    "    # Create a list to store packet data\n",
    "    packet_data = []\n",
    "\n",
    "    for packet in packets:\n",
    "        # Initialize all fields to extract\n",
    "        timestamp = packet.time\n",
    "        src_ip, dst_ip, src_port, dst_port, proto, length = '', '', '', '', '', len(packet)\n",
    "        src_mac, dst_mac, raw_data = '', '', ''\n",
    "        pkt_type = type(packet)\n",
    "        \n",
    "        # Ethernet Layer\n",
    "        if Ether in packet:\n",
    "            src_mac = packet[Ether].src\n",
    "            dst_mac = packet[Ether].dst\n",
    "\n",
    "        # IP Layer\n",
    "        if IP in packet:\n",
    "            src_ip = packet[IP].src\n",
    "            dst_ip = packet[IP].dst\n",
    "            proto = packet[IP].proto\n",
    "\n",
    "        # Transport Layer\n",
    "        if TCP in packet:\n",
    "            src_port = packet[TCP].sport\n",
    "            dst_port = packet[TCP].dport\n",
    "        elif UDP in packet:\n",
    "            src_port = packet[UDP].sport\n",
    "            dst_port = packet[UDP].dport\n",
    "        elif ICMP in packet:\n",
    "            src_port = 'N/A'\n",
    "            dst_port = 'N/A'\n",
    "            icmp_type = packet[ICMP].type\n",
    "            icmp_code = packet[ICMP].code\n",
    "        \n",
    "        # Raw Payload\n",
    "        if Raw in packet:\n",
    "            raw_data = packet[Raw].load\n",
    "\n",
    "        packet_data.append([timestamp, src_mac, dst_mac, src_ip, dst_ip, src_port, dst_port, proto, pkt_type, length, raw_data])\n",
    "    \n",
    "    # Create a DataFrame from the packet data\n",
    "    df = pd.DataFrame(packet_data, columns=['Timestamp', 'Source MAC', 'Destination MAC', 'Source IP', 'Destination IP', \n",
    "                                            'Source Port', 'Destination Port', 'Protocol', 'Packet Type', 'Length', 'Raw Data'])\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    display(df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
