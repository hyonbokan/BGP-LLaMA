{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "\n",
    "You are tasked with generating Python scripts that perform various BGP analysis tasks using the pybgpstream library. Please adhere to the following guidelines when writing the code:\n",
    "\n",
    "- Main Loop Processing:\n",
    "Do not use any filter attributes like stream.add_filter() or set filter parameters when initializing BGPStream.\n",
    "All filtering and processing should occur within the main loop where you iterate over records and elements.\n",
    "\n",
    "- Script Structure:\n",
    "Start by importing necessary libraries, including pybgpstream and any others required for the task (e.g., datetime, collections).\n",
    "Define a main function or functions that encapsulate the core logic.\n",
    "Include a __main__ block or a usage example to demonstrate how to run the script.\n",
    "\n",
    "- Key Processing Guidelines:\n",
    "* Time Format: Define the time range as strings in the following format: from_time = \"YYYY-MM-DD HH:MM:SS\"\n",
    "until_time = \"YYYY-MM-DD HH:MM:SS\"\n",
    "\n",
    "* Stream Initialization: Use these time parameters during BGPStream initialization:\n",
    "stream = pybgpstream.BGPStream(\n",
    "    from_time=from_time,\n",
    "    until_time=until_time,\n",
    "    record_type=\"updates\",\n",
    "    collectors=collectors\n",
    ")\n",
    "\n",
    "* Iterating Over Records and Elements:\n",
    "for rec in stream.records(): for elem in rec: Processing logic goes here\n",
    "\n",
    "* Accessing Element Attributes:\n",
    "Timestamp: elem_time = datetime.utcfromtimestamp(elem.time)\n",
    "\n",
    "Element Type (Announcement or Withdrawal): elem_type = elem.type 'A' for announcements, 'W' for withdrawals\n",
    "\n",
    "Fields Dictionary: fields = elem.fields\n",
    "\n",
    "Prefix: prefix = fields.get(\"prefix\") if prefix is None: continue\n",
    "\n",
    "AS Path: as_path_str = fields.get('as-path', \"\") as_path = as_path_str.split()\n",
    "\n",
    "Peer ASN and Collector: peer_asn = elem.peer_asn collector = rec.collector\n",
    "\n",
    "Communities: communities = fields.get('communities', [])\n",
    "\n",
    "* Filtering Logic Within the Loop:\n",
    "Filtering for a Specific ASN in AS Path: target_asn = '64500' if target_asn not in as_path: continue\n",
    "\n",
    "Filtering for Specific Prefixes: target_prefixes = ['192.0.2.0/24', '198.51.100.0/24'] if prefix not in target_prefixes: continue\n",
    "\n",
    "* Processing Key Values and Attributes:\n",
    "Counting Announcements and Withdrawals: if elem_type == 'A': announcements[prefix] += 1 elif elem_type == 'W': withdrawals[prefix] += 1\n",
    "\n",
    "Detecting AS Path Changes: if prefix in prefix_as_paths: if as_path != prefix_as_paths[prefix]: # AS path has changed prefix_as_paths[prefix] = as_path else: prefix_as_paths[prefix] = as_path\n",
    "\n",
    "Analyzing Community Attributes: for community in communities: community_str = f\"{community[0]}:{community[1]}\" community_counts[community_str] += 1\n",
    "\n",
    "Calculating Statistics (e.g., Average MED): med = fields.get('med') if med is not None: try: med_values.append(int(med)) except ValueError: pass\n",
    "\n",
    "* Detecting Hijacks: Compare the observed origin AS with the expected origin AS for target prefixes:\n",
    "expected_origins = {'192.0.2.0/24': '64500', '198.51.100.0/24': '64501'}\n",
    "if prefix in expected_origins:\n",
    "    observed_origin = as_path[-1] if as_path else None\n",
    "    expected_origin = expected_origins[prefix]\n",
    "    if observed_origin != expected_origin:\n",
    "        # Potential hijack detected\n",
    "        print(f\"Possible hijack detected for {prefix}: expected {expected_origin}, observed {observed_origin}\")\n",
    "\n",
    "* Detecting Outages:\n",
    "* Monitor for withdrawals of prefixes without re-announcements:\n",
    "Keep track of withdrawn prefixes and their timestamps\n",
    "if elem_type == 'W':\n",
    "    withdrawals[prefix] = elem_time\n",
    "elif elem_type == 'A':\n",
    "    # Remove from withdrawals if re-announced\n",
    "    if prefix in withdrawals:\n",
    "        del withdrawals[prefix]\n",
    "Check if prefix remains withdrawn for a certain period (e.g., 30 minutes)\n",
    "for prefix, withdrawal_time in list(withdrawals.items()):\n",
    "    if elem_time - withdrawal_time > timedelta(minutes=30):\n",
    "        # Outage detected for prefix\n",
    "        print(f\"Outage detected for {prefix} starting at {withdrawal_time}\")\n",
    "        del withdrawals[prefix]\n",
    "\n",
    "* Detecting MOAS (Multiple Origin AS) Conflicts: Monitor prefixes announced by multiple origin ASNs\n",
    "origin_asn = as_path[-1] if as_path else None\n",
    "if origin_asn:\n",
    "    if prefix not in prefix_origins:\n",
    "        prefix_origins[prefix] = set()\n",
    "    prefix_origins[prefix].add(origin_asn)\n",
    "    if len(prefix_origins[prefix]) > 1:\n",
    "        # MOAS conflict detected\n",
    "        origins = ', '.join(prefix_origins[prefix])\n",
    "        print(f\"MOAS conflict for {prefix}: announced by ASNs {origins}\")\n",
    "\n",
    "* Analyzing AS Path Prepending: Detect AS path prepending by identifying consecutive repeated ASNs in the AS path:\n",
    "last_asn = None\n",
    "consecutive_count = 1\n",
    "for asn in as_path:\n",
    "    if asn == last_asn:\n",
    "        consecutive_count += 1\n",
    "    else:\n",
    "        if consecutive_count > 1:\n",
    "            prepending_counts[last_asn] += consecutive_count - 1\n",
    "        consecutive_count = 1\n",
    "    last_asn = asn\n",
    "Check for prepending at the end of the path\n",
    "if consecutive_count > 1 and last_asn:\n",
    "    prepending_counts[last_asn] += consecutive_count - 1\n",
    "    \n",
    "* Handling IP Addresses and Prefixes:\n",
    "Validating and Parsing IP Prefixes: import ipaddress try: network = ipaddress.ip_network(prefix) except ValueError: continue\n",
    "\n",
    "Here is your tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Track AS-level trends over period from 13pm to 13:10 pm for AS3356. Summarize metrics like announcements and withdrawals with print statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import ipaddress\n",
    "\n",
    "def analyze_bgp_messages():\n",
    "    # Define the time range\n",
    "    from_time = \"2024-10-28 12:00:00\"\n",
    "    until_time = \"2024-10-29 12:00:00\"\n",
    "\n",
    "    # Specify the collector and target ASN\n",
    "    collectors = [\"rrc00\"]\n",
    "    target_asn = \"3356\"\n",
    "\n",
    "    # Initialize BGPStream\n",
    "    stream = pybgpstream.BGPStream(\n",
    "        from_time=from_time,\n",
    "        until_time=until_time,\n",
    "        record_type=\"updates\",\n",
    "        collectors=collectors\n",
    "    )\n",
    "\n",
    "    # Initialize counters and data structures\n",
    "    announcements = defaultdict(int)\n",
    "    withdrawals = defaultdict(int)\n",
    "    prefix_as_paths = {}\n",
    "    community_counts = defaultdict(int)\n",
    "    med_values = []\n",
    "\n",
    "    # Iterate over records and elements\n",
    "    for rec in stream.records():\n",
    "        for elem in rec:\n",
    "            # Process the element\n",
    "            elem_time = datetime.utcfromtimestamp(elem.time)\n",
    "            elem_type = elem.type  # 'A' for announcements, 'W' for withdrawals\n",
    "            fields = elem.fields\n",
    "\n",
    "            # Get the prefix\n",
    "            prefix = fields.get(\"prefix\")\n",
    "            if prefix is None:\n",
    "                continue  # Skip if prefix is not present\n",
    "\n",
    "            # Get the AS path\n",
    "            as_path_str = fields.get('as-path', \"\")\n",
    "            as_path = as_path_str.split()\n",
    "\n",
    "            # Check if the target ASN is in the AS path\n",
    "            if target_asn not in as_path:\n",
    "                continue  # Skip if target ASN is not in the AS path\n",
    "\n",
    "            # Get peer ASN and collector\n",
    "            peer_asn = elem.peer_asn\n",
    "            collector = rec.collector\n",
    "\n",
    "            # Count announcements and withdrawals\n",
    "            if elem_type == 'A':\n",
    "                announcements[prefix] += 1\n",
    "            elif elem_type == 'W':\n",
    "                withdrawals[prefix] += 1\n",
    "\n",
    "            # Detect AS path changes\n",
    "            if prefix in prefix_as_paths:\n",
    "                if as_path != prefix_as_paths[prefix]:  # AS path has changed\n",
    "                    prefix_as_paths[prefix] = as_path\n",
    "            else:\n",
    "                prefix_as_paths[prefix] = as_path\n",
    "\n",
    "            # Analyze community attributes\n",
    "            communities = fields.get('communities', [])\n",
    "            for community in communities:\n",
    "                community_str = f\"{community[0]}:{community[1]}\"\n",
    "                community_counts[community_str] += 1\n",
    "\n",
    "            # Calculate statistics (e.g., Average MED)\n",
    "            med = fields.get('med')\n",
    "            if med is not None:\n",
    "                try:\n",
    "                    med_values.append(int(med))\n",
    "                except ValueError:\n",
    "                    pass  # Ignore invalid MED values\n",
    "\n",
    "    # Calculate average MED if values exist\n",
    "    if med_values:\n",
    "        med_avg = sum(med_values) / len(med_values)\n",
    "        print(f\"Average MED: {med_avg:.2f}\")\n",
    "    # Print the results\n",
    "    print(\"Announcements:\", dict(announcements))\n",
    "    print(\"Withdrawals:\", dict(withdrawals))\n",
    "    print(\"Communities Count:\", dict(community_counts))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_bgp_messages()\n",
    "\n",
    "# ~35 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import ipaddress\n",
    "\n",
    "def analyze_bgp_messages():\n",
    "    # Define the time range\n",
    "    from_time = \"2024-10-28 12:00:00\"\n",
    "    until_time = \"2024-10-29 12:00:00\"\n",
    "\n",
    "    # Specify the collector and target ASN\n",
    "    collectors = [\"rrc00\"]\n",
    "    target_asn = \"3356\"\n",
    "\n",
    "    # Define filter to limit processing to relevant records only\n",
    "    filter_str = f\"collector rrc00 and type updates and ipversion 4 and path _{target_asn}_\"\n",
    "\n",
    "    # Initialize BGPStream with the filter\n",
    "    stream = pybgpstream.BGPStream(\n",
    "        from_time=from_time,\n",
    "        until_time=until_time,\n",
    "        record_type=\"updates\",\n",
    "        filter=filter_str  # Apply the filter string\n",
    "    )\n",
    "\n",
    "    # Initialize counters and data structures\n",
    "    announcements = defaultdict(int)\n",
    "    withdrawals = defaultdict(int)\n",
    "    prefix_as_paths = {}\n",
    "    community_counts = defaultdict(int)\n",
    "    med_values = []\n",
    "\n",
    "    # Iterate over records and elements\n",
    "    for rec in stream.records():\n",
    "        for elem in rec:\n",
    "            # Process the element\n",
    "            elem_time = datetime.utcfromtimestamp(elem.time)\n",
    "            elem_type = elem.type  # 'A' for announcements, 'W' for withdrawals\n",
    "            fields = elem.fields\n",
    "\n",
    "            # Get the prefix\n",
    "            prefix = fields.get(\"prefix\")\n",
    "            if prefix is None:\n",
    "                continue  # Skip if prefix is not present\n",
    "\n",
    "            # Get the AS path\n",
    "            as_path_str = fields.get('as-path', \"\")\n",
    "            as_path = as_path_str.split()\n",
    "\n",
    "            # Check if the target ASN is in the AS path (double-checking as a safeguard)\n",
    "            if target_asn not in as_path:\n",
    "                continue  # Skip if target ASN is not in the AS path\n",
    "\n",
    "            # Count announcements and withdrawals\n",
    "            if elem_type == 'A':\n",
    "                announcements[prefix] += 1\n",
    "            elif elem_type == 'W':\n",
    "                withdrawals[prefix] += 1\n",
    "\n",
    "            # Detect AS path changes\n",
    "            if prefix in prefix_as_paths:\n",
    "                if as_path != prefix_as_paths[prefix]:  # AS path has changed\n",
    "                    prefix_as_paths[prefix] = as_path\n",
    "            else:\n",
    "                prefix_as_paths[prefix] = as_path\n",
    "\n",
    "            # Analyze community attributes\n",
    "            communities = fields.get('communities', [])\n",
    "            for community in communities:\n",
    "                community_str = f\"{community[0]}:{community[1]}\"\n",
    "                community_counts[community_str] += 1\n",
    "\n",
    "            # Calculate statistics (e.g., Average MED)\n",
    "            med = fields.get('med')\n",
    "            if med is not None:\n",
    "                try:\n",
    "                    med_values.append(int(med))\n",
    "                except ValueError:\n",
    "                    pass  # Ignore invalid MED values\n",
    "\n",
    "    # Calculate average MED if values exist\n",
    "    if med_values:\n",
    "        med_avg = sum(med_values) / len(med_values)\n",
    "        print(f\"Average MED: {med_avg:.2f}\")\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Announcements:\", dict(announcements))\n",
    "    print(\"Withdrawals:\", dict(withdrawals))\n",
    "    print(\"Communities Count:\", dict(community_counts))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_bgp_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect hijacking from as3356 from oct 28 13pm to 13:30 pm 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybgpstream\n",
    "from datetime import datetime, timedelta\n",
    "import collections\n",
    "import ipaddress\n",
    "\n",
    "def detect_hijacking(from_time, until_time, target_asn):\n",
    "    # Initialize BGPStream with the specified time range and record type\n",
    "    stream = pybgpstream.BGPStream(\n",
    "        from_time=from_time,\n",
    "        until_time=until_time,\n",
    "        record_type=\"updates\"\n",
    "    )\n",
    "\n",
    "    # Initialize dictionaries to track potential hijacks\n",
    "    observed_origins = {}\n",
    "    expected_origins = {'192.0.2.0/24': '3356', '198.51.100.0/24': '64501'}  # Example prefixes\n",
    "\n",
    "    # Iterate over BGP records and their elements\n",
    "    for rec in stream.records():\n",
    "        for elem in rec:\n",
    "            # Access element attributes\n",
    "            elem_time = datetime.utcfromtimestamp(elem.time)\n",
    "            elem_type = elem.type  # 'A' for announcements, 'W' for withdrawals\n",
    "            fields = elem.fields\n",
    "\n",
    "            # Get prefix and skip if not present\n",
    "            prefix = fields.get(\"prefix\")\n",
    "            if prefix is None:\n",
    "                continue\n",
    "\n",
    "            # Get AS path and peer ASN\n",
    "            as_path_str = fields.get('as-path', \"\")\n",
    "            as_path = as_path_str.split()\n",
    "            peer_asn = elem.peer_asn\n",
    "            \n",
    "            # Detect hijacks by comparing observed and expected origins\n",
    "            if prefix in expected_origins:\n",
    "                observed_origin = as_path[-1] if as_path else None\n",
    "                expected_origin = expected_origins[prefix]\n",
    "                \n",
    "                if observed_origin != expected_origin:\n",
    "                    print(f\"Possible hijack detected for {prefix}: expected {expected_origin}, observed {observed_origin} from AS {peer_asn} at {elem_time}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the time range for analysis\n",
    "    from_time = \"2024-10-28 13:00:00\"\n",
    "    until_time = \"2024-10-28 13:30:00\"\n",
    "    target_asn = '3356'\n",
    "\n",
    "    # Run the hijacking detection function\n",
    "    detect_hijacking(from_time, until_time, target_asn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_39_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
