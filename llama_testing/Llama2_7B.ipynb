{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe0fdaed384450d9d2620494011073f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/myenv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05aaf932ad2047bdadde289ca5d07a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "import os\n",
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "# bnb_config = transformers.BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type='nf4',\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_compute_dtype=bfloat16\n",
    "# )\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Need auth token for these\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/10\n",
      "Processed 2/10\n",
      "Processed 3/10\n",
      "Processed 4/10\n",
      "Processed 5/10\n",
      "Processed 6/10\n",
      "Processed 7/10\n",
      "Processed 8/10\n",
      "Processed 9/10\n",
      "Processed 10/10\n",
      "[{'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 07:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 07:05:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | [SEP] row 3: | 2022-03-28 07:10:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 07:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 07:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 07:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 07:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 07:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2022-03-28 07:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 07:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 07:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 07:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 08:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 08:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 08:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 08:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 08:20:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | [SEP] row 18: | 2022-03-28 08:25:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 08:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2022-03-28 08:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are a few anomalies detected in the given time period.\\n\\nThe first anomaly is detected at timestamp 2022-03-28 08:25:00, where the value of num_routes is 7, which is significantly higher than the average value of 0. This indicates an anomaly in the number of routes advertised by ASN 8342 during this time period.\\n\\nThe second anomaly is detected at timestamp 2022-03-28 08:35:00, where the value of num_routes is 1, which is significantly lower than the average value of 7. This indicates an anomaly in the number of routes advertised by ASN 8342 during this time period.\\n\\nTherefore, the anomalies are detected at timestamps 2022-03-28 08:25:00 and 2022-03-28 08:35:00.\\n\\nReason for anomaly 1: High value of num_routes=7.\\nReason for anomaly 2: Low value of num_routes=1.\\n\\nIt is important to note that these are just examples of anomalies and the actual reason for the anomaly may be due to various factors such as network changes, maintenance, or other issues. Further investigation and analysis are required to determine the root cause of the anomaly.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 08:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 08:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 08:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 08:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 09:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 09:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 09:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 09:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2022-03-28 09:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 09:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 09:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 09:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 09:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 09:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 09:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 09:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 10:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 10:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 19: | 2022-03-28 10:10:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 20: | 2022-03-28 10:15:00 | 8342 | 10 | 10 | 17 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 41 | 10 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data. Here are the timestamps of the anomalies and the reasons explaining which values are anomalous:\\n\\nAnomaly 1:\\nTimestamp: 2022-03-28 09:45:00\\nReason: The value of num_routes = 0 is anomalous. This is the first time in the entire dataset that num_routes is equal to 0.\\n\\nAnomaly 2:\\nTimestamp: 2022-03-28 10:15:00\\nReason: The value of num_routes = 10 is anomalous. This is the highest value of num_routes observed in the dataset, and it is significantly higher than the average value of num_routes = 4.1.\\n\\nAnomaly 3:\\nTimestamp: 2022-03-28 10:10:00\\nReason: The value of num_withdrawals = 1 is anomalous. This is the first time in the dataset that num_withdrawals is equal to 1, and it is significantly lower than the average value of num_withdrawals = 1.7.\\n\\nAnomaly 4:\\nTimestamp: 2022-03-28 09:50:00\\nReason: The value of max_path_length = 0 is anomalous. This is the first time in the dataset that max_path_length is equal to 0, and it is significantly lower than the average value of max_path_length = 1.7.\\n\\nAnomaly 5:\\nTimestamp: 2022-03-28 10:05:00\\nReason: The value of avg_edit_distance = 0.0 is anomalous. This is the first time in the dataset that avg_edit_distance is equal to 0.0, and it is significantly lower than the average value of avg_edit_distance = 0.7.\\n\\nAnomaly 6:\\nTimestamp: 2022-03-28 09:35:00\\nReason: The value of num_announcements = 0 is anomalous. This is the first time in the dataset that num_announcements is equal to 0, and it is significantly lower than the average value of num_announcements = 1.3.\\n\\nAnomaly 7:\\nTimestamp: 2022-03-28 09:40:00\\nReason: The value of num_unique_prefixes_announced = 0 is anomalous. This is the first time in the dataset that num_unique_prefixes_announced is equal to 0, and it is significantly lower than the average value of num_unique_prefixes_announced = 1.1.\\n\\nIn summary, there are seven anomalies detected in the BGP data at the following timestamps: 2022-03-28 09:45:00, 2022-03-28 10:15:00, 2022-03-28 10:10:00, 2022-03-28 09:50:00, 2022-03-28 10:05:00, 2022-03-28 09:35:00, and 2022-03-28 09:40:00.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 10:20:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | [SEP] row 2: | 2022-03-28 10:25:00 | 8342 | 8 | 2 | 29 | 0 | 6 | 6 | 3.5 | 4 | 2.5 | 39 | 8 | [SEP] row 3: | 2022-03-28 10:30:00 | 8342 | 13 | 8 | 3 | 0 | 0 | 6 | 1.6923076923076923 | 0 | 0.0 | 13 | 13 | [SEP] row 4: | 2022-03-28 10:35:00 | 8342 | 26 | 13 | 0 | 0 | 13 | 6 | 2.8076923076923075 | 5 | 1.6538461538461535 | 26 | 26 | [SEP] row 5: | 2022-03-28 10:40:00 | 8342 | 0 | 0 | 26 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 10:45:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 10 | 10 | [SEP] row 7: | 2022-03-28 10:50:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | [SEP] row 8: | 2022-03-28 10:55:00 | 8342 | 6 | 1 | 11 | 0 | 5 | 7 | 5.333333333333333 | 5 | 3.5 | 6 | 6 | [SEP] row 9: | 2022-03-28 11:00:00 | 8342 | 20 | 20 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | [SEP] row 10: | 2022-03-28 11:05:00 | 8342 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 11:10:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 12: | 2022-03-28 11:15:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 11:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 11:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 11:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 11:35:00 | 8342 | 27 | 27 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 27 | 27 | [SEP] row 17: | 2022-03-28 11:40:00 | 8342 | 27 | 0 | 0 | 0 | 27 | 6 | 4.962962962962963 | 5 | 3.2222222222222223 | 27 | 27 | [SEP] row 18: | 2022-03-28 11:45:00 | 8342 | 0 | 0 | 27 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 11:50:00 | 8342 | 6 | 6 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 6 | 6 | [SEP] row 20: | 2022-03-28 11:55:00 | 8342 | 0 | 0 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data for the specified time period.\\n\\n1. Anomaly detected at 2022-03-28 10:25:00, 2022-03-28 10:30:00, and 2022-03-28 10:35:00. The values of num_routes are 8, 13, and 16, respectively, which are higher than the average value of 10.3 for the given time period.\\n2. Anomaly detected at 2022-03-28 11:05:00 and 2022-03-28 11:10:00. The values of num_routes are 20 and 1, respectively, which are significantly lower than the average value of 10.3 for the given time period.\\n3. Anomaly detected at 2022-03-28 11:25:00. The value of num_routes is 0, which is significantly lower than the average value of 10.3 for the given time period.\\n4. Anomaly detected at 2022-03-28 11:40:00 and 2022-03-28 11:45:00. The values of num_routes are 27 and 0, respectively, which are significantly lower than the average value of 10.3 for the given time period.\\n\\nReason for anomaly:\\nThe values of num_routes that are anomalous are higher or lower than the average value of 10.3 for the given time period. This could indicate changes in the network topology, routing policies, or other factors that affect the number of routes advertised in the BGP system.\\n\\nTherefore, the data indicates several anomalies in the BGP data for the specified time period. The anomalies are characterized by high or low values of num_routes compared to the average value for the given time period.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 12:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 12:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 3: | 2022-03-28 12:10:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 12:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 12:20:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 6: | 2022-03-28 12:25:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 12:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 12:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 9: | 2022-03-28 12:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 12:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 12:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 12:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 13:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 13:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 13:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 13:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 13:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 13:25:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 175 | 20 | [SEP] row 19: | 2022-03-28 13:30:00 | 8342 | 20 | 0 | 0 | 0 | 20 | 6 | 5.75 | 4 | 4.0 | 94 | 20 | [SEP] row 20: | 2022-03-28 13:35:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 4 | 4.0 | 11 | 11 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data.\\n\\nThe first anomaly is at timestamp 2022-03-28 13:25:00, where the number of new routes (num_new_routes) is 20, which is significantly higher than the average value of 4. This indicates an anomaly in the number of new routes advertised by ASN 8342 during this time period.\\n\\nThe second anomaly is at timestamp 2022-03-28 13:35:00, where the number of routes withdrawn (num_withdrawals) is 11, which is higher than the average value of 4. This indicates an anomaly in the number of routes withdrawn by ASN 8342 during this time period.\\n\\nThe third anomaly is at timestamp 2022-03-28 13:20:00, where the maximum path length (max_path_length) is 5.75, which is higher than the average value of 4. This indicates an anomaly in the maximum path length of the routes advertised by ASN 8342 during this time period.\\n\\nThe reason for these anomalies is that the values for num_new_routes, num_withdrawals, and max_path_length are significantly higher or lower than the average values for the given time period.\\n\\nTherefore, the data indicates three anomalies:\\n\\n* Anomaly detected at 2022-03-28 13:25:00 due to high value of num_new_routes=20.\\n* Anomaly detected at 2022-03-28 13:35:00 due to high value of num_withdrawals=11.\\n* Anomaly detected at 2022-03-28 13:20:00 due to high value of max_path_length=5.75.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 13:40:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 13:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 13:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 13:55:00 | 8342 | 9 | 9 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 18 | 9 | [SEP] row 5: | 2022-03-28 14:00:00 | 8342 | 25 | 16 | 1 | 0 | 9 | 8 | 2.88 | 2 | 0.72 | 69 | 25 | [SEP] row 6: | 2022-03-28 14:05:00 | 8342 | 0 | 0 | 25 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 14:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 14:15:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 117 | 10 | [SEP] row 9: | 2022-03-28 14:20:00 | 8342 | 20 | 11 | 1 | 0 | 9 | 5 | 2.25 | 4 | 1.8 | 127 | 20 | [SEP] row 10: | 2022-03-28 14:25:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 2 | 2.0 | 11 | 11 | [SEP] row 11: | 2022-03-28 14:30:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 14:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 13: | 2022-03-28 14:40:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 5 | 1 | [SEP] row 14: | 2022-03-28 14:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 14:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 14:55:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 3 | 1 | [SEP] row 17: | 2022-03-28 15:00:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 15:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 15:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2022-03-28 15:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are a few anomalies detected in the BGP data. Here are the timestamps of the anomalies and the reasons explaining which values are anomalous:\\n\\n1. Anomaly detected at 2022-03-28 14:05:00. The value of num_routes = 9 is anomalous as it is significantly higher than the previous values (average value is 2.88).\\n2. Anomaly detected at 2022-03-28 14:15:00. The value of num_routes = 10 is anomalous as it is significantly higher than the previous values (average value is 2.25).\\n3. Anomaly detected at 2022-03-28 14:25:00. The value of num_routes = 11 is anomalous as it is significantly higher than the previous values (average value is 5.0).\\n4. Anomaly detected at 2022-03-28 14:35:00. The value of num_routes = 1 is anomalous as it is significantly lower than the previous values (average value is 5).\\n\\nReason for anomaly:\\nThe values of num_routes are significantly different from the average value, which indicates an anomaly. The average value of num_routes is 2.88, but there are several instances where the value is significantly higher or lower than this average.\\n\\nAdditionally, the anomaly detection algorithm can also identify other anomalies in the data, such as:\\n\\n* Anomaly detected at 2022-03-28 13:40:00. The value of num_new_routes = 0 is anomalous as it is significantly lower than the previous values (average value is 0.72).\\n* Anomaly detected at 2022-03-28 13:50:00. The value of num_withdrawals = 1 is anomalous as it is significantly higher than the previous values (average value is 0).\\n* Anomaly detected at 2022-03-28 14:00:00. The value of avg_edit_distance = 2.88 is anomalous as it is significantly higher than the previous values (average value is 1.8).\\n\\nReason for anomaly:\\nThe values of num_new_routes, num_withdrawals, and avg_edit_distance are significantly different from the average value, which indicates an anomaly. The average value of these metrics is lower than the previous values, which is unusual and could indicate a change in the network behavior.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 15:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 15:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 15:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 15:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 15:40:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 6: | 2022-03-28 15:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 15:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 15:55:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | [SEP] row 9: | 2022-03-28 16:00:00 | 8342 | 1 | 1 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 10: | 2022-03-28 16:05:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 16:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 16:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 16:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 16:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 16:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 16:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 16:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 16:45:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 19: | 2022-03-28 16:50:00 | 8342 | 1 | 0 | 0 | 0 | 0 | 3 | 3.0 | 0 | 0.0 | 1 | 1 | [SEP] row 20: | 2022-03-28 16:55:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data. Here are the timestamps of the anomalies and the reasons explaining which values are anomalous:\\n\\n1. Anomaly detected at 2022-03-28 15:30:00. The number of new routes (num_new_routes) is 1, which is anomalous as it is not consistent with the previous values.\\n2. Anomaly detected at 2022-03-28 15:45:00. The number of withdrawals (num_withdrawals) is 1, which is anomalous as it is not consistent with the previous values.\\n3. Anomaly detected at 2022-03-28 16:00:00. The number of routes (num_routes) is 20, which is anomalous as it is not consistent with the previous values.\\n4. Anomaly detected at 2022-03-28 16:15:00. The maximum path length (max_path_length) is 3, which is anomalous as it is not consistent with the previous values.\\n5. Anomaly detected at 2022-03-28 16:30:00. The number of announcements (num_announcements) is 1, which is anomalous as it is not consistent with the previous values.\\n\\nReasons for the anomalies:\\n\\n1. Increase in number of new routes at 2022-03-28 15:30:00: This could be due to a change in network topology or a new prefix being advertised.\\n2. Increase in withdrawals at 2022-03-28 15:45:00: This could be due to a change in network topology or a prefix being withdrawn.\\n3. Increase in routes at 2022-03-28 16:00:00: This could be due to a change in network topology or an increase in prefixes being advertised.\\n4. Increase in maximum path length at 2022-03-28 16:15:00: This could be due to a change in network topology or an increase in the number of prefixes being advertised.\\n5. Decrease in number of announcements at 2022-03-28 16:30:00: This could be due to a change in network topology or a decrease in the number of prefixes being advertised.\\n\\nIt is important to note that these are just possible reasons and further investigation is required to determine the root cause of the anomalies.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 17:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2019-05-08 14:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2019-05-08 14:05:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2019-05-08 14:10:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2019-05-08 14:15:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2019-05-08 14:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2019-05-08 14:25:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2019-05-08 14:30:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2019-05-08 14:35:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2019-05-08 14:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2019-05-08 14:45:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2019-05-08 14:50:00 | 268869 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 8 | 1 | [SEP] row 13: | 2019-05-08 14:55:00 | 268869 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2019-05-08 15:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2019-05-08 15:05:00 | 268869 | 7 | 7 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 373 | 7 | [SEP] row 16: | 2019-05-08 15:10:00 | 268869 | 2 | 0 | 183 | 0 | 2 | 6 | 6.0 | 4 | 4.0 | 580 | 2 | [SEP] row 17: | 2019-05-08 15:15:00 | 268869 | 0 | 0 | 2 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2019-05-08 15:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2019-05-08 15:25:00 | 268869 | 5 | 5 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 392 | 5 | [SEP] row 20: | 2019-05-08 15:30:00 | 268869 | 5 | 0 | 0 | 0 | 5 | 6 | 5.8 | 3 | 3.0 | 13 | 5 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the given time period. Here are the timestamps of the anomalies and the reasons explaining which values are anomalous:\\n\\n1. Anomaly detected at 2019-05-08 14:05:00. The value of num_routes = 0 is anomalous as there should be at least one route announced by this time.\\n2. Anomaly detected at 2019-05-08 14:10:00. The value of max_path_length = 0 is anomalous as it should be greater than 0.\\n3. Anomaly detected at 2019-05-08 14:15:00. The value of num_new_routes = 0 is anomalous as there should be at least one new route announced by this time.\\n4. Anomaly detected at 2019-05-08 14:20:00. The value of avg_edit_distance = 0 is anomalous as it should be greater than 0.\\n5. Anomaly detected at 2019-05-08 14:25:00. The value of num_withdrawals = 0 is anomalous as there should be at least one withdrawal by this time.\\n6. Anomaly detected at 2019-05-08 14:30:00. The value of num_routes = 0 is anomalous as there should be at least one route announced by this time.\\n7. Anomaly detected at 2019-05-08 14:35:00. The value of max_path_length = 0 is anomalous as it should be greater than 0.\\n8. Anomaly detected at 2019-05-08 14:40:00. The value of num_announcements = 0 is anomalous as there should be at least one announcement by this time.\\n9. Anomaly detected at 2019-05-08 14:45:00. The value of avg_path_length = 0 is anomalous as it should be greater than 0.\\n10. Anomaly detected at 2019-05-08 15:00:00. The value of num_unique_prefixes_announced = 0 is anomalous as there should be at least one unique prefix announced by this time.\\n\\nReason for each anomaly:\\n\\n* Anomaly detected at 2019-05-08 14:05:00: The value of num_routes = 0 is anomalous because there should be at least one route announced by this time.\\n* Anomaly detected at 2019-05-08 14:10:00: The value of max_path_length = 0 is anomalous because it should be greater than 0.\\n* Anomaly detected at 2019-05-08 14:15:00: The value of num_new_routes = 0 is anomalous because there should be at least one new route announced by this time.\\n* Anomaly detected at 2019-05-08 14:20:00: The value of avg_edit_distance = 0 is anomalous because it should be greater than 0.\\n* Anomaly detected at 2019-05-08 14:25:00: The value of num_withdrawals = 0 is anomalous because there should be at least one withdrawal by this time.\\n* Anomaly detected at 2019-05-08 14:30:00: The value of num_routes = 0 is anomalous because there should be at least one route announced by this time.\\n* Anomaly detected at 2019-05-08 14:35:00: The value of max_path_length = 0 is anomalous because it should be greater than 0.\\n* Anomaly detected at 2019-05-08 14:40:00: The value of num_announcements = 0 is anomalous because there should be at least one announcement by this time.\\n* Anomaly detected at 2019-05-08 14:45:00: The value of avg_path_length = 0 is anomalous because it should be greater than 0.\\n* Anomaly detected at 2019-05-08 15:00:00: The value of num_unique_prefixes_announced = 0 is anomalous because there should be at least one unique prefix announced by this time.\\n\\nNote: These are just examples of possible anomalies based on the data provided, and the actual anomalies may be different.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2019-05-08 15:35:00 | 268869 | 0 | 0 | 5 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2019-05-08 15:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2019-05-08 15:45:00 | 268869 | 4 | 4 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 4 | 4 | [SEP] row 4: | 2019-05-08 15:50:00 | 268869 | 0 | 0 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2019-05-08 15:55:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2019-05-08 16:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 04:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 04:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 04:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 04:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2017-12-12 04:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 04:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2017-12-12 04:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 04:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 04:40:00 | 39523 | 77 | 77 | 393 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 12086 | 77 | [SEP] row 16: | 2017-12-12 04:45:00 | 39523 | 50 | 3 | 1470 | 0 | 47 | 8 | 5.66 | 5 | 2.94 | 3427 | 50 | [SEP] row 17: | 2017-12-12 04:50:00 | 39523 | 0 | 0 | 50 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2017-12-12 04:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2017-12-12 05:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2017-12-12 05:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are a few anomalies that can be detected:\\n\\n1. Anomaly detected at 2019-05-08 15:40:00. The number of new routes (num_new_routes) is 4, which is higher than the average value of 0. This indicates an anomaly in the number of new routes advertised by the ASN at this timestamp.\\n2. Anomaly detected at 2019-05-08 15:45:00. The number of withdrawals (num_withdrawals) is 4, which is higher than the average value of 0. This indicates an anomaly in the number of routes withdrawn by the ASN at this timestamp.\\n3. Anomaly detected at 2017-12-12 04:35:00. The number of routes (num_routes) is 77, which is higher than the average value of 393. This indicates an anomaly in the number of routes advertised by the ASN at this timestamp.\\n\\nReason for the anomalies:\\n\\n1. The high number of new routes advertised at 2019-05-08 15:40:00 may indicate a network topology change or a new peering relationship.\\n2. The high number of withdrawals at 2019-05-08 15:45:00 may indicate a network maintenance or upgrade activity.\\n3. The high number of routes advertised at 2017-12-12 04:35:00 may indicate a network expansion or a change in the routing policy.\\n\\nIn each case, the anomaly is detected by comparing the observed value to the average value or the expected range of values. The reason for the anomaly is provided based on the context of the data and the values that are outside the expected range.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2017-12-12 05:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2017-12-12 05:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2017-12-12 05:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2017-12-12 05:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2017-12-12 05:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2017-12-12 05:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 05:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 05:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 05:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 05:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2017-12-12 06:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 06:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2017-12-12 06:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 06:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 06:20:00 | 39523 | 31 | 31 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 57 | 31 | [SEP] row 16: | 2017-12-12 06:25:00 | 39523 | 0 | 0 | 31 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2017-12-12 06:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2017-12-12 06:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2017-12-12 06:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2017-12-12 06:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data. Here are the timestamps of the anomalies and the reasons explaining which values are anomalous:\\n\\n1. Anomaly detected at 2017-12-12 05:10:00: The value of num_routes is 0, which is anomalous as there should be at least one route announced by a BGP speaker at this timestamp.\\n2. Anomaly detected at 2017-12-12 05:15:00: The value of num_routes is 0, which is anomalous as there should be at least one route announced by a BGP speaker at this timestamp.\\n3. Anomaly detected at 2017-12-12 05:20:00: The value of num_routes is 31, which is anomalous as the value is much higher than the previous values at this timestamp.\\n4. Anomaly detected at 2017-12-12 05:25:00: The value of num_routes is 0, which is anomalous as there should be at least one route announced by a BGP speaker at this timestamp.\\n5. Anomaly detected at 2017-12-12 05:30:00: The value of num_routes is 31, which is anomalous as the value is much higher than the previous values at this timestamp.\\n6. Anomaly detected at 2017-12-12 05:35:00: The value of num_routes is 0, which is anomalous as there should be at least one route announced by a BGP speaker at this timestamp.\\n7. Anomaly detected at 2017-12-12 05:40:00: The value of num_routes is 31, which is anomalous as the value is much higher than the previous values at this timestamp.\\n8. Anomaly detected at 2017-12-12 05:45:00: The value of num_routes is 0, which is anomalous as there should be at least one route announced by a BGP speaker at this timestamp.\\n9. Anomaly detected at 2017-12-12 05:50:00: The value of num_routes is 31, which is anomalous as the value is much higher than the previous values at this timestamp.\\n10. Anomaly detected at 2017-12-12 05:55:00: The value of num_routes is 0, which is anomalous as there should be at least one route announced by a BGP speaker at this timestamp.\\n\\nReason for anomaly:\\nIn each of these instances, the value of num_routes is either 0 or much higher than the previous values at that timestamp. This indicates a possible issue with the BGP system, such as a routing leak or a misconfiguration. Further investigation is needed to determine the root cause of the anomaly.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2017-12-12 06:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2017-12-12 06:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2017-12-12 07:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2017-12-12 07:05:00 | 39523 | 74 | 74 | 2211 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16467 | 74 | [SEP] row 5: | 2017-12-12 07:10:00 | 39523 | 20 | 2 | 96 | 0 | 16 | 8 | 6.3 | 4 | 2.6 | 73 | 20 | [SEP] row 6: | 2017-12-12 07:15:00 | 39523 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 07:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 07:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 07:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 07:35:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 181 | 1 | [SEP] row 11: | 2017-12-12 07:40:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 07:45:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 13: | 2017-12-12 07:50:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 07:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 08:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided in the table, there are a few anomalies that can be detected:\\n\\n1. Anomaly detected at 2017-12-12 07:35:00. The value of num_routes = 1 is anomalous as it is different from the previous values, which were all 0.\\n2. Anomaly detected at 2017-12-12 07:45:00. The value of num_routes = 1 is anomalous as it is different from the previous value of 0.\\n3. Anomaly detected at 2017-12-12 07:50:00. The value of num_routes = 0 is anomalous as it is different from the previous values, which were all non-zero.\\n\\nReason for anomaly 1:\\nThe value of num_routes = 1 at 2017-12-12 07:35:00 is anomalous because it is different from the previous values, which were all 0. This could indicate a network event or change that caused a temporary increase in the number of routes.\\n\\nReason for anomaly 2:\\nThe value of num_routes = 1 at 2017-12-12 07:45:00 is anomalous because it is different from the previous value of 0. This could indicate a network event or change that caused a temporary increase in the number of routes.\\n\\nReason for anomaly 3:\\nThe value of num_routes = 0 at 2017-12-12 07:50:00 is anomalous because it is different from the previous values, which were all non-zero. This could indicate a network event or change that caused a temporary decrease in the number of routes.\\n\\nTherefore, the anomalies are detected at timestamps 2017-12-12 07:35:00, 2017-12-12 07:45:00, and 2017-12-12 07:50:00.'}]\n",
      "Results saved to llm_7B_bgp_data_with_outputs_20.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tablular_eval_util import combine_csv_files, split_dataframe, preprocess_data, run_llm_inference\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "if 'anomaly_status' in combined_df.columns:\n",
    "    combined_df = combined_df.drop(columns=['anomaly_status'])\n",
    "    \n",
    "\n",
    "# Split the DataFrame into smaller chunks\n",
    "split_size = 20\n",
    "data_list = split_dataframe(combined_df, split_size)\n",
    "\n",
    "# Preprocess the data into the required format\n",
    "formatted_data = [preprocess_data(chunk) for chunk in data_list]\n",
    "\n",
    "formatted_data_file = 'llm_table_bgp_data_test_20.json'\n",
    "with open(formatted_data_file, 'w') as f:\n",
    "    json.dump(formatted_data, f, indent=4)\n",
    "\n",
    "with open(formatted_data_file, 'r') as f:\n",
    "    formatted_data = json.load(f)\n",
    "\n",
    "output_results_file = 'llm_7B_bgp_data_with_outputs_20.json'\n",
    "run_llm_inference(formatted_data, model, tokenizer, max_length=3050, output_results_file=output_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 08:25:00', '2022-03-28 08:35:00', '2022-03-28 08:25:00', '2022-03-28 08:35:00', '2022-03-28 09:45:00', '2022-03-28 10:15:00', '2022-03-28 10:10:00', '2022-03-28 09:50:00', '2022-03-28 10:05:00', '2022-03-28 09:35:00', '2022-03-28 09:40:00', '2022-03-28 09:45:00', '2022-03-28 10:15:00', '2022-03-28 10:10:00', '2022-03-28 09:50:00', '2022-03-28 10:05:00', '2022-03-28 09:35:00', '2022-03-28 09:40:00', '2022-03-28 10:25:00', '2022-03-28 10:30:00', '2022-03-28 10:35:00', '2022-03-28 11:05:00', '2022-03-28 11:10:00', '2022-03-28 11:25:00', '2022-03-28 11:40:00', '2022-03-28 11:45:00', '2022-03-28 13:25:00', '2022-03-28 13:35:00', '2022-03-28 13:20:00', '2022-03-28 13:25:00', '2022-03-28 13:35:00', '2022-03-28 13:20:00', '2022-03-28 14:05:00', '2022-03-28 14:15:00', '2022-03-28 14:25:00', '2022-03-28 14:35:00', '2022-03-28 13:40:00', '2022-03-28 13:50:00', '2022-03-28 14:00:00', '2022-03-28 15:30:00', '2022-03-28 15:45:00', '2022-03-28 16:00:00', '2022-03-28 16:15:00', '2022-03-28 16:30:00', '2022-03-28 15:30:00', '2022-03-28 15:45:00', '2022-03-28 16:00:00', '2022-03-28 16:15:00', '2022-03-28 16:30:00', '2019-05-08 14:05:00', '2019-05-08 14:10:00', '2019-05-08 14:15:00', '2019-05-08 14:20:00', '2019-05-08 14:25:00', '2019-05-08 14:30:00', '2019-05-08 14:35:00', '2019-05-08 14:40:00', '2019-05-08 14:45:00', '2019-05-08 15:00:00', '2019-05-08 14:05:00', '2019-05-08 14:10:00', '2019-05-08 14:15:00', '2019-05-08 14:20:00', '2019-05-08 14:25:00', '2019-05-08 14:30:00', '2019-05-08 14:35:00', '2019-05-08 14:40:00', '2019-05-08 14:45:00', '2019-05-08 15:00:00', '2019-05-08 15:40:00', '2019-05-08 15:45:00', '2017-12-12 04:35:00', '2019-05-08 15:40:00', '2019-05-08 15:45:00', '2017-12-12 04:35:00', '2017-12-12 05:10:00', '2017-12-12 05:15:00', '2017-12-12 05:20:00', '2017-12-12 05:25:00', '2017-12-12 05:30:00', '2017-12-12 05:35:00', '2017-12-12 05:40:00', '2017-12-12 05:45:00', '2017-12-12 05:50:00', '2017-12-12 05:55:00', '2017-12-12 07:35:00', '2017-12-12 07:45:00', '2017-12-12 07:50:00', '2017-12-12 07:35:00', '2017-12-12 07:45:00', '2017-12-12 07:50:00', '2017-12-12 07:35:00', '2017-12-12 07:45:00', '2017-12-12 07:50:00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "llama7b_outputs = pd.read_json(\"/home/hb/LLM-research/LLM_testing/llm_7B_bgp_data_with_outputs_20.json\")\n",
    "llama7b_outputs = llama7b_outputs[\"output\"]\n",
    "llama7b_outputs.to_csv(\"llm_7B_bgp_data_with_outputs_20.csv\")\n",
    "\n",
    "timestamps = []\n",
    "\n",
    "timestamp_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}')\n",
    "\n",
    "for output in llama7b_outputs:\n",
    "    matches = timestamp_pattern.findall(output)\n",
    "    timestamps.extend(matches)\n",
    "\n",
    "llama7b_outputs_timestamp = list(set(timestamps))\n",
    "\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 10:25:00', '2022-03-28 10:30:00', '2022-03-28 10:35:00', '2022-03-28 10:40:00', '2022-03-28 10:55:00', '2022-03-28 11:00:00', '2022-03-28 11:35:00', '2022-03-28 11:40:00', '2022-03-28 11:45:00', '2022-03-28 13:25:00', '2022-03-28 13:30:00', '2022-03-28 13:35:00', '2022-03-28 14:00:00', '2022-03-28 14:05:00', '2022-03-28 14:15:00', '2022-03-28 14:20:00', '2022-03-28 14:25:00', '2022-03-28 15:55:00', '2022-03-28 16:00:00', '2022-03-28 16:05:00', '2019-05-08 15:05:00', '2019-05-08 15:10:00', '2019-05-08 15:15:00', '2019-05-08 15:30:00', '2017-12-12 04:40:00', '2017-12-12 04:45:00', '2017-12-12 04:50:00', '2017-12-12 07:05:00', '2017-12-12 07:10:00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import combine_csv_files\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "combined_df = combined_df[['anomaly_status']]\n",
    "\n",
    "# Filter the rows with \"anomaly detected\" in the anomaly_status\n",
    "filtered_df = combined_df[combined_df['anomaly_status'].str.contains('anomaly detected', na=False)]\n",
    "filtered_df.to_csv('/home/hb/dataset_bgp/bgp_tab_dataset_test/test_true_label.csv', index=False)\n",
    "\n",
    "# Extract the date from the anomaly_status string\n",
    "true_label = filtered_df['anomaly_status'].str.extract(r'anomaly detected at (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})')\n",
    "\n",
    "# Convert the dates to a list\n",
    "true_label = true_label[0].tolist()\n",
    "\n",
    "print(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Precision: 0.21\n",
      "Recall: 0.41\n",
      "F1 Score: 0.28\n",
      "True Positives: 12\n",
      "False Positives: 46\n",
      "False Negatives: 17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import evaluate_llm_results\n",
    "\n",
    "evaluation_result = evaluate_llm_results(true_anomalies=true_label, llm_results=llama7b_outputs_timestamp)\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Precision: {evaluation_result['precision']:.2f}\")\n",
    "print(f\"Recall: {evaluation_result['recall']:.2f}\")\n",
    "print(f\"F1 Score: {evaluation_result['f1_score']:.2f}\")\n",
    "print(f\"True Positives: {evaluation_result['true_positives']}\")\n",
    "print(f\"False Positives: {evaluation_result['false_positives']}\")\n",
    "print(f\"False Negatives: {evaluation_result['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] \n",
      "The goal for this task is to identify the type of BGP anomaly based on the given data. The context, section, and table columns provide important information for identifying the correct anomaly type.. \n",
      "[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2024-06-10 12:00:00 | 12345 | 100 | 5 | 3 | 1 | 2 | 4 | 3.5 | 2 | 1.5 | 10 | 8 | [SEP] row 2: | 2024-06-10 12:05:00 | 12346 | 95 | 7 | 4 | 0 | 1 | 5 | 3.2 | 1 | 1.7 | 9 | 7 | [SEP] row 3: | 2024-06-10 12:10:00 | 12347 | 102 | 4 | 5 | 2 | 3 | 4.1 | 3 | 2.5 | 11 | 10 |\n",
      "Based on the data provided, identify the type of BGP anomaly. The possible anomaly types are: route_flapping, outage, prefix_hijacking, normal. The data contains various metrics such as num_routes, num_new_routes, num_withdrawals, etc.\n",
      " [/INST]  Based on the data provided, the most likely type of BGP anomaly is route flapping. This is because the data shows a rapid change in the number of routes (num_routes) and the number of new routes (num_new_routes) over a short period of time (less than 5 minutes). Specifically, the change in num_routes from row 1 to row 2 is 50 (100 - 50), and the change in num_new_routes is 7 (95 - 38). These changes are significant and indicate route flapping.\n",
      "\n",
      "Other possible types of BGP anomalies that could be observed in this data are:\n",
      "\n",
      "* Outage: A sudden drop in the number of routes (num_routes) or the number of new routes (num_new_routes) could indicate an outage. However, the data does not show a significant drop in either metric, which suggests that an outage is unlikely.\n",
      "* Prefix hijacking: A sudden change in the number of unique prefixes announced (num_unique_prefixes_announced) could indicate prefix hijacking. However, the data does not show a significant change in this metric, which suggests that prefix hijacking is unlikely.\n",
      "* Normal: The data does not show any significant changes in the other metrics, such as the number of withdrawals (num_withdrawals), origin changes (num_origin_changes), or route changes (num_route_changes). This suggests that the observed changes in num_routes and num_new_routes are likely due to normal BGP behavior rather than an anomaly.\n",
      "\n",
      "Therefore, based on the data provided, the most likely type of BGP anomaly is route flapping.\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = f\"\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1528)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import evaluate_llm_results\n",
    "\n",
    "evaluation_result = evaluate_llm_results(true_anomalies=true_label, llm_results=llama7b_outputs_timestamp)\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"Precision: {evaluation_result['precision']:.2f}\")\n",
    "print(f\"Recall: {evaluation_result['recall']:.2f}\")\n",
    "print(f\"F1 Score: {evaluation_result['f1_score']:.2f}\")\n",
    "print(f\"True Positives: {evaluation_result['true_positives']}\")\n",
    "print(f\"False Positives: {evaluation_result['false_positives']}\")\n",
    "print(f\"False Negatives: {evaluation_result['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Create a Python script with the Scapy library to detect DDoS attacks from a PCAP file. The script should read the file, analyze traffic patterns by monitoring packets per second against a set threshold within defined time windows, and reset counters for each time window. It should also log any potential attacks showing the source IP and packet rate. Include a final check for the last time window at the end of the file.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Generate Python code to calculate and visualize 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns. [/INST]  Sure! Here is some Python code that can be used to calculate and visualize 5G network performance KPIs based on the provided CSV file:\n",
      "```\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "# Load the data from the CSV file\n",
      "df = pd.read_csv('5G_Infrastructure/demand_driven_postcode_data_results.csv')\n",
      "\n",
      "# Identify the relevant columns\n",
      "capacity = df['capacity']\n",
      "cost = df['cost']\n",
      "area = df['area']\n",
      "numpoints = df['numpoints']\n",
      "\n",
      "# Calculate the KPIs\n",
      "total_network_capacity = capacity.sum()\n",
      "capacity_per_area = capacity / area\n",
      "capacity_per_point = capacity / numpoints\n",
      "cost_per_capacity = cost / capacity\n",
      "cost_per_area = cost / area\n",
      "surplus_per_area = cost - (capacity * cost_per_point)\n",
      "\n",
      "# Visualize the results\n",
      "sns.barplot(x=range(len(capacity)), y=capacity, hue='numpoints')\n",
      "sns.lineplot(x=range(len(capacity)), y=capacity_per_point, label='Capacity per Point')\n",
      "sns.lineplot(x=range(len(area)), y=capacity_per_area, label='Capacity per Area')\n",
      "sns.lineplot(x=range(len(cost)), y=cost_per_capacity, label='Cost per Capacity')\n",
      "sns.lineplot(x=range(len(area)), y=cost_per_area, label='Cost per Area')\n",
      "sns.barplot(x=range(len(surplus)), y=surplus_per_area, label='Surplus per Area')\n",
      "\n",
      "# Add axis labels and titles\n",
      "plt.xlabel('Postcode')\n",
      "plt.ylabel('Capacity/Cost')\n",
      "plt.title('5G Network Performance KPIs')\n",
      "\n",
      "# Show the plot\n",
      "plt.show()\n",
      "```\n",
      "This code first loads the data from the `demand_driven_postcode_data_results.csv` file using the `pd.read_csv()` function. It then identifies the relevant columns in the data frame using the `capacity`, `cost`, `area`, and `numpoints` keywords.\n",
      "\n",
      "Next, the code calculates the KPIs using the identified columns. Specifically, it calculates the total network capacity by summing the `capacity` column, the capacity per area by dividing the `capacity` column by the `area` column, and the capacity per point by dividing the `capacity` column by the `\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"Generate Python code to calculate and visualize 5G network performance KPIs: Total Network Capacity, Capacity per Area, Capacity per Point, Cost per Capacity, Cost per Area, and Surplus per Area. Load data from '5G_Infrastructure/demand_driven_postcode_data_results.csv'. Use keywords: 'capacity', 'cost', 'area', 'numpoints' to identify relevant columns.\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=712)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Choice\n",
    "`5G configuration analysis v1`:\n",
    "Accuracy: 66%\n",
    "Correct answers: 13 + 7 = 20\n",
    "Incorrect answers: 10\n",
    "\n",
    "`5G configuration analysis v2`:\n",
    "Accuracy: 56%\n",
    "Correct answers: 17\n",
    "Incorrect answers: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
