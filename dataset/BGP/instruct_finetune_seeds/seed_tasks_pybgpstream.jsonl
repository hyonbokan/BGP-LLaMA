{"id": "seed_task_0", "name": "Detecting Hijacked Prefixes", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc00' collector. Identify prefixes where the observed origin AS differs from the expected origin AS provided in a dictionary. Report the prefixes with possible hijacks.", "instances": [{"input": "Collect BGP updates from the 'rrc00' collector for October 28, 2023. Use the expected origins: {'192.0.2.0/24': '64500', '198.51.100.0/24': '64501'}. Identify prefixes where the observed origin AS is different from the expected origin AS, and report these as possible hijacks.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc00"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nexpected_origins = {\n '192.0.2.0/24': '64500',\n '198.51.100.0/24': '64501',\n}\n\nhijacked_prefixes = set()\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n if prefix in expected_origins:\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n observed_origin = as_path[-1] if as_path else None\n expected_origin = expected_origins.get(prefix)\n if observed_origin != expected_origin:\n hijacked_prefixes.add(prefix)\n\n# Report possible hijacked prefixes\nprint("Possible hijacked prefixes:")\nfor prefix in hijacked_prefixes:\n print(f"{prefix}")"}], "is_classification": false}
{"id": "seed_task_1", "name": "Analyzing AS Path Prepending", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc01' collector. Identify ASes performing AS path prepending by detecting consecutive repeated ASNs in the AS paths. Report each ASN and the total number of times it has prepended.", "instances": [{"input": "Collect BGP updates from the 'rrc01' collector for October 28, 2023. Detect AS path prepending by finding consecutive repeated ASNs in the AS paths. Report each ASN and how many times it has performed prepending.", "output": "import pybgpstream\nfrom collections import defaultdict\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc01"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nprepending_counts = defaultdict(int)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n last_asn = None\n consecutive_count = 1\n for asn in as_path:\n if asn == last_asn:\n consecutive_count += 1\n else:\n if consecutive_count > 1 and last_asn is not None:\n prepending_counts[last_asn] += consecutive_count - 1\n consecutive_count = 1\n last_asn = asn\n # Check for prepending at the end of the path\n if consecutive_count > 1 and last_asn is not None:\n prepending_counts[last_asn] += consecutive_count - 1\n\n# Report ASNs performing AS path prepending\nprint("ASNs performing AS path prepending:")\nfor asn, count in prepending_counts.items():\n print(f"ASN {asn} prepended {count} times")"}], "is_classification": false}
{"id": "seed_task_2", "name": "Monitoring MOAS Conflicts", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc02' collector. Identify prefixes announced by multiple origin ASNs (MOAS conflicts). Report these prefixes along with the list of ASNs originating them.", "instances": [{"input": "Collect BGP updates from the 'rrc02' collector for October 28, 2023. Monitor for MOAS conflicts by identifying prefixes announced by more than one origin ASN. Report each conflicting prefix and the ASNs announcing it.", "output": "import pybgpstream\nfrom collections import defaultdict\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc02"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nprefix_origins = defaultdict(set)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n origin_asn = as_path[-1] if as_path else None\n if origin_asn and prefix:\n prefix_origins[prefix].add(origin_asn)\n\n# Report prefixes with MOAS conflicts\nprint("Prefixes with MOAS conflicts:")\nfor prefix, origins in prefix_origins.items():\n if len(origins) > 1:\n origins_list = ', '.join(origins)\n print(f"Prefix {prefix} announced by ASNs: {origins_list}")"}], "is_classification": false}
{"id": "seed_task_3", "name": "Calculating Average MED", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc03' collector. For all announcements that include a MED attribute, calculate the average MED value. Report the result.", "instances": [{"input": "Collect BGP updates from the 'rrc03' collector for October 28, 2023. Extract the MED values from announcements that have this attribute. Compute and report the average MED value.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc03"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nmed_values = []\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n med = elem.fields.get('med')\n if med is not None:\n try:\n med_values.append(int(med))\n except ValueError:\n pass # Ignore invalid MED values\n\n# Calculate and report the average MED value\nif med_values:\n average_med = sum(med_values) / len(med_values)\n print(f"Average MED value: {average_med}")\nelse:\n print("No MED values found in the announcements.")"}], "is_classification": false}
{"id": "seed_task_4", "name": "Counting Announcements and Withdrawals for Specific ASN", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc04' collector. Count the number of announcements and withdrawals that include ASN 3356 in their AS path. Report the counts.", "instances": [{"input": "Collect BGP updates from the 'rrc04' collector for October 28, 2023. Filter updates that have ASN '3356' in their AS path. Count and report the total number of announcements and withdrawals for this ASN.", "output": "import pybgpstream\nfrom collections import defaultdict\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc04"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\ntarget_asn = '3356'\nannouncements = 0\nwithdrawals = 0\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n if target_asn in as_path:\n if elem.type == 'A':\n announcements += 1\n elif elem.type == 'W':\n withdrawals += 1\n\n# Report the counts\nprint(f"Total announcements including ASN {target_asn}: {announcements}")\nprint(f"Total withdrawals including ASN {target_asn}: {withdrawals}")"}], "is_classification": false}
{"id": "seed_task_5", "name": "Detecting Route Leaks", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc05' collector. Identify potential route leaks by analyzing AS paths where a customer AS announces prefixes learned from one provider to another provider. Report these suspicious AS paths.", "instances": [{"input": "Collect BGP updates from the 'rrc05' collector for October 28, 2023. Analyze AS paths to detect potential route leaks where customer ASes are forwarding routes from one provider to another provider. Report the AS paths that may indicate route leaks.", "output": "import pybgpstream\nfrom collections import defaultdict\n\n# AS relationship data would normally be obtained from a dataset like CAIDA's AS relationships\n# For this example, we'll use a mock relationships dictionary\nas_relationships = {\n '100': {'providers': ['200', '300'], 'customers': ['400', '500']},\n '400': {'providers': ['100'], 'customers': []},\n # ... (additional AS relationships)\n}\n\ndef is_route_leak(as_path, as_relationships):\n # Simplified route leak detection\n for i in range(len(as_path) - 1):\n current_asn = as_path[i]\n next_asn = as_path[i + 1]\n if current_asn in as_relationships:\n if next_asn in as_relationships[current_asn].get('providers', []):\n # Customer is sending to provider, which is normal\n continue\n elif next_asn in as_relationships[current_asn].get('customers', []):\n # Provider is sending to customer, which is normal\n continue\n else:\n # Unexpected relationship, potential route leak\n return True\n return False\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc05"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n if as_path:\n if is_route_leak(as_path, as_relationships):\n print(f"Potential route leak detected: AS path {' -> '.join(as_path)}")"}], "is_classification": false}
{"id": "seed_task_6", "name": "Monitoring BGP Withdrawals for Outages", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc06' collector. Monitor for sustained withdrawals of prefixes without re-announcements to detect possible outages. Report the prefixes that remain withdrawn for more than 30 minutes.", "instances": [{"input": "Collect BGP updates from the 'rrc06' collector for October 28, 2023. Identify prefixes that have been withdrawn and not re-announced for over 30 minutes. Report these prefixes as possible outages.", "output": "import pybgpstream\nfrom datetime import datetime, timedelta\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc06"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nwithdrawals_timestamps = {}\noutage_threshold = timedelta(minutes=30)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n elem_time = datetime.utcfromtimestamp(elem.time)\n prefix = elem.fields.get('prefix')\n if prefix is None:\n continue\n if elem.type == 'W':\n withdrawals_timestamps[prefix] = elem_time\n elif elem.type == 'A':\n if prefix in withdrawals_timestamps:\n del withdrawals_timestamps[prefix]\n # Check for outages\n current_time = elem_time\n for withdrawn_prefix, withdrawal_time in list(withdrawals_timestamps.items()):\n if current_time - withdrawal_time > outage_threshold:\n print(f"Possible outage detected for {withdrawn_prefix} since {withdrawal_time}")\n del withdrawals_timestamps[withdrawn_prefix]"}], "is_classification": false}
{"id": "seed_task_7", "name": "Analyzing BGP Community Frequencies", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc07' collector. Analyze the frequency of different BGP community attributes used in the announcements. Report the top 10 most frequent community values.", "instances": [{"input": "Collect BGP updates from the 'rrc07' collector for October 28, 2023. Count the occurrences of each community attribute in the announcements. Report the top 10 community values by frequency.", "output": "import pybgpstream\nfrom collections import defaultdict\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc07"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\ncommunity_counts = defaultdict(int)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n communities = elem.fields.get('communities', [])\n for community in communities:\n community_str = f"{community[0]}:{community[1]}"\n community_counts[community_str] += 1\n\n# Get the top 10 communities by frequency\ntop_communities = sorted(community_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n\n# Report the top 10 communities\nprint("Top 10 BGP Community Values:")\nfor community, count in top_communities:\n print(f"{community}: {count} occurrences")"}], "is_classification": false}
{"id": "seed_task_8", "name": "Identifying the Top Origin ASNs", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc08' collector. Identify the top 5 origin ASNs announcing the most unique prefixes. Report these ASNs along with the number of unique prefixes they originated.", "instances": [{"input": "Collect BGP updates from the 'rrc08' collector for October 28, 2023. Determine the ASNs that originated the most unique prefixes. Report the top 5 ASNs and the count of unique prefixes they originated.", "output": "import pybgpstream\nfrom collections import defaultdict\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc08"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nasn_prefixes = defaultdict(set)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n origin_asn = as_path[-1] if as_path else None\n if origin_asn and prefix:\n asn_prefixes[origin_asn].add(prefix)\n\n# Calculate the number of unique prefixes per ASN\nasn_prefix_counts = {asn: len(prefixes) for asn, prefixes in asn_prefixes.items()}\n\n# Get the top 5 ASNs by unique prefix count\ntop_asns = sorted(asn_prefix_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n\n# Report the top 5 ASNs\nprint("Top 5 Origin ASNs by Unique Prefixes Announced:")\nfor asn, count in top_asns:\n print(f"ASN {asn}: {count} unique prefixes")"}], "is_classification": false}
{"id": "seed_task_9", "name": "Calculating the Average AS Path Length", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc09' collector. Calculate the average AS path length for all announcements received during the day. Report the average AS path length.", "instances": [{"input": "Collect BGP updates from the 'rrc09' collector for October 28, 2023. For each announcement, record the AS path length. Compute and report the average AS path length over all announcements.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc09"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\ntotal_path_length = 0\ntotal_announcements = 0\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n path_length = len(as_path)\n total_path_length += path_length\n total_announcements += 1\n\n# Calculate and report the average AS path length\nif total_announcements > 0:\n average_path_length = total_path_length / total_announcements\n print(f"Average AS Path Length: {average_path_length}")\nelse:\n print("No announcements found.")"}], "is_classification": false}
{"id": "seed_task_10", "name": "Detecting Flapping Prefixes", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc10' collector. Identify prefixes that have been announced and withdrawn more than 5 times during the day (flapping prefixes). Report these prefixes along with the number of times they flapped.", "instances": [{"input": "Collect BGP updates from the 'rrc10' collector for October 28, 2023. Monitor prefixes that are repeatedly announced and withdrawn. Report prefixes that have flapped more than 5 times and the count of flaps.", "output": "import pybgpstream\nfrom collections import defaultdict\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc10"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nflap_counts = defaultdict(int)\nprevious_states = {}\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n prefix = elem.fields.get('prefix')\n if prefix is None:\n continue\n current_state = elem.type\n last_state = previous_states.get(prefix)\n if last_state and last_state != current_state:\n flap_counts[prefix] += 1\n previous_states[prefix] = current_state\n\n# Identify flapping prefixes\nflapping_prefixes = {prefix: count for prefix, count in flap_counts.items() if count > 5}\n\n# Report flapping prefixes\nprint("Flapping prefixes:")\nfor prefix, count in flapping_prefixes.items():\n print(f"{prefix} flapped {count} times")"}], "is_classification": false}
{"id": "seed_task_11", "name": "Identifying BGP Updates with Specific MED Values", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc11' collector. Identify all announcements where the MED value is greater than 100. Report the prefixes and their corresponding MED values.", "instances": [{"input": "Collect BGP updates from the 'rrc11' collector for October 28, 2023. Find announcements with MED values greater than 100. Report the prefixes and their MED values.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc11"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n med = elem.fields.get('med')\n if med is not None:\n try:\n med_value = int(med)\n if med_value > 100:\n print(f"Prefix {prefix} has MED value {med_value}")\n except ValueError:\n pass # Ignore invalid MED values"}], "is_classification": false}
{"id": "seed_task_12", "name": "Analyzing Prefix Length Distribution", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc12' collector. Analyze the distribution of prefix lengths in the announcements. Report the number of prefixes for each prefix length.", "instances": [{"input": "Collect BGP updates from the 'rrc12' collector for October 28, 2023. Count the number of announced prefixes for each prefix length (e.g., /16, /24). Report the counts per prefix length.", "output": "import pybgpstream\nfrom collections import defaultdict\nimport ipaddress\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc12"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nprefix_length_counts = defaultdict(int)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n if prefix:\n try:\n network = ipaddress.ip_network(prefix)\n prefix_length = network.prefixlen\n prefix_length_counts[prefix_length] += 1\n except ValueError:\n pass # Invalid prefix\n\n# Report the prefix length distribution\nprint("Prefix Length Distribution:")\nfor length in sorted(prefix_length_counts.keys()):\n count = prefix_length_counts[length]\n print(f"/{length}: {count} prefixes")"}], "is_classification": false}
{"id": "seed_task_13", "name": "Monitoring BGP Updates from Specific Peer ASN", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc13' collector. Filter updates that are received from peer ASN 64496. Count the total number of announcements and withdrawals from this peer. Report the counts.", "instances": [{"input": "Collect BGP updates from the 'rrc13' collector for October 28, 2023. Focus on updates from peer ASN '64496'. Count and report the total number of announcements and withdrawals from this peer ASN.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc13"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\npeer_asn_filter = '64496'\nannouncements = 0\nwithdrawals = 0\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n peer_asn = elem.peer_asn\n if peer_asn == peer_asn_filter:\n if elem.type == 'A':\n announcements += 1\n elif elem.type == 'W':\n withdrawals += 1\n\n# Report the counts\nprint(f"Total announcements from peer ASN {peer_asn_filter}: {announcements}")\nprint(f"Total withdrawals from peer ASN {peer_asn_filter}: {withdrawals}")"}], "is_classification": false}
{"id": "seed_task_14", "name": "Identifying Updates with Large AS Paths", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc14' collector. Identify announcements with AS paths longer than 10 ASNs. Report the prefixes and their AS path lengths.", "instances": [{"input": "Collect BGP updates from the 'rrc14' collector for October 28, 2023. Find announcements where the AS path length exceeds 10. Report the prefixes and their AS path lengths.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project="ris",\n collectors=["rrc14"],\n from_time="2023-10-28 00:00:00 UTC",\n until_time="2023-10-28 23:59:59 UTC",\n record_type="updates",\n)\n\nthreshold = 10\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n path_length = len(as_path)\n if path_length > threshold:\n print(f"Prefix {prefix} has AS path length {path_length}")"}], "is_classification": false}
{"id": "seed_task_15", "name": "Monitoring BGP Announcements for Bogon Prefixes", "instruction": "Collect BGP updates on October 15, 2023, from the 'rrc00' collector. Identify announcements of bogon prefixes (e.g., 192.0.2.0/24, 198.51.100.0/24, 203.0.113.0/24). Report any occurrences of these announcements.", "instances": [{"input": "Collect BGP updates from the 'rrc00' collector for October 15, 2023. Identify any announcements of bogon prefixes such as '192.0.2.0/24', '198.51.100.0/24', and '203.0.113.0/24'. Report any instances where these prefixes are announced.", "output": "import pybgpstream\n\nbogon_prefixes = ['192.0.2.0/24', '198.51.100.0/24', '203.0.113.0/24']\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project=\"ris\",\n    collectors=[\"rrc00\"],\n    from_time=\"2023-10-15 00:00:00 UTC\",\n    until_time=\"2023-10-15 23:59:59 UTC\",\n    record_type=\"updates\",\n)\n\n# Loop over the stream of BGP records\nprint(\"Bogon prefixes announced:\")\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            prefix = elem.fields.get('prefix')\n            if prefix in bogon_prefixes:\n                print(f\"Prefix {prefix} announced at {elem.time}\")"}], "is_classification": false}
{"id": "seed_task_16", "name": "Detecting BGP Communities Indicating Blackholing", "instruction": "Collect BGP updates on October 16, 2023, from the 'rrc01' collector. Identify announcements with BGP community attributes that indicate blackholing (e.g., '65535:666'). Report the prefixes associated with these communities.", "instances": [{"input": "Collect BGP updates from the 'rrc01' collector for October 16, 2023. Find announcements with the community attribute '65535:666' indicating blackholing. Report the prefixes that have this community attribute.", "output": "import pybgpstream\n\nblackhole_community = '65535:666'\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project=\"ris\",\n    collectors=[\"rrc01\"],\n    from_time=\"2023-10-16 00:00:00 UTC\",\n    until_time=\"2023-10-16 23:59:59 UTC\",\n    record_type=\"updates\",\n)\n\n# Loop over the stream of BGP records\nprint(\"Prefixes with blackhole community:\")\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            communities = elem.fields.get('communities', [])\n            for community in communities:\n                community_str = f\"{community[0]}:{community[1]}\"\n                if community_str == blackhole_community:\n                    prefix = elem.fields.get('prefix')\n                    print(f\"Prefix {prefix} announced with blackhole community at {elem.time}\")"}], "is_classification": false}
{"id": "seed_task_17", "name": "Calculating the Number of Unique AS Paths", "instruction": "Collect BGP updates on October 17, 2023, from the 'rrc02' collector. For a specific prefix '1.1.1.0/24', calculate the number of unique AS paths observed during the day. Report the total count of unique AS paths.", "instances": [{"input": "Collect BGP updates from the 'rrc02' collector for October 17, 2023. Focus on the prefix '1.1.1.0/24' and record all unique AS paths seen. Calculate and report the number of unique AS paths for this prefix.", "output": "import pybgpstream\n\nprefix_of_interest = '1.1.1.0/24'\nunique_as_paths = set()\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project=\"ris\",\n    collectors=[\"rrc02\"],\n    from_time=\"2023-10-17 00:00:00 UTC\",\n    until_time=\"2023-10-17 23:59:59 UTC\",\n    record_type=\"updates\",\n)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            prefix = elem.fields.get('prefix')\n            if prefix == prefix_of_interest:\n                as_path_str = elem.fields.get('as-path', '')\n                as_path = as_path_str.strip()\n                unique_as_paths.add(as_path)\n\n# Report the total number of unique AS paths\nprint(f\"Total unique AS paths for {prefix_of_interest}: {len(unique_as_paths)}\")"}], "is_classification": false}
{"id": "seed_task_18", "name": "Identifying Announcements with Invalid Origin AS", "instruction": "Collect BGP updates on October 18, 2023, from the 'rrc03' collector. Identify announcements where the origin AS is listed in the bogon ASNs (e.g., AS0, AS23456). Report the prefixes and their invalid origin ASNs.", "instances": [{"input": "Collect BGP updates from the 'rrc03' collector for October 18, 2023. Find announcements where the origin AS is a bogon ASN such as '0' or '23456'. Report the prefixes and their invalid origin ASNs.", "output": "import pybgpstream\n\nbogon_asns = {'0', '23456'}\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project=\"ris\",\n    collectors=[\"rrc03\"],\n    from_time=\"2023-10-18 00:00:00 UTC\",\n    until_time=\"2023-10-18 23:59:59 UTC\",\n    record_type=\"updates\",\n)\n\n# Loop over the stream of BGP records\nprint(\"Announcements with invalid origin ASNs:\")\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            as_path_str = elem.fields.get('as-path', '')\n            as_path = as_path_str.strip().split()\n            origin_asn = as_path[-1] if as_path else None\n            if origin_asn in bogon_asns:\n                prefix = elem.fields.get('prefix')\n                print(f\"Prefix {prefix} announced with invalid origin ASN {origin_asn} at {elem.time}\")"}], "is_classification": false}
{"id": "seed_task_19", "name": "Analyzing BGP Announcements for Specific Prefix Lengths", "instruction": "Collect BGP updates on October 19, 2023, from the 'rrc04' collector. Identify and count announcements for prefixes longer than /24 (i.e., prefixes with prefix length greater than 24). Report the total count of such announcements.", "instances": [{"input": "Collect BGP updates from the 'rrc04' collector for October 19, 2023. Find announcements for prefixes with a prefix length greater than 24. Count and report the total number of these announcements.", "output": "import pybgpstream\nimport ipaddress\n\ntotal_announcements = 0\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project=\"ris\",\n    collectors=[\"rrc04\"],\n    from_time=\"2023-10-19 00:00:00 UTC\",\n    until_time=\"2023-10-19 23:59:59 UTC\",\n    record_type=\"updates\",\n)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            prefix = elem.fields.get('prefix')\n            if prefix:\n                try:\n                    network = ipaddress.ip_network(prefix)\n                    if network.prefixlen > 24:\n                        total_announcements += 1\n                except ValueError:\n                    pass  # Skip invalid prefixes\n\n# Report the total count\nprint(f\"Total announcements for prefixes longer than /24: {total_announcements}\")"}], "is_classification": false}
{"id": "seed_task_20", "name": "Analyzing AS Path Changes for a Specific Prefix", "instruction": "Collect BGP updates on October 20, 2023, from the 'rrc05' collector. Monitor the AS path for the prefix '8.8.8.0/24' and report any changes observed during the day.", "instances": [{"input": "Collect BGP updates from the 'rrc05' collector for October 20, 2023. Focus on the prefix '8.8.8.0/24' and monitor for any AS path changes. Report all instances where the AS path for this prefix changes.", "output": "import pybgpstream\n\nprefix_of_interest = '8.8.8.0/24'\nprevious_as_path = None\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc05'],\n from_time='2023-10-20 00:00:00 UTC',\n until_time='2023-10-20 23:59:59 UTC',\n record_type='updates',\n)\n\nprint(f"Monitoring AS path changes for {prefix_of_interest}:")\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n if prefix == prefix_of_interest:\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip()\n if previous_as_path and as_path != previous_as_path:\n print(f"AS path changed for {prefix}: {previous_as_path} -> {as_path} at {elem.time}")\n previous_as_path = as_path"}], "is_classification": false}
{"id": "seed_task_21", "name": "Detecting BGP Hijacks for Multiple Prefixes", "instruction": "Collect BGP updates on October 21, 2023, from the 'rrc06' collector. Use a list of expected origin ASNs for specific prefixes. Identify any prefixes where the observed origin AS differs from the expected origin AS, and report them as possible hijacks.", "instances": [{"input": "Collect BGP updates from the 'rrc06' collector for October 21, 2023. Use the expected origins: {'10.0.0.0/24': '64512', '172.16.0.0/16': '64513'}. Report any prefixes where the observed origin AS is different from the expected.", "output": "import pybgpstream\n\nexpected_origins = {\n '10.0.0.0/24': '64512',\n '172.16.0.0/16': '64513',\n}\n\nhijacked_prefixes = set()\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc06'],\n from_time='2023-10-21 00:00:00 UTC',\n until_time='2023-10-21 23:59:59 UTC',\n record_type='updates',\n)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n if prefix in expected_origins:\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n observed_origin = as_path[-1] if as_path else None\n expected_origin = expected_origins.get(prefix)\n if observed_origin != expected_origin:\n hijacked_prefixes.add(prefix)\n\n# Report possible hijacked prefixes\nprint("Possible hijacked prefixes:")\nfor prefix in hijacked_prefixes:\n print(f"{prefix}")"}], "is_classification": false}
{"id": "seed_task_22", "name": "Analyzing BGP Communities for Traffic Engineering", "instruction": "Collect BGP updates on October 22, 2023, from the 'rrc07' collector. Identify announcements with BGP community attributes used for traffic engineering (e.g., '65000:80', '65000:90'). Report the prefixes and their associated communities.", "instances": [{"input": "Collect BGP updates from the 'rrc07' collector for October 22, 2023. Find announcements with community attributes '65000:80' or '65000:90' indicating traffic engineering. Report the prefixes and their communities.", "output": "import pybgpstream\n\ntraffic_engineering_communities = {'65000:80', '65000:90'}\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc07'],\n from_time='2023-10-22 00:00:00 UTC',\n until_time='2023-10-22 23:59:59 UTC',\n record_type='updates',\n)\n\nprint("Prefixes with traffic engineering communities:")\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n communities = elem.fields.get('communities', [])\n for community in communities:\n community_str = f"{community[0]}:{community[1]}"\n if community_str in traffic_engineering_communities:\n print(f"Prefix {prefix} has community {community_str}")"}], "is_classification": false}
{"id": "seed_task_23", "name": "Identifying Announcements with Private ASNs in AS Path", "instruction": "Collect BGP updates on October 23, 2023, from the 'rrc08' collector. Identify announcements where the AS path includes private ASNs (64512-65534). Report the prefixes and their AS paths containing private ASNs.", "instances": [{"input": "Collect BGP updates from the 'rrc08' collector for October 23, 2023. Find announcements where the AS path contains private ASNs. Report the prefixes and their AS paths with private ASNs.", "output": "import pybgpstream\n\nprivate_asns = set(str(asn) for asn in range(64512, 65535))\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc08'],\n from_time='2023-10-23 00:00:00 UTC',\n until_time='2023-10-23 23:59:59 UTC',\n record_type='updates',\n)\n\nprint("Announcements with private ASNs in AS path:")\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n as_path_str = elem.fields.get('as-path', '')\n as_path = as_path_str.strip().split()\n if any(asn in private_asns for asn in as_path):\n print(f"Prefix {prefix} has AS path {as_path_str} containing private ASNs")"}], "is_classification": false}
{"id": "seed_task_24", "name": "Monitoring BGP Announcements for Specific Next-Hop IP", "instruction": "Collect BGP updates on October 24, 2023, from the 'rrc09' collector. Identify announcements where the next-hop IP address is '192.0.2.1'. Report the prefixes associated with this next-hop IP.", "instances": [{"input": "Collect BGP updates from the 'rrc09' collector for October 24, 2023. Find announcements where the next-hop IP is '192.0.2.1'. Report the prefixes using this next-hop IP address.", "output": "import pybgpstream\n\nnext_hop_filter = '192.0.2.1'\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc09'],\n from_time='2023-10-24 00:00:00 UTC',\n until_time='2023-10-24 23:59:59 UTC',\n record_type='updates',\n)\n\nprint(f"Prefixes with next-hop IP {next_hop_filter}:")\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n next_hop = elem.fields.get('next-hop')\n if next_hop == next_hop_filter:\n print(f"Prefix {prefix} announced with next-hop IP {next_hop}")"}], "is_classification": false}
{"id": "seed_task_25", "name": "Calculating Average Local Preference", "instruction": "Collect BGP updates on October 25, 2023, from the 'rrc10' collector. For all announcements that include a Local Preference attribute, calculate the average Local Preference value. Report the result.", "instances": [{"input": "Collect BGP updates from the 'rrc10' collector for October 25, 2023. Extract the Local Preference values from announcements that have this attribute. Compute and report the average Local Preference.", "output": "import pybgpstream\n\nlocal_pref_values = []\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc10'],\n from_time='2023-10-25 00:00:00 UTC',\n until_time='2023-10-25 23:59:59 UTC',\n record_type='updates',\n)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n local_pref = elem.fields.get('local-pref')\n if local_pref is not None:\n try:\n local_pref_values.append(int(local_pref))\n except ValueError:\n pass # Ignore invalid values\n\n# Calculate and report the average Local Preference\nif local_pref_values:\n average_local_pref = sum(local_pref_values) / len(local_pref_values)\n print(f"Average Local Preference: {average_local_pref}")\nelse:\n print("No Local Preference values found in the announcements.")"}], "is_classification": false}
{"id": "seed_task_26", "name": "Analyzing BGP Updates for IPv6 Prefixes", "instruction": "Collect BGP updates on October 26, 2023, from the 'rrc11' collector. Identify and count announcements for IPv6 prefixes. Report the total number of IPv6 announcements.", "instances": [{"input": "Collect BGP updates from the 'rrc11' collector for October 26, 2023. Focus on announcements of IPv6 prefixes. Count and report the total number of IPv6 prefix announcements.", "output": "import pybgpstream\nimport ipaddress\n\ntotal_ipv6_announcements = 0\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project='ris',\n    collectors=['rrc11'],\n    from_time='2023-10-26 00:00:00 UTC',\n    until_time='2023-10-26 23:59:59 UTC',\n    record_type='updates',\n)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            prefix = elem.fields.get('prefix')\n            if prefix:\n                try:\n                    network = ipaddress.ip_network(prefix)\n                    if network.version == 6:\n                        total_ipv6_announcements += 1\n                except ValueError:\n                    pass  # Skip invalid prefixes\n\n# Report the total count\nprint(f\"Total IPv6 announcements: {total_ipv6_announcements}\")"}], "is_classification": false}
{"id": "seed_task_27", "name": "Monitoring BGP Updates for Specific AS Path Length", "instruction": "Collect BGP updates on October 27, 2023, from the 'rrc12' collector. Identify announcements where the AS path length is exactly 5. Report the prefixes and their AS paths.", "instances": [{"input": "Collect BGP updates from the 'rrc12' collector for October 27, 2023. Find announcements with AS path length equal to 5. Report the prefixes and their corresponding AS paths.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project='ris',\n    collectors=['rrc12'],\n    from_time='2023-10-27 00:00:00 UTC',\n    until_time='2023-10-27 23:59:59 UTC',\n    record_type='updates',\n)\n\npath_length_target = 5\n\n# Loop over the stream of BGP records\nprint(f\"Announcements with AS path length {path_length_target}:\")\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            prefix = elem.fields.get('prefix')\n            as_path_str = elem.fields.get('as-path', '')\n            as_path = as_path_str.strip().split()\n            if len(as_path) == path_length_target:\n                print(f\"Prefix {prefix} has AS path: {' -> '.join(as_path)}\")"}], "is_classification": false}
{"id": "seed_task_28", "name": "Identifying BGP Announcements with AS_SET in AS Path", "instruction": "Collect BGP updates on October 28, 2023, from the 'rrc13' collector. Identify announcements where the AS path includes AS_SET segments (denoted by curly braces '{}'). Report the prefixes and their AS paths.", "instances": [{"input": "Collect BGP updates from the 'rrc13' collector for October 28, 2023. Find announcements where the AS path contains AS_SET segments. Report the prefixes and their AS paths.", "output": "import pybgpstream\nimport re\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project='ris',\n    collectors=['rrc13'],\n    from_time='2023-10-28 00:00:00 UTC',\n    until_time='2023-10-28 23:59:59 UTC',\n    record_type='updates',\n)\n\n# Pattern to detect AS_SET\nas_set_pattern = re.compile(r'\\{.*?\\}')\n\nprint(\"Announcements with AS_SET in AS path:\")\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            prefix = elem.fields.get('prefix')\n            as_path_str = elem.fields.get('as-path', '')\n            if as_set_pattern.search(as_path_str):\n                print(f\"Prefix {prefix} has AS path with AS_SET: {as_path_str}\")"}], "is_classification": false}
{"id": "seed_task_29", "name": "Analyzing BGP Withdrawals Over Time", "instruction": "Collect BGP updates on October 29, 2023, from the 'rrc14' collector. Count the number of withdrawals per hour. Report the withdrawal counts for each hour of the day.", "instances": [{"input": "Collect BGP updates from the 'rrc14' collector for October 29, 2023. Tally the number of withdrawal messages received each hour. Provide a report showing the count of withdrawals for each hour.", "output": "import pybgpstream\nfrom collections import defaultdict\nfrom datetime import datetime\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project='ris',\n    collectors=['rrc14'],\n    from_time='2023-10-29 00:00:00 UTC',\n    until_time='2023-10-29 23:59:59 UTC',\n    record_type='updates',\n)\n\nwithdrawals_per_hour = defaultdict(int)\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'W':\n            elem_time = datetime.utcfromtimestamp(elem.time)\n            hour = elem_time.strftime('%Y-%m-%d %H:00')\n            withdrawals_per_hour[hour] += 1\n\n# Report the withdrawal counts per hour\nprint(\"Withdrawals per hour:\")\nfor hour in sorted(withdrawals_per_hour.keys()):\n    count = withdrawals_per_hour[hour]\n    print(f\"{hour}: {count} withdrawals\")"}], "is_classification": false}
{"id": "seed_task_30", "name": "Identifying BGP Announcements with Missing AS_PATH", "instruction": "Collect BGP updates on October 30, 2023, from the 'rrc15' collector. Identify announcements where the AS_PATH attribute is missing or empty. Report the prefixes with missing AS_PATH.", "instances": [{"input": "Collect BGP updates from the 'rrc15' collector for October 30, 2023. Find announcements that lack an AS_PATH attribute. Report the prefixes for which AS_PATH is missing or empty.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n    project='ris',\n    collectors=['rrc15'],\n    from_time='2023-10-30 00:00:00 UTC',\n    until_time='2023-10-30 23:59:59 UTC',\n    record_type='updates',\n)\n\nprint(\"Announcements with missing or empty AS_PATH:\")\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n    for elem in rec:\n        if elem.type == 'A':\n            as_path_str = elem.fields.get('as-path')\n            if not as_path_str:\n                prefix = elem.fields.get('prefix')\n                print(f\"Prefix {prefix} has missing or empty AS_PATH\")"}], "is_classification": false}
{"id": "seed_task_31", "name": "Analyzing BGP Announcements for RPKI Invalids", "instruction": "Collect BGP updates on October 31, 2023, from the 'rrc00' collector. Identify announcements that are RPKI invalid, where the prefix and origin AS do not match the ROA records. Report the prefixes and origin ASNs.", "instances": [{"input": "Collect BGP updates from the 'rrc00' collector for October 31, 2023. Identify announcements that are RPKI invalid, where the prefix and origin AS do not match the ROA records. Report the prefixes and origin ASNs.", "output": "import pybgpstream\n\n# Placeholder function for RPKI validation\ndef is_rpki_invalid(prefix, origin_asn):\n # Implement RPKI validation logic here\n # Return True if the prefix and origin ASN combination is RPKI invalid\n # For demonstration purposes, this function always returns False\n return False\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc00'],\n from_time='2023-10-31 00:00:00 UTC',\n until_time='2023-10-31 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('RPKI Invalid Announcements:')\n\n# Loop over the stream of BGP records\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n prefix = elem.fields.get('prefix')\n as_path = elem.fields.get('as-path', '')\n if as_path:\n origin_asn = as_path.strip().split()[-1]\n if is_rpki_invalid(prefix, origin_asn):\n print(f'Prefix {prefix} with origin ASN {origin_asn} is RPKI invalid')"}], "is_classification": false}
{"id": "seed_task_32", "name": "Detecting Potential DDoS Attack Patterns", "instruction": "Collect BGP updates on November 1, 2023, from the 'rrc01' collector. Analyze the frequency of announcements and withdrawals for prefixes. Identify prefixes with sudden spikes in updates, indicating possible DDoS attack mitigations. Report these prefixes and time intervals.", "instances": [{"input": "Collect BGP updates from the 'rrc01' collector for November 1, 2023. Analyze the frequency of announcements and withdrawals for prefixes. Identify prefixes with sudden spikes in updates. Report these prefixes and time intervals.", "output": "import pybgpstream\nimport pandas as pd\nfrom datetime import datetime\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc01'],\n from_time='2023-11-01 00:00:00 UTC',\n until_time='2023-11-01 23:59:59 UTC',\n record_type='updates',\n)\n\n# Initialize data structures\ndata = []\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n timestamp = datetime.utcfromtimestamp(elem.time)\n prefix = elem.fields.get('prefix')\n data.append({'timestamp': timestamp, 'prefix': prefix, 'type': elem.type})\n\n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Group by prefix and time intervals\ndf.set_index('timestamp', inplace=True)\nupdates_per_interval = df.groupby(['prefix', pd.Grouper(freq='15Min')]).size().reset_index(name='update_count')\n\n# Identify prefixes with spikes\nthreshold = updates_per_interval['update_count'].mean() + 3 * updates_per_interval['update_count'].std()\nanomalies = updates_per_interval[updates_per_interval['update_count'] > threshold]\n\n# Report anomalies\nprint('Prefixes with sudden spikes in updates:')\nfor index, row in anomalies.iterrows():\n print(f\"Prefix {row['prefix']} had {row['update_count']} updates at {row['timestamp']}\")"}], "is_classification": false}
{"id": "seed_task_33", "name": "Monitoring Prefix Deaggregation", "instruction": "Collect BGP updates on November 2, 2023, from the 'rrc02' collector. Identify cases where a prefix is announced with more specific sub-prefixes than usual. Report the prefixes and their sub-prefixes.", "instances": [{"input": "Collect BGP updates from the 'rrc02' collector for November 2, 2023. Identify prefixes announced with more specific sub-prefixes than usual. Report these prefixes and their sub-prefixes.", "output": "import pybgpstream\nfrom netaddr import IPSet, IPNetwork\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc02'],\n from_time='2023-11-02 00:00:00 UTC',\n until_time='2023-11-02 23:59:59 UTC',\n record_type='updates',\n)\n\n# Initialize data structures\nprefixes = {}\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n prefix = elem.fields.get('prefix')\n if prefix:\n supernet = str(IPNetwork(prefix).supernet())\n if supernet not in prefixes:\n prefixes[supernet] = set()\n prefixes[supernet].add(prefix)\n\n# Identify deaggregation cases\nprint('Prefixes with deaggregation:')\nfor supernet, subnets in prefixes.items():\n if len(subnets) > 1:\n print(f'Supernet: {supernet}')\n for subnet in subnets:\n print(f' Sub-prefix: {subnet}')}"], "is_classification": false}
{"id": "seed_task_34", "name": "Analyzing AS Relationships", "instruction": "Collect BGP updates on November 3, 2023, from the 'rrc03' collector. Build a graph of AS relationships based on the AS paths observed. Identify and report any new or unexpected AS relationships.", "instances": [{"input": "Collect BGP updates from the 'rrc03' collector for November 3, 2023. Build a graph of AS relationships from the AS paths. Identify and report new or unexpected AS relationships.", "output": "import pybgpstream\nimport networkx as nx\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc03'],\n from_time='2023-11-03 00:00:00 UTC',\n until_time='2023-11-03 23:59:59 UTC',\n record_type='updates',\n)\n\n# Initialize AS graph\nas_graph = nx.Graph()\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n as_path = elem.fields.get('as-path', '')\n if as_path:\n asns = as_path.strip().split()\n edges = zip(asns[:-1], asns[1:])\n as_graph.add_edges_from(edges)\n\n# Identify new relationships (placeholder logic)\n# In a real scenario, compare with a known baseline of AS relationships\nprint('AS Relationships:')\nfor edge in as_graph.edges():\n print(f'AS{edge[0]} - AS{edge[1]}')"}], "is_classification": false}
{"id": "seed_task_35", "name": "Detecting Unusually Long AS Paths", "instruction": "Collect BGP updates on November 4, 2023, from the 'rrc04' collector. Identify announcements with AS paths significantly longer than the average. Report the prefixes and their AS paths.", "instances": [{"input": "Collect BGP updates from the 'rrc04' collector for November 4, 2023. Identify announcements with AS paths longer than the average. Report the prefixes and their AS paths.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc04'],\n from_time='2023-11-04 00:00:00 UTC',\n until_time='2023-11-04 23:59:59 UTC',\n record_type='updates',\n)\n\n# Collect AS path lengths\nas_path_lengths = []\nannouncements = []\n\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n as_path = elem.fields.get('as-path', '')\n if as_path:\n length = len(as_path.strip().split())\n as_path_lengths.append(length)\n announcements.append({'prefix': elem.fields.get('prefix'), 'as_path': as_path, 'length': length})\n\n# Calculate average AS path length\naverage_length = sum(as_path_lengths) / len(as_path_lengths)\n\n# Identify unusually long AS paths\nthreshold = average_length + 3\nprint('Announcements with unusually long AS paths:')\nfor ann in announcements:\n if ann['length'] > threshold:\n print(f\"Prefix {ann['prefix']} with AS path {ann['as_path']}\")"}], "is_classification": false}
{"id": "seed_task_36", "name": "Monitoring BGP Updates for Specific Country Code", "instruction": "Collect BGP updates on November 5, 2023, from the 'rrc05' collector. Filter announcements where the origin AS is registered in a specific country, such as 'US'. Report the number of such announcements.", "instances": [{"input": "Collect BGP updates from the 'rrc05' collector for November 5, 2023. Filter announcements where the origin AS is registered in 'US'. Report the number of such announcements.", "output": "import pybgpstream\nimport requests\n\n# Function to get country code for an ASN\ndef get_country_code(asn):\n # Placeholder function\n # In practice, use a service or database to map ASN to country code\n return 'US' # For demonstration, assume all ASNs are 'US'\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc05'],\n from_time='2023-11-05 00:00:00 UTC',\n until_time='2023-11-05 23:59:59 UTC',\n record_type='updates',\n)\n\ncount = 0\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'A':\n as_path = elem.fields.get('as-path', '')\n if as_path:\n origin_asn = as_path.strip().split()[-1]\n country_code = get_country_code(origin_asn)\n if country_code == 'US':\n count += 1\n\nprint(f'Total announcements with origin AS in US: {count}')"}], "is_classification": false}
{"id": "seed_task_37", "name": "Identifying BGP Updates with Large Communities", "instruction": "Collect BGP updates on November 6, 2023, from the 'rrc06' collector. Identify announcements that include BGP Large Community attributes. Report the prefixes and their Large Communities.", "instances": [{"input": "Collect BGP updates from the 'rrc06' collector for November 6, 2023. Identify announcements with BGP Large Community attributes. Report the prefixes and their Large Communities.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc06'],\n from_time='2023-11-06 00:00:00 UTC',\n until_time='2023-11-06 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Announcements with BGP Large Communities:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n communities = elem.fields.get('large-communities')\n if communities:\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} has Large Communities {communities}')"}], "is_classification": false}
{"id": "seed_task_38", "name": "Analyzing BGP AS Path Loops", "instruction": "Collect BGP updates on November 7, 2023, from the 'rrc07' collector. Identify AS paths that contain loops, where the same ASN appears more than once non-consecutively. Report the prefixes and AS paths.", "instances": [{"input": "Collect BGP updates from the 'rrc07' collector for November 7, 2023. Identify AS paths with loops. Report the prefixes and AS paths.", "output": "import pybgpstream\n\n# Function to check for AS path loops\ndef has_as_path_loop(as_path):\n asns = as_path.strip().split()\n seen = set()\n for asn in asns:\n if asn in seen:\n return True\n seen.add(asn)\n return False\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc07'],\n from_time='2023-11-07 00:00:00 UTC',\n until_time='2023-11-07 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('AS Paths with loops:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n as_path = elem.fields.get('as-path', '')\n if as_path and has_as_path_loop(as_path):\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} with AS path {as_path}')"}], "is_classification": false}
{"id": "seed_task_39", "name": "Monitoring BGP Announcements for Deprecated Attributes", "instruction": "Collect BGP updates on November 8, 2023, from the 'rrc08' collector. Identify announcements that include deprecated BGP attributes. Report the prefixes and the deprecated attributes used.", "instances": [{"input": "Collect BGP updates from the 'rrc08' collector for November 8, 2023. Identify announcements with deprecated BGP attributes. Report the prefixes and the attributes.", "output": "import pybgpstream\n\n# List of deprecated BGP attributes\ndeprecated_attributes = ['atomic-aggregate']\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc08'],\n from_time='2023-11-08 00:00:00 UTC',\n until_time='2023-11-08 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Announcements with deprecated attributes:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n attributes = elem.fields\n deprecated_used = [attr for attr in deprecated_attributes if attr in attributes]\n if deprecated_used:\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} uses deprecated attributes {deprecated_used}')"}], "is_classification": false}
{"id": "seed_task_40", "name": "Calculating Prefix Reachability", "instruction": "Collect BGP updates on November 9, 2023, from the 'rrc09' collector. For a set of prefixes, determine the percentage of peers that have a route to each prefix. Report the prefixes and their reachability percentages.", "instances": [{"input": "Collect BGP updates from the 'rrc09' collector for November 9, 2023. Determine the percentage of peers with a route to each prefix. Report the prefixes and reachability percentages.", "output": "import pybgpstream\n\n# List of prefixes to check\nprefix_list = ['1.1.1.0/24', '8.8.8.0/24']\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc09'],\n from_time='2023-11-09 00:00:00 UTC',\n until_time='2023-11-09 23:59:59 UTC',\n record_type='rib',\n)\n\n# Initialize data structures\npeer_counts = {}\n\n# Collect data\nfor rec in stream.records():\n peer_asn = rec.peer_asn\n for elem in rec:\n prefix = elem.fields.get('prefix')\n if prefix in prefix_list:\n if prefix not in peer_counts:\n peer_counts[prefix] = set()\n peer_counts[prefix].add(peer_asn)\n\n# Total number of peers\ntotal_peers = len(set([rec.peer_asn for rec in stream.records()]))\n\n# Calculate reachability\nprint('Prefix Reachability Percentages:')\nfor prefix, peers in peer_counts.items():\n percentage = (len(peers) / total_peers) * 100 if total_peers > 0 else 0\n print(f'Prefix {prefix} is reachable by {percentage:.2f}% of peers')"}], "is_classification": false}
{"id": "seed_task_41", "name": "Detecting BGP Updates with Invalid NEXT_HOP", "instruction": "Collect BGP updates on November 10, 2023, from the 'rrc10' collector. Identify announcements where the NEXT_HOP attribute contains an invalid IP address. Report the prefixes and the invalid NEXT_HOP values.", "instances": [{"input": "Collect BGP updates from the 'rrc10' collector for November 10, 2023. Identify announcements with invalid NEXT_HOP IP addresses. Report the prefixes and NEXT_HOP values.", "output": "import pybgpstream\nimport ipaddress\n\n# Function to check if IP is valid\ndef is_valid_ip(ip):\n try:\n ipaddress.ip_address(ip)\n return True\n except ValueError:\n return False\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc10'],\n from_time='2023-11-10 00:00:00 UTC',\n until_time='2023-11-10 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Announcements with invalid NEXT_HOP:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n next_hop = elem.fields.get('next-hop')\n if next_hop and not is_valid_ip(next_hop):\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} with invalid NEXT_HOP {next_hop}')"}], "is_classification": false}
{"id": "seed_task_42", "name": "Analyzing BGP Attributes for AS_PATH Aggregation", "instruction": "Collect BGP updates on November 11, 2023, from the 'rrc11' collector. Identify announcements where the AS_PATH indicates aggregation, such as the presence of AS_CONFED_SET. Report the prefixes and AS paths.", "instances": [{"input": "Collect BGP updates from the 'rrc11' collector for November 11, 2023. Identify announcements with AS_PATH aggregation indicators. Report the prefixes and AS paths.", "output": "import pybgpstream\nimport re\n\n# Regex pattern to detect AS_CONFED_SET or AS_SET (curly braces)\npattern = re.compile(r'\\{.*?\\}')\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc11'],\n from_time='2023-11-11 00:00:00 UTC',\n until_time='2023-11-11 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Announcements indicating AS_PATH aggregation:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n as_path = elem.fields.get('as-path', '')\n if as_path and pattern.search(as_path):\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} with AS path {as_path}')"}], "is_classification": false}
{"id": "seed_task_43", "name": "Monitoring BGP Announcements for Specific Origin Validation State", "instruction": "Collect BGP updates on November 12, 2023, from the 'rrc12' collector. Identify announcements with an origin validation state of 'unknown'. Report the prefixes and origin ASNs.", "instances": [{"input": "Collect BGP updates from the 'rrc12' collector for November 12, 2023. Identify announcements with origin validation state 'unknown'. Report the prefixes and origin ASNs.", "output": "import pybgpstream\n\n# Configure BGPStream with origin validation (placeholder)\n# Note: Actual origin validation requires additional data\n\nprint('Announcements with origin validation state unknown:')\n\n# Since pybgpstream does not support origin validation natively,\n# we assume that the origin validation state is available\n# For demonstration purposes, this script will not perform real validation"}], "is_classification": false}
{"id": "seed_task_44", "name": "Identifying BGP Updates with Unusually High LOCAL_PREF", "instruction": "Collect BGP updates on November 13, 2023, from the 'rrc13' collector. Identify announcements where the LOCAL_PREF attribute is set higher than 1000. Report the prefixes and their LOCAL_PREF values.", "instances": [{"input": "Collect BGP updates from the 'rrc13' collector for November 13, 2023. Identify announcements with LOCAL_PREF higher than 1000. Report the prefixes and LOCAL_PREF values.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc13'],\n from_time='2023-11-13 00:00:00 UTC',\n until_time='2023-11-13 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Announcements with LOCAL_PREF > 1000:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n local_pref = elem.fields.get('local-pref')\n if local_pref and int(local_pref) > 1000:\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} with LOCAL_PREF {local_pref}')"}], "is_classification": false}
{"id": "seed_task_45", "name": "Analyzing BGP Update Inter-arrival Times", "instruction": "Collect BGP updates on November 14, 2023, from the 'rrc14' collector. For a set of prefixes, calculate the inter-arrival times of updates. Identify prefixes with unusually short inter-arrival times. Report these prefixes.", "instances": [{"input": "Collect BGP updates from the 'rrc14' collector for November 14, 2023. Calculate inter-arrival times for updates. Identify prefixes with short inter-arrival times. Report these prefixes.", "output": "import pybgpstream\nfrom datetime import datetime\n\n# List of prefixes to monitor\nprefix_list = ['1.1.1.0/24', '8.8.8.0/24']\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc14'],\n from_time='2023-11-14 00:00:00 UTC',\n until_time='2023-11-14 23:59:59 UTC',\n record_type='updates',\n)\n\n# Initialize data structures\ntimestamps = {prefix: [] for prefix in prefix_list}\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n prefix = elem.fields.get('prefix')\n if prefix in prefix_list:\n timestamp = datetime.utcfromtimestamp(elem.time)\n timestamps[prefix].append(timestamp)\n\n# Calculate inter-arrival times\nprint('Prefixes with short inter-arrival times:')\nfor prefix, times in timestamps.items():\n times.sort()\n intervals = [(times[i+1] - times[i]).total_seconds() for i in range(len(times)-1)]\n if intervals:\n min_interval = min(intervals)\n if min_interval < 60: # Threshold in seconds\n print(f'Prefix {prefix} has a minimum inter-arrival time of {min_interval} seconds')"}], "is_classification": false}
{"id": "seed_task_46", "name": "Monitoring BGP Withdrawals for Specific ASN", "instruction": "Collect BGP updates on November 15, 2023, from the 'rrc15' collector. Identify withdrawals where ASN 64500 is present in the AS path before withdrawal. Report the prefixes withdrawn.", "instances": [{"input": "Collect BGP updates from the 'rrc15' collector for November 15, 2023. Identify withdrawals with ASN 64500 in the AS path. Report the prefixes withdrawn.", "output": "import pybgpstream\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc15'],\n from_time='2023-11-15 00:00:00 UTC',\n until_time='2023-11-15 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Withdrawals with ASN 64500 in AS path:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n if elem.type == 'W':\n as_path = elem.fields.get('as-path', '')\n if '64500' in as_path.split():\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} withdrawn with ASN 64500 in AS path')"}], "is_classification": false}
{"id": "seed_task_47", "name": "Detecting Announcements with Conflicting Origin ASNs", "instruction": "Collect BGP updates on November 16, 2023, from the 'rrc00' collector. For prefixes expected to be originated by a specific AS, identify any announcements where the origin ASN differs. Report the prefixes and observed origin ASNs.", "instances": [{"input": "Collect BGP updates from the 'rrc00' collector for November 16, 2023. For known prefixes, identify announcements where the origin ASN differs from expected. Report these prefixes and origin ASNs.", "output": "import pybgpstream\n\n# Expected origin ASNs for prefixes\nexpected_origins = {\n '1.1.1.0/24': '13335',\n '8.8.8.0/24': '15169',\n}\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc00'],\n from_time='2023-11-16 00:00:00 UTC',\n until_time='2023-11-16 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Announcements with conflicting origin ASNs:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n prefix = elem.fields.get('prefix')\n if prefix in expected_origins:\n as_path = elem.fields.get('as-path', '')\n if as_path:\n origin_asn = as_path.strip().split()[-1]\n if origin_asn != expected_origins[prefix]:\n print(f'Prefix {prefix} expected origin {expected_origins[prefix]}, observed {origin_asn}')"}], "is_classification": false}
{"id": "seed_task_48", "name": "Analyzing BGP Updates for Specific AFI/SAFI", "instruction": "Collect BGP updates on November 17, 2023, from the 'rrc01' collector. Filter updates for a specific Address Family Identifier (AFI) and Subsequent Address Family Identifier (SAFI). Report the number of updates for each AFI/SAFI combination.", "instances": [{"input": "Collect BGP updates from the 'rrc01' collector for November 17, 2023. Filter updates for specific AFI/SAFI values. Report the number of updates for each combination.", "output": "import pybgpstream\n\n# Note: pybgpstream does not directly expose AFI/SAFI filtering\n# For demonstration, we will simulate the filtering process\n\nprint('Number of updates for each AFI/SAFI combination:')\n\n# Placeholder output\nprint('AFI 1/SAFI 1: 1000 updates')\nprint('AFI 2/SAFI 1: 500 updates')"}], "is_classification": false}
{"id": "seed_task_49", "name": "Monitoring BGP Announcements for New Prefixes", "instruction": "Collect BGP updates on November 18, 2023, from the 'rrc02' collector. Identify prefixes that have not been seen in the routing table before. Report these new prefixes and their origin ASNs.", "instances": [{"input": "Collect BGP updates from the 'rrc02' collector for November 18, 2023. Identify new prefixes not seen before. Report these prefixes and their origin ASNs.", "output": "import pybgpstream\n\n# Assume we have a set of known prefixes\nknown_prefixes = set()\n\n# Configure BGPStream for previous day to build known prefixes\nstream_prev = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc02'],\n from_time='2023-11-17 00:00:00 UTC',\n until_time='2023-11-17 23:59:59 UTC',\n record_type='rib',\n)\n\nfor rec in stream_prev.records():\n for elem in rec:\n prefix = elem.fields.get('prefix')\n if prefix:\n known_prefixes.add(prefix)\n\n# Configure BGPStream for the target day\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc02'],\n from_time='2023-11-18 00:00:00 UTC',\n until_time='2023-11-18 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('New prefixes announced:')\n\n# Collect data\nnew_prefixes = {}\nfor rec in stream.records():\n for elem in rec:\n prefix = elem.fields.get('prefix')\n if prefix and prefix not in known_prefixes:\n as_path = elem.fields.get('as-path', '')\n origin_asn = as_path.strip().split()[-1] if as_path else 'Unknown'\n new_prefixes[prefix] = origin_asn\n\nfor prefix, origin_asn in new_prefixes.items():\n print(f'Prefix {prefix} with origin ASN {origin_asn} is new')"}], "is_classification": false}
{"id": "seed_task_50", "name": "Detecting BGP Updates with Invalid AS_PATH Syntax", "instruction": "Collect BGP updates on November 19, 2023, from the 'rrc03' collector. Identify announcements where the AS_PATH attribute contains invalid syntax, such as non-numeric values. Report the prefixes and the invalid AS_PATH values.", "instances": [{"input": "Collect BGP updates from the 'rrc03' collector for November 19, 2023. Identify announcements with invalid AS_PATH syntax. Report the prefixes and AS_PATH values.", "output": "import pybgpstream\n\n# Function to check AS_PATH syntax\ndef is_valid_as_path(as_path):\n asns = as_path.strip().split()\n for asn in asns:\n if not asn.isdigit() and not (asn.startswith('{') and asn.endswith('}')):\n return False\n return True\n\n# Configure BGPStream\nstream = pybgpstream.BGPStream(\n project='ris',\n collectors=['rrc03'],\n from_time='2023-11-19 00:00:00 UTC',\n until_time='2023-11-19 23:59:59 UTC',\n record_type='updates',\n)\n\nprint('Announcements with invalid AS_PATH syntax:')\n\n# Collect data\nfor rec in stream.records():\n for elem in rec:\n as_path = elem.fields.get('as-path', '')\n if as_path and not is_valid_as_path(as_path):\n prefix = elem.fields.get('prefix')\n print(f'Prefix {prefix} with invalid AS_PATH {as_path}')"}], "is_classification": false}