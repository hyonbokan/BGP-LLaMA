{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "import transformers\n",
    "import os\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "# model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "# model_id = 'codellama/CodeLlama-7b-hf'\n",
    "# model_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "new_model = \"/home/hb/dataset_bgp/llm_finetuned/llama2-7b-table135-20split-10k-instruct\"\n",
    "\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    ")\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import (\n",
    "#     AutoModelForCausalLM,\n",
    "#     AutoTokenizer,\n",
    "#     pipeline,\n",
    "#     logging,\n",
    "# )\n",
    "# import transformers\n",
    "# import os\n",
    "\n",
    "# model_id = 'hyonbokan/BGP-LLaMA13-BGPStream10k-cutoff-1024-max-2048-fpFalse'\n",
    "\n",
    "# # Need auth token for these\n",
    "# hf_auth = os.environ.get('hf_token')\n",
    "\n",
    "# model_config = transformers.AutoConfig.from_pretrained(\n",
    "#     model_id,\n",
    "#     use_auth_token=hf_auth\n",
    "# )\n",
    "\n",
    "# model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     trust_remote_code=True,\n",
    "#     config=model_config,\n",
    "#     # quantization_config=bnb_config,\n",
    "#     device_map='auto',\n",
    "#     use_auth_token=hf_auth\n",
    "# )\n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "#     model_id,\n",
    "#     use_auth_token=hf_auth\n",
    "# )\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/10\n",
      "Processed 2/10\n",
      "Processed 3/10\n",
      "Processed 4/10\n",
      "Processed 5/10\n",
      "Processed 6/10\n",
      "Processed 7/10\n",
      "Processed 8/10\n",
      "Processed 9/10\n",
      "Processed 10/10\n",
      "[{'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 07:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 07:05:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | [SEP] row 3: | 2022-03-28 07:10:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 07:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 07:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 07:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 07:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 07:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2022-03-28 07:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 07:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 07:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 07:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 08:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 08:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 08:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 08:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 08:20:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | [SEP] row 18: | 2022-03-28 08:25:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 08:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2022-03-28 08:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data.\\n\\nThe first anomaly is detected at 2022-03-28 07:20:00, with num_withdrawals=7 and max_path_length=0.0. This indicates that there were 7 route withdrawals without any corresponding route announcements, which is unusual and could indicate a routing issue or a change in network topology.\\n\\nThe second anomaly is detected at 2022-03-28 07:25:00, with num_withdrawals=0 and avg_path_length=0.0. This suggests that there were no route withdrawals, but the average path length was 0.0, which is unusual and could indicate a change in network topology or routing behavior.\\n\\nThe third anomaly is detected at 2022-03-28 08:10:00, with num_routes=7 and num_origin_changes=7. This indicates that there were 7 new routes announced and 7 origin changes, which is a high number of both types of events and could indicate a high level of routing activity or changes in network topology.\\n\\nThe reason for these anomalies is that high values of num_withdrawals without any corresponding route announcements (anomaly at 2022-03-28 07:20:00), high average path length without any corresponding route changes (anomaly at 2022-03-28 07:25:00), and high numbers of new routes and origin changes (anomaly at 2022-03-28 08:10:00) are unusual and could indicate changes in network topology or routing behavior.\\n\\nTherefore, the anomalies are detected at 2022-03-28 07:20:00, 2022-03-28 07:25:00, and 2022-03-28 08:10:00.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 08:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 08:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 08:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 08:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 09:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 09:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 09:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 09:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2022-03-28 09:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 09:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 09:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 09:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 09:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 09:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 09:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 09:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 10:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 10:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 19: | 2022-03-28 10:10:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 20: | 2022-03-28 10:15:00 | 8342 | 10 | 10 | 17 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 41 | 10 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data for ASN 8342.\\n\\nThe first anomaly is detected at timestamp 2022-03-28 09:45:00, where the number of origin changes (num_origin_changes) is 40, which is much higher than the average origin change value of 10.5. This indicates that there were a large number of changes in the routes announced by this ASN during this time period, which could be a sign of route leaks or other issues.\\n\\nAnother anomaly is detected at timestamp 2022-03-28 10:15:00, where the maximum path length (max_path_length) is 10, and the average path length (avg_path_length) is 4.889748326103627, which is much lower than the average path length of 3.628807699092614. This could indicate that there are many short paths in the network, which could be a sign of route fragmentation or other issues.\\n\\nAdditionally, there are several instances where the number of unique prefixes announced (num_unique_prefixes_announced) is very high, indicating a large number of unique routes were announced by this ASN during these time periods.\\n\\nReason for anomaly:\\n\\n* Anomaly detected at 2022-03-28 09:45:00 due to high number of origin changes (40).\\n* Anomaly detected at 2022-03-28 10:15:00 due to low maximum path length (10) and low average path length (4.889748326103627), indicating route fragmentation.\\n\\nNote: The above reasons are based on the values provided in the table, and may not be the only possible reasons for the anomalies detected. Further analysis and investigation are required to determine the root cause of the anomalies.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 10:20:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | [SEP] row 2: | 2022-03-28 10:25:00 | 8342 | 8 | 2 | 29 | 0 | 6 | 6 | 3.5 | 4 | 2.5 | 39 | 8 | [SEP] row 3: | 2022-03-28 10:30:00 | 8342 | 13 | 8 | 3 | 0 | 0 | 6 | 1.6923076923076923 | 0 | 0.0 | 13 | 13 | [SEP] row 4: | 2022-03-28 10:35:00 | 8342 | 26 | 13 | 0 | 0 | 13 | 6 | 2.8076923076923075 | 5 | 1.6538461538461535 | 26 | 26 | [SEP] row 5: | 2022-03-28 10:40:00 | 8342 | 0 | 0 | 26 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 10:45:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 10 | 10 | [SEP] row 7: | 2022-03-28 10:50:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | [SEP] row 8: | 2022-03-28 10:55:00 | 8342 | 6 | 1 | 11 | 0 | 5 | 7 | 5.333333333333333 | 5 | 3.5 | 6 | 6 | [SEP] row 9: | 2022-03-28 11:00:00 | 8342 | 20 | 20 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | [SEP] row 10: | 2022-03-28 11:05:00 | 8342 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 11:10:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 12: | 2022-03-28 11:15:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 11:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 11:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 11:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 11:35:00 | 8342 | 27 | 27 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 27 | 27 | [SEP] row 17: | 2022-03-28 11:40:00 | 8342 | 27 | 0 | 0 | 0 | 27 | 6 | 4.962962962962963 | 5 | 3.2222222222222223 | 27 | 27 | [SEP] row 18: | 2022-03-28 11:45:00 | 8342 | 0 | 0 | 27 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 11:50:00 | 8342 | 6 | 6 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 6 | 6 | [SEP] row 20: | 2022-03-28 11:55:00 | 8342 | 0 | 0 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected:\\n\\nAnomaly detected at 2022-03-28 10:25:00 with reason: \"high value of num_new_routes=8; high value of max_path_length=3.5; high value of avg_path_length=0.5714285714285714; high value of num_route_changes=2; high value of num_announcements=16; high value of num_unique_prefixes_announced=8; high value of  num_origin_changes=2; high value of num_withdrawals=16; high value of num_route_changes=16; high value of num_announcements=16; high value of num_unique_prefixes_announced=16; high value of num_origin_changes=16; high value of num_withdrawals=16; high value of num_route_changes=16; high value of num_announcements=16; high value of num_unique_prefixes_announced=16; high value of num_origin_changes=16; high value of num_withdrawals=16; high value of num_route_changes=16; high value of num_announcements=26; high value of num_unique_prefixes_announced=26; high value of num_origin_changes=26; high value of num_withdrawals=26; high value of num_route_changes=26; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes=6; high value of num_announcements=6; high value of num_unique_prefixes_announced=6; high value of num_origin_changes=6; high value of num_withdrawals=6; high value of num_route_changes='}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 12:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 12:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 3: | 2022-03-28 12:10:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 12:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 12:20:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 6: | 2022-03-28 12:25:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 12:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 12:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 9: | 2022-03-28 12:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 12:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 12:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 12:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 13:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 13:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 13:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 13:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 13:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 13:25:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 175 | 20 | [SEP] row 19: | 2022-03-28 13:30:00 | 8342 | 20 | 0 | 0 | 0 | 20 | 6 | 5.75 | 4 | 4.0 | 94 | 20 | [SEP] row 20: | 2022-03-28 13:35:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 4 | 4.0 | 11 | 11 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data.\\n\\nThe first anomaly is detected at 2022-03-28 12:20:00, with num_routes = 1 and max_path_length = 5.0. This is an anomaly because the number of routes announce by 8342 is very low, and all of them have a maximum path length of 5.0.\\n\\nThe second anomaly is detected at 2022-03-28 13:25:00, with num_routes = 20, num_withdrawals = 20, num_route_changes = 6, and avg_path_length = 5.75. This is an anomaly because the number of routes announce by 8342 is very high, and there are a large number of route changes and withdrawals. The avg_path_length is also very high, which could indicate that there are many short paths being announced.\\n\\nThe third anomaly is detected at 2022-03-28 13:30:00, with num_routes = 20, num_origin_changes = 11, num_route_changes = 9, and avg_path_length = 4.0. This is an anomaly because the number of routes announce by 8342 is very high, and there are a large number of origin changes and route changes. The avg_path_length is also very high, which could indicate that there are many short paths being announced.\\n\\nThe reason for these anomalies is that the values for num_routes, num_withdrawals, num_route_changes, and avg_path_length are much higher than the usual values for 8342.\\n\\nTherefore, the anomalies are detected at the following timestamps:\\n\\n* 2022-03-28 12:20:00\\n* 2022-03-28 13:25:00\\n* 2022-03-28 13:30:00\\n\\nNote that these are just examples, and the specific values that are anomalous may vary depending on the context and the other data available.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 13:40:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 13:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 13:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 13:55:00 | 8342 | 9 | 9 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 18 | 9 | [SEP] row 5: | 2022-03-28 14:00:00 | 8342 | 25 | 16 | 1 | 0 | 9 | 8 | 2.88 | 2 | 0.72 | 69 | 25 | [SEP] row 6: | 2022-03-28 14:05:00 | 8342 | 0 | 0 | 25 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 14:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 14:15:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 117 | 10 | [SEP] row 9: | 2022-03-28 14:20:00 | 8342 | 20 | 11 | 1 | 0 | 9 | 5 | 2.25 | 4 | 1.8 | 127 | 20 | [SEP] row 10: | 2022-03-28 14:25:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 2 | 2.0 | 11 | 11 | [SEP] row 11: | 2022-03-28 14:30:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 14:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 13: | 2022-03-28 14:40:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 5 | 1 | [SEP] row 14: | 2022-03-28 14:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 14:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 14:55:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 3 | 1 | [SEP] row 17: | 2022-03-28 15:00:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 15:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 15:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2022-03-28 15:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data. Here are the timestamps of the anomalous data and the reasons for each anomaly:\\n\\n1. Anomaly detected at 2022-03-28 13:45:00, as the number of new routes (9) is much higher than the average number of new routes (2.88) in the same time period.\\n2. Anomaly detected at 2022-03-28 14:05:00, as the number of routes (0) is much higher than the average number of routes (2.25) in the same time period.\\n3. Anomaly detected at 2022-03-28 14:20:00, as the number of routes (11) is much higher than the average number of routes (5.0) in the same time period.\\n4. Anomaly detected at 2022-03-28 14:40:00, as the number of route changes (1) is much higher than the average number of route changes (4.88) in the same time period.\\n5. Anomaly detected at 2022-03-28 14:45:00, as the number of origin changes (1) is much higher than the average number of origin changes (4.88) in the same time period.\\n6. Anomaly detected at 2022-03-28 14:55:00, as the number of max path length (5) is much higher than the average max path length (2.25) in the same time period.\\n\\nReason for each anomaly:\\n\\n1. High number of new routes at 2022-03-28 13:45:00: This is likely due to a change in network topology or routing behavior, as there were no significant changes in the number of unique prefixes announced or the number of withdraardals during this time period.\\n2. Zero routes at 2022-03-28 14:05:00: This is likely due to a change in network topology or routing behavior, as there were no significant changes in the number of unique prefixes announced or the number of withdrawals during this time period.\\n3. High number of routes at 2022-03-28 14:20:00: This is likely due to a change in network topology or routing behavior, as there were no significant changes in the number of unique prefixes announced or the number of route changes during this time period.\\n4. High number of route changes at 2022-03-28 14:40:00: This is likely due to a change in network topology or routing behavior, as there were no significant changes in the number of unique prefixes announced or the number of route changes during this time period.\\n5. High number of origin changes at 2022-03-28 14:45:00: This is likely due to a change in network topology or routing behavior, as there were no significant changes in the number of unique prefixes announced or the number of origin changes during this time period.\\n6. High max path length at 2022-03-28 14:55:00: This is likely due to a change in network topology or routing behavior, as there were no significant changes in the number of unique prefixes announced or the number of route changes during this time period.\\n\\nNote that these are just potential reasons for the anomalies detected, and further analysis is needed to confirm the cause of each anomaly.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 15:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 15:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 15:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 15:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 15:40:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 6: | 2022-03-28 15:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 15:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 15:55:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | [SEP] row 9: | 2022-03-28 16:00:00 | 8342 | 1 | 1 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 10: | 2022-03-28 16:05:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 16:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 16:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 16:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 16:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 16:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 16:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 16:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 16:45:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 19: | 2022-03-28 16:50:00 | 8342 | 1 | 0 | 0 | 0 | 0 | 3 | 3.0 | 0 | 0.0 | 1 | 1 | [SEP] row 20: | 2022-03-28 16:55:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data.\\n\\nThe first anomaly is detected at 2022-03-28 15:25:00, with num_routes = 0, num_new_routes = 0, num_withdrawals = 20, num_route_changes = 20, max_path_length = 0.0, avg_path_length = 0.0, max_edit_distance = 0.0, avg_edit_distance = 0.0, num_announcements = 20, num_unique_prefixes_announced = 20. These values are anomalous because they indicate a large number of route changes and withdrawals, with no new routes announced, which can indicate a possible route anomaly.\\n\\nThe second anomaly is detected at 2022-03-28 15:35:00, with num_routes = 1, num_new_routes = 1, num_withdrawals = 0, num_route_changes = 1, max_path_length = 0.0, avg_path_length = 0.0, max_edit_distance = 0.0, avg_edit_distance = 0.0, num_announcements = 1, num_unique_prefixes_announced = 1. These values are anomalous because they indicate a low number of routes announced, with no route changes or withdrawals, which can indicate a possible route anomaly.\\n\\nThe third anomaly is detected at 2022-03-28 16:40:00, with num_routes = 0, num_new_routes = 0, num_withdrawals = 1, num_route_changes = 1, max_path_length = 0.0, avg_path_length = 0.0, max_edit_distance = 0.0, avg_edit_distance = 0.0, num_announcements = 1, num_unique_prefixes_announced = 1. These values are anomalous because they indicate a large number of route changes and withdrawals, with no new routes announced, which can indicate a possible route anomaly.\\n\\nThe reason for these anomalies is that the number of route changes and withdrawals is very high, indicating possible route anomalies.\\n\\nTherefore, the anomalies are detected at timestamps 2022-03-28 15:25:00, 2022-03-28 15:35:00, and 2022-03-28 16:40:00.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 17:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2019-05-08 14:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2019-05-08 14:05:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2019-05-08 14:10:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2019-05-08 14:15:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2019-05-08 14:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2019-05-08 14:25:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2019-05-08 14:30:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2019-05-08 14:35:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2019-05-08 14:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2019-05-08 14:45:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2019-05-08 14:50:00 | 268869 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 8 | 1 | [SEP] row 13: | 2019-05-08 14:55:00 | 268869 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2019-05-08 15:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2019-05-08 15:05:00 | 268869 | 7 | 7 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 373 | 7 | [SEP] row 16: | 2019-05-08 15:10:00 | 268869 | 2 | 0 | 183 | 0 | 2 | 6 | 6.0 | 4 | 4.0 | 580 | 2 | [SEP] row 17: | 2019-05-08 15:15:00 | 268869 | 0 | 0 | 2 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2019-05-08 15:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2019-05-08 15:25:00 | 268869 | 5 | 5 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 392 | 5 | [SEP] row 20: | 2019-05-08 15:30:00 | 268869 | 5 | 0 | 0 | 0 | 5 | 6 | 5.8 | 3 | 3.0 | 13 | 5 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data. Here are the timestamps of the anomaly data and the reasons explaining which values are anomalous:\\n\\nAnomaly detected at 2019-05-08 14:20:00:\\n\\n* num_routes = 0, avg_path_length = 0.0, max_edit_distance = 0; these values are anomalous as num_routes = 0 is expected to be rare, and avg_path_length and max_edit_distance are both close to 0, indicating a lack of unique prefixes announced.\\n\\nAnomaly detected at 2019-05-08 14:30:00:\\n\\n* num_routes = 0, num_withdrawals = 756, avg_path_length = 0.0, max_edit_distance = 0; these values are anomalous as num_routes = 0 is expected to be rare, and num_withdrawals is high, indicating a large number of route changes.\\n\\nAnomaly detected at 2019-05-08 14:50:00:\\n\\n* num_routes = 1, num_origin_changes = 8, max_path_length = 5.8, max_edit_distance = 3; these values are anomalous as num_routes = 1 is expected to be rare, and num_origin_changes = 8 is high, indicating a high level of route manipulation.\\n\\nAnomaly detected at 2019-05-08 15:15:00:\\n\\n* num_routes = 7, num_withdrawals = 728, num_announcements = 373, num_unique_prefixes_announced = 7; these values are anomalous as num_routes = 7 is expected to be rare, and num_withdrawals = 728, num_announcements = 373, num_unique_prefixes_announced = 7, indicating a high level of route changes and unique prefixes announced.\\n\\nNote that these are just examples of anomalies that can be detected in BGP data, and the specific values that are anomalous may vary depending on the context and the other data in the table.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2019-05-08 15:35:00 | 268869 | 0 | 0 | 5 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2019-05-08 15:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2019-05-08 15:45:00 | 268869 | 4 | 4 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 4 | 4 | [SEP] row 4: | 2019-05-08 15:50:00 | 268869 | 0 | 0 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2019-05-08 15:55:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2019-05-08 16:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 04:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 04:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 04:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 04:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2017-12-12 04:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 04:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2017-12-12 04:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 04:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 04:40:00 | 39523 | 77 | 77 | 393 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 12086 | 77 | [SEP] row 16: | 2017-12-12 04:45:00 | 39523 | 50 | 3 | 1470 | 0 | 47 | 8 | 5.66 | 5 | 2.94 | 3427 | 50 | [SEP] row 17: | 2017-12-12 04:50:00 | 39523 | 0 | 0 | 50 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2017-12-12 04:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2017-12-12 05:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2017-12-12 05:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data.\\n\\nThe first anomaly is detected at 2019-05-08 15:40:00, with a change in num_routes from 0 to 4. This indicates an anomaly in the number of routes announced by a particular AS, which could be a sign of increased route propagation or changes in network topology.\\n\\nThe second anomaly is detected at 2019-05-08 15:50:00, with a change in num_routes from 0 to 4. This is similar to the previous anomaly, indicating a change in the number of routes announced by a particular AS.\\n\\nThe third anomaly is detected at 2017-12-12 04:05:00, with a change in num_routes from 0 to 77. This is a significant increase in the number of routes announced, which could be indicative of a large-scale change in network topology or a possible route anomaly.\\n\\nAdditionally, there are several anomalies detected in the num_new_routes and num_route_changes columns. These anomalies could indicate changes in the number of new routes announced or the number of route changes made by a particular AS, which could be indicative of changes in network topology or routing behavior.\\n\\nReason for anomaly:\\n\\n* Anomaly detected at 2019-05-08 15:40:00 due to high value of num_routes=4. This could indicate a change in the number of routes announced by a particular AS, which could be a sign of increased route propagation or changes in network topology.\\n* Anomaly detected at 2019-05-08 15:50:00 due to high value of num_routes=4. This is similar to the previous anomaly, indicating a change in the number of routes announced by a particular AS.\\n* Anomaly detected at 2017-12-12 04:05:00 due to high value of num_routes=77. This is a significant increase in the number of routes announced, which could be indicative of a large-scale change in network topology or a possible route anomaly.\\n\\nNote: The above reasons are based on the values provided in the table and may not be the only possible reasons for the anomalies detected. Further analysis and investigation are required to determine the root cause of the anomalies.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2017-12-12 05:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2017-12-12 05:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2017-12-12 05:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2017-12-12 05:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2017-12-12 05:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2017-12-12 05:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 05:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 05:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 05:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 05:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2017-12-12 06:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 06:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2017-12-12 06:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 06:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 06:20:00 | 39523 | 31 | 31 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 57 | 31 | [SEP] row 16: | 2017-12-12 06:25:00 | 39523 | 0 | 0 | 31 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2017-12-12 06:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2017-12-12 06:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2017-12-12 06:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2017-12-12 06:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the BGP data.\\n\\nThe first anomaly is detected at 2017-12-12 06:25:00, with num_withdrawals=31 and max_path_length=0.0. This indicates that there were 31 withdrawals of announcements with no path length changes. This is an anomaly because typically, withdrawals are used to cancel old announcements and make room for new ones, but in this case, there were no new announcements made to replace the withdrawn ones.\\n\\nThe second anomaly is detected at 2017-12-12 06:35:00, with num_origin_changes=31 and avg_path_length=0.0. This indicates that there were 31 origin changes and no path length changes. This is an anomaly because origin changes are used to update the origin of an announcement, but in this case, there were no path length changes, which suggests that the origin changes were likely made without any corresponding path length changes.\\n\\nThe third anomaly is detected at 2017-12-12 06:40:00, with num_route_changes=31 and max_path_length=0.0. This indicates that there were 31 route changes and no max path length changes. This is an anomaly because route changes are used to update the routing information, but in this case, there were no max path length changes, which suggests that the route changes were likely made without any corresponding max path length changes.\\n\\nIn addition to these anomalies, there are several other anomalous values throughout the data set, including high numbers of num_announcements, num_unique_prefixes_announced, and num_new_routes. These values are often accompanied by high numbers of num_withdrawals, num_origin_changes, and num_route_changes, which suggests that there is a high level of activity in the BGP protocol.\\n\\nTherefore, based on the data provided, there are several anomalies detected in the BGP data, including high numbers of withdrawals, origin changes, and route changes, as well as high numbers of num_announcements, num_unique_prefixes_announced, and num_new_routes.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2017-12-12 06:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2017-12-12 06:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2017-12-12 07:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2017-12-12 07:05:00 | 39523 | 74 | 74 | 2211 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16467 | 74 | [SEP] row 5: | 2017-12-12 07:10:00 | 39523 | 20 | 2 | 96 | 0 | 16 | 8 | 6.3 | 4 | 2.6 | 73 | 20 | [SEP] row 6: | 2017-12-12 07:15:00 | 39523 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 07:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 07:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 07:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 07:35:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 181 | 1 | [SEP] row 11: | 2017-12-12 07:40:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 07:45:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 13: | 2017-12-12 07:50:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 07:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 08:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected in the given time period.\\n\\nThe first anomaly is detected at 2017-12-12 07:05:00, where the number of originations (num_announcements) is 16, and the number of unique prefixes announced (num_unique_prefixes_announced) is 74. This is an anomaly because the number of originations is high, and the number of unique prefixes announced is also high, which may indicate a high level of route changes or path length changes.\\n\\nThe second anomaly is detected at 2017-12-12 07:25:00, where the number of originations (num_announcements) is 0, and the number of withdrawals (num_withdrawals) is 20. This is an anomaly because the number of originations is very low, and the number of withdrawals is high, which may indicate a high level of route changes or path length changes.\\n\\nThe third anomaly is detected at 2017-12-12 07:40:00, where the maximum edit distance (max_edit_distance) is 6, and the average edit distance (avg_edit_distance) is 3.8. This is an anomaly because the maximum edit distance is very low, and the average edit distance is also low, which may indicate a high level of route changes or path length changes.\\n\\nThe reason for these anomalies is that the number of route changes or path length changes is high, which may indicate a high level of network activity or instability.\\n\\nTherefore, the anomalies are detected at the following timestamps:\\n\\n* 2017-12-12 07:05:00\\n* 2017-12-12 07:25:00\\n* 2017-12-12 07:40:00\\n\\nReason for anomaly:\\n\\n* 2017-12-12 07:05:00: High number of originations (16) and unique prefixes announced (74), which may indicate a high level of route changes or path length changes.\\n* 2017-12-12 07:25:00: High number of withdrawals (20), which may indicate a high level of route changes or path length changes.\\n* 2017-12-12 07:40:00: Low maximum edit distance (6) and average edit distance (3.8), which may indicate a high level of route changes or path length changes.'}]\n",
      "Results saved to table135-20split-2k-with-outputs-20.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tablular_eval_util import combine_csv_files, split_dataframe, preprocess_data, run_llm_inference\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "\n",
    "if 'anomaly_status' in combined_df.columns:\n",
    "    combined_df = combined_df.drop(columns=['anomaly_status'])\n",
    "    \n",
    "# Split the DataFrame into smaller chunks\n",
    "split_size = 20\n",
    "data_list = split_dataframe(combined_df, split_size)\n",
    "\n",
    "# Preprocess the data into the required format\n",
    "formatted_data = [preprocess_data(chunk) for chunk in data_list]\n",
    "\n",
    "formatted_data_file = f'llm_table_bgp_data_test_{split_size}.json'\n",
    "with open(formatted_data_file, 'w') as f:\n",
    "    json.dump(formatted_data, f, indent=4)\n",
    "\n",
    "with open(formatted_data_file, 'r') as f:\n",
    "    formatted_data = json.load(f)\n",
    "\n",
    "output_results_file = f'table135-20split-2k-with-outputs-{split_size}.json'\n",
    "run_llm_inference(formatted_data, model, tokenizer, max_length=3050, output_results_file=output_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 07:20:00', '2022-03-28 07:25:00', '2022-03-28 08:10:00', '2022-03-28 07:20:00', '2022-03-28 07:25:00', '2022-03-28 08:10:00', '2022-03-28 07:20:00', '2022-03-28 07:25:00', '2022-03-28 08:10:00', '2022-03-28 09:45:00', '2022-03-28 10:15:00', '2022-03-28 09:45:00', '2022-03-28 10:15:00', '2022-03-28 10:25:00', '2022-03-28 12:20:00', '2022-03-28 13:25:00', '2022-03-28 13:30:00', '2022-03-28 12:20:00', '2022-03-28 13:25:00', '2022-03-28 13:30:00', '2022-03-28 13:45:00', '2022-03-28 14:05:00', '2022-03-28 14:20:00', '2022-03-28 14:40:00', '2022-03-28 14:45:00', '2022-03-28 14:55:00', '2022-03-28 13:45:00', '2022-03-28 14:05:00', '2022-03-28 14:20:00', '2022-03-28 14:40:00', '2022-03-28 14:45:00', '2022-03-28 14:55:00', '2022-03-28 15:25:00', '2022-03-28 15:35:00', '2022-03-28 16:40:00', '2022-03-28 15:25:00', '2022-03-28 15:35:00', '2022-03-28 16:40:00', '2019-05-08 14:20:00', '2019-05-08 14:30:00', '2019-05-08 14:50:00', '2019-05-08 15:15:00', '2019-05-08 15:40:00', '2019-05-08 15:50:00', '2017-12-12 04:05:00', '2019-05-08 15:40:00', '2019-05-08 15:50:00', '2017-12-12 04:05:00', '2017-12-12 06:25:00', '2017-12-12 06:35:00', '2017-12-12 06:40:00', '2017-12-12 07:05:00', '2017-12-12 07:25:00', '2017-12-12 07:40:00', '2017-12-12 07:05:00', '2017-12-12 07:25:00', '2017-12-12 07:40:00', '2017-12-12 07:05:00', '2017-12-12 07:25:00', '2017-12-12 07:40:00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "output_file = pd.read_json(f\"/home/hb/LLM-research/finetune_main/finetuning_tabular/table_read/table135-20split-2k-with-outputs-{split_size}.json\")\n",
    "output_file = output_file[\"output\"]\n",
    "output_file.to_csv(f\"table135-20split-2k-outputs-{split_size}.csv\")\n",
    "\n",
    "timestamps = []\n",
    "\n",
    "timestamp_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}')\n",
    "\n",
    "for output in output_file:\n",
    "    matches = timestamp_pattern.findall(output)\n",
    "    timestamps.extend(matches)\n",
    "\n",
    "bgp_llm_output = list(set(timestamps))\n",
    "\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 10:25:00', '2022-03-28 10:30:00', '2022-03-28 10:35:00', '2022-03-28 10:40:00', '2022-03-28 10:55:00', '2022-03-28 11:00:00', '2022-03-28 11:35:00', '2022-03-28 11:40:00', '2022-03-28 11:45:00', '2022-03-28 13:25:00', '2022-03-28 13:30:00', '2022-03-28 13:35:00', '2022-03-28 14:00:00', '2022-03-28 14:05:00', '2022-03-28 14:15:00', '2022-03-28 14:20:00', '2022-03-28 14:25:00', '2022-03-28 15:55:00', '2022-03-28 16:00:00', '2022-03-28 16:05:00', '2019-05-08 15:05:00', '2019-05-08 15:10:00', '2019-05-08 15:15:00', '2019-05-08 15:30:00', '2017-12-12 04:40:00', '2017-12-12 04:45:00', '2017-12-12 04:50:00', '2017-12-12 07:05:00', '2017-12-12 07:10:00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import combine_csv_files\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "combined_df = combined_df[['anomaly_status']]\n",
    "\n",
    "# Filter the rows with \"anomaly detected\" in the anomaly_status\n",
    "filtered_df = combined_df[combined_df['anomaly_status'].str.contains('anomaly detected', na=False)]\n",
    "# filtered_df.to_csv('/home/hb/dataset_bgp/bgp_tab_dataset_test/test_true_label.csv', index=False)\n",
    "\n",
    "# Extract the date from the anomaly_status string\n",
    "true_label = filtered_df['anomaly_status'].str.extract(r'anomaly detected at (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})')\n",
    "\n",
    "# Convert the dates to a list\n",
    "true_label = true_label[0].tolist()\n",
    "\n",
    "print(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results 20 split:\n",
      "Precision: 0.23\n",
      "Recall: 0.24\n",
      "F1 Score: 0.23\n",
      "True Positives: 7\n",
      "False Positives: 24\n",
      "False Negatives: 22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import evaluate_llm_results\n",
    "\n",
    "evaluation_result = evaluate_llm_results(true_anomalies=true_label, llm_results=bgp_llm_output)\n",
    "print(f\"Evaluation Results {split_size} split:\")\n",
    "print(f\"Precision: {evaluation_result['precision']:.2f}\")\n",
    "print(f\"Recall: {evaluation_result['recall']:.2f}\")\n",
    "print(f\"F1 Score: {evaluation_result['f1_score']:.2f}\")\n",
    "print(f\"True Positives: {evaluation_result['true_positives']}\")\n",
    "print(f\"False Positives: {evaluation_result['false_positives']}\")\n",
    "print(f\"False Negatives: {evaluation_result['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
