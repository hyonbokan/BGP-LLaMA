{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/myenv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e47127c9752407f9e0bf31579990c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "import transformers\n",
    "import os\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "# model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "# model_id = 'codellama/CodeLlama-7b-hf'\n",
    "# model_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "new_model = \"/home/hb/dataset_bgp/llm_finetuned/llama2-7b-table283New-10split-5k-instruct-1e5rate-loraa64drop01\"\n",
    "\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    ")\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hb/myenv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ccd40bd8754ad19b49f393759f6ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a16f3e8cb03452f98a188175a5a8ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00003.bin:  56%|#####6    | 5.60G/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80d7b16ac354160aedc856a77afdc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00003.bin:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d37c3146ec43e2aacfd868958ea2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00003.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5f3c6bb9914b188de2667f1c568b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b86d73067154014bb6d083d6c30abda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7206c81ff58a4e018f435c926dd10d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b1875dbc594e078ad0327a5d37516f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fd9a4b9c3e4808a95d3b8698f3340a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681100378b87458ea72e902257364f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "import transformers\n",
    "import os\n",
    "\n",
    "model_id = \"hyonbokan/BGP-LLaMA13-BGPStream5k-cutoff-1024-max-2048-fpFalse\"\n",
    "\n",
    "# Need auth token for these\n",
    "hf_auth = os.environ.get('hf_token')\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    # quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9/10\n",
      "Processed 10/10\n",
      "[{'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 07:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 07:05:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | [SEP] row 3: | 2022-03-28 07:10:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 07:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 07:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 07:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 07:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 07:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2022-03-28 07:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 07:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 07:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 07:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 08:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 08:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 08:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 08:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 08:20:00 | 8342 | 7 | 7 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 19 | 7 | [SEP] row 18: | 2022-03-28 08:25:00 | 8342 | 0 | 0 | 7 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 08:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2022-03-28 08:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there is an anomaly detected at 2022-03-28 07:10:00. The reason for the anomaly is the high value of num_routes=7, which is significantly higher than the average value of num_routes=0 for the other rows. This indicates that there was a sudden increase in the number of routes announced by ASN 8342 at that particular time.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 08:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 08:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 08:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 08:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 09:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 09:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 09:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 09:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2022-03-28 09:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 09:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 09:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 09:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 09:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 09:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 09:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 09:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 10:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 10:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 19: | 2022-03-28 10:10:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 20: | 2022-03-28 10:15:00 | 8342 | 10 | 10 | 17 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 41 | 10 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, an anomaly is detected at 2022-03-28 10:15:00. The reason for the anomaly is the high value of num_routes=10, which is significantly higher than the previous values of num_routes=0, 0, 0, 0, 0, 0, 0, 0, and 0. This indicates a sudden change in the network configuration or a malfunction in the data collection process.\\n\\nTherefore, the anomaly is detected at 2022-03-28 10:15:00 due to the high value of num_routes=10.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 10:20:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | [SEP] row 2: | 2022-03-28 10:25:00 | 8342 | 8 | 2 | 29 | 0 | 6 | 6 | 3.5 | 4 | 2.5 | 39 | 8 | [SEP] row 3: | 2022-03-28 10:30:00 | 8342 | 13 | 8 | 3 | 0 | 0 | 6 | 1.6923076923076923 | 0 | 0.0 | 13 | 13 | [SEP] row 4: | 2022-03-28 10:35:00 | 8342 | 26 | 13 | 0 | 0 | 13 | 6 | 2.8076923076923075 | 5 | 1.6538461538461535 | 26 | 26 | [SEP] row 5: | 2022-03-28 10:40:00 | 8342 | 0 | 0 | 26 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2022-03-28 10:45:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 10 | 10 | [SEP] row 7: | 2022-03-28 10:50:00 | 8342 | 16 | 16 | 10 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16 | 16 | [SEP] row 8: | 2022-03-28 10:55:00 | 8342 | 6 | 1 | 11 | 0 | 5 | 7 | 5.333333333333333 | 5 | 3.5 | 6 | 6 | [SEP] row 9: | 2022-03-28 11:00:00 | 8342 | 20 | 20 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | [SEP] row 10: | 2022-03-28 11:05:00 | 8342 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 11:10:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 12: | 2022-03-28 11:15:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 11:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 11:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 11:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 11:35:00 | 8342 | 27 | 27 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 27 | 27 | [SEP] row 17: | 2022-03-28 11:40:00 | 8342 | 27 | 0 | 0 | 0 | 27 | 6 | 4.962962962962963 | 5 | 3.2222222222222223 | 27 | 27 | [SEP] row 18: | 2022-03-28 11:45:00 | 8342 | 0 | 0 | 27 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 11:50:00 | 8342 | 6 | 6 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 6 | 6 | [SEP] row 20: | 2022-03-28 11:55:00 | 8342 | 0 | 0 | 6 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected:\\n\\n1. At timestamp 2022-03-28 10:25:00, the number of new routes (num_new_routes) is anomalously high (29).\\n2. At timestamp 2022-03-28 10:30:00, the number of route changes (num_route_changes) is anomalously high (6).\\n3. At timestamp 2022-03-28 10:35:00, the number of announcements (num_announcements) is anomalously high (26).\\n4. At timestamp 2022-03-28 10:45:00, the number of unique prefixes announced (num_unique_prefixes_announced) is anomalously high (27).\\n5. At timestamp 2022-03-28 11:25:00, the number of route changes (num_route_changes) is anomalously high (6).\\n6. At timestamp 2022-03-28 11:35:00, the number of announcements (num_announcements) is anomalously high (27).\\n7. At timestamp 2022-03-28 11:45:00, the number of unique prefixes announced (num_unique_prefixes_announced) is anomalously high (27).\\n\\nThe anomalies are detected based on the following reasons:\\n\\n1. High number of new routes: This could indicate a sudden change in the network configuration or a malfunction in the BGP monitoring system.\\n2. High number of route changes: This could indicate a high level of activity in the network or a malfunction in the BGP monitoring system.\\n3. High number of announcements: This could indicate a high level of activity in the network or a malfunction in the BGP monitoring system.\\n4. High number of unique prefixes announced: This could indicate a high level of activity in the network or a malfunction in the BGP monitoring system.\\n\\nIn conclusion, the data indicates several anomalies in the BGP monitoring data for the given time period. These anomalies could be due to various reasons such as network configuration changes, malfunctions in the monitoring system, or high levels of activity in the network. Further investigation is required to determine the root cause of these anomalies.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 12:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 12:05:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 3: | 2022-03-28 12:10:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 12:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 12:20:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 6: | 2022-03-28 12:25:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 12:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 12:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 9: | 2022-03-28 12:40:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2022-03-28 12:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 12:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 12:55:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 13:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 13:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 13:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 13:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 13:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 13:25:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 175 | 20 | [SEP] row 19: | 2022-03-28 13:30:00 | 8342 | 20 | 0 | 0 | 0 | 20 | 6 | 5.75 | 4 | 4.0 | 94 | 20 | [SEP] row 20: | 2022-03-28 13:35:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 4 | 4.0 | 11 | 11 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, an anomaly is detected at 2022-03-28 13:25:00. The reason for the anomaly is the high value of num_routes=20. This is an unusual value compared to the other rows in the table, which have a maximum value of num_routes=11. Additionally, the value of num_routes=20 is not consistent with the other values in the table, which are all 0 or 1. Therefore, this data point is considered an anomaly.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 13:40:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 13:45:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 13:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 13:55:00 | 8342 | 9 | 9 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 18 | 9 | [SEP] row 5: | 2022-03-28 14:00:00 | 8342 | 25 | 16 | 1 | 0 | 9 | 8 | 2.88 | 2 | 0.72 | 69 | 25 | [SEP] row 6: | 2022-03-28 14:05:00 | 8342 | 0 | 0 | 25 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 14:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 14:15:00 | 8342 | 10 | 10 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 117 | 10 | [SEP] row 9: | 2022-03-28 14:20:00 | 8342 | 20 | 11 | 1 | 0 | 9 | 5 | 2.25 | 4 | 1.8 | 127 | 20 | [SEP] row 10: | 2022-03-28 14:25:00 | 8342 | 11 | 0 | 9 | 0 | 11 | 5 | 5.0 | 2 | 2.0 | 11 | 11 | [SEP] row 11: | 2022-03-28 14:30:00 | 8342 | 0 | 0 | 11 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 14:35:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 13: | 2022-03-28 14:40:00 | 8342 | 1 | 1 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 5 | 1 | [SEP] row 14: | 2022-03-28 14:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 14:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 14:55:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 3 | 1 | [SEP] row 17: | 2022-03-28 15:00:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 15:05:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2022-03-28 15:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2022-03-28 15:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there are several anomalies detected:\\n\\n1. Anomaly detected at 2022-03-28 13:45:00 due to high value of num_routes=0.\\n2. Anomaly detected at 2022-03-28 13:55:00 due to high value of num_routes=9.\\n3. Anomaly detected at 2022-03-28 14:05:00 due to high value of num_routes=25.\\n4. Anomaly detected at 2022-03-28 14:15:00 due to high value of num_routes=10.\\n5. Anomaly detected at 2022-03-28 14:25:00 due to high value of num_routes=20.\\n6. Anomaly detected at 2022-03-28 14:35:00 due to high value of num_routes=1.\\n7. Anomaly detected at 2022-03-28 14:45:00 due to high value of num_routes=1.\\n8. Anomaly detected at 2022-03-28 14:55:00 due to high value of num_routes=3.\\n\\nThe reason for each anomaly is the high value of num_routes compared to the other rows. This indicates a change in the network configuration or a change in the data collection process.\\n\\nThe data does indicate an anomaly. The anomalies are detected at the following timestamps:\\n\\n1. 2022-03-28 13:45:00\\n2. 2022-03-28 13:55:00\\n3. 2022-03-28 14:05:00\\n4. 2022-03-28 14:15:00\\n5. 2022-03-28 14:25:00\\n6. 2022-03-28 14:35:00\\n7. 2022-03-28 14:45:00\\n8. 2022-03-28 14:55:00\\n\\nThe anomalies are caused by changes in the network configuration or changes in the data collection process.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 15:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2022-03-28 15:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2022-03-28 15:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2022-03-28 15:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2022-03-28 15:40:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 6: | 2022-03-28 15:45:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2022-03-28 15:50:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2022-03-28 15:55:00 | 8342 | 20 | 20 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 20 | 20 | [SEP] row 9: | 2022-03-28 16:00:00 | 8342 | 1 | 1 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 10: | 2022-03-28 16:05:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2022-03-28 16:10:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2022-03-28 16:15:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2022-03-28 16:20:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2022-03-28 16:25:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2022-03-28 16:30:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 16: | 2022-03-28 16:35:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2022-03-28 16:40:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2022-03-28 16:45:00 | 8342 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 19: | 2022-03-28 16:50:00 | 8342 | 1 | 0 | 0 | 0 | 0 | 3 | 3.0 | 0 | 0.0 | 1 | 1 | [SEP] row 20: | 2022-03-28 16:55:00 | 8342 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, an anomaly is detected at 2022-03-28 16:45:00. The reason for the anomaly is the high value of num_routes=20. This indicates that there was a significant change in the number of routes announced by ASN 8342 at this time.\\n\\nThe data also indicates that there were no anomalies in the other columns, such as num_new_routes, num_withdrawals, num_origin_changes, num_route_changes, max_path_length, avg_path_length, max_edit_distance, avg_edit_distance, num_announcements, and num_unique_prefixes_announced.\\n\\nTherefore, the anomaly detected is related to the change in the number of routes announced by ASN 8342 at 2022-03-28 16:45:00.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2022-03-28 17:00:00 | 8342 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2019-05-08 14:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2019-05-08 14:05:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2019-05-08 14:10:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2019-05-08 14:15:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2019-05-08 14:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2019-05-08 14:25:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2019-05-08 14:30:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2019-05-08 14:35:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2019-05-08 14:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2019-05-08 14:45:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2019-05-08 14:50:00 | 268869 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 8 | 1 | [SEP] row 13: | 2019-05-08 14:55:00 | 268869 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2019-05-08 15:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2019-05-08 15:05:00 | 268869 | 7 | 7 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 373 | 7 | [SEP] row 16: | 2019-05-08 15:10:00 | 268869 | 2 | 0 | 183 | 0 | 2 | 6 | 6.0 | 4 | 4.0 | 580 | 2 | [SEP] row 17: | 2019-05-08 15:15:00 | 268869 | 0 | 0 | 2 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2019-05-08 15:20:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2019-05-08 15:25:00 | 268869 | 5 | 5 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 392 | 5 | [SEP] row 20: | 2019-05-08 15:30:00 | 268869 | 5 | 0 | 0 | 0 | 5 | 6 | 5.8 | 3 | 3.0 | 13 | 5 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, an anomaly is detected at 2019-05-08 14:55:00. The reason for the anomaly is the high value of num_routes=77. This is an anomaly because the previous rows have all reported 0 for num_routes, and suddenly there is a large increase in the number of routes at this timestamp. This could indicate a change in the network configuration or a malfunction in the monitoring system.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2019-05-08 15:35:00 | 268869 | 0 | 0 | 5 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2019-05-08 15:40:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2019-05-08 15:45:00 | 268869 | 4 | 4 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 4 | 4 | [SEP] row 4: | 2019-05-08 15:50:00 | 268869 | 0 | 0 | 4 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2019-05-08 15:55:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2019-05-08 16:00:00 | 268869 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 04:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 04:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 04:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 04:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2017-12-12 04:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 04:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2017-12-12 04:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 04:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 04:40:00 | 39523 | 77 | 77 | 393 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 12086 | 77 | [SEP] row 16: | 2017-12-12 04:45:00 | 39523 | 50 | 3 | 1470 | 0 | 47 | 8 | 5.66 | 5 | 2.94 | 3427 | 50 | [SEP] row 17: | 2017-12-12 04:50:00 | 39523 | 0 | 0 | 50 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2017-12-12 04:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2017-12-12 05:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2017-12-12 05:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there is an anomaly detected at 2017-12-12 04:35:00. The reason for the anomaly is the high value of num_routes=77. This is an unusual value compared to the other rows in the table, which have a maximum value of 4. This indicates that there was a significant change in the network configuration or routing policy at this time.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2017-12-12 05:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2017-12-12 05:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2017-12-12 05:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2017-12-12 05:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 5: | 2017-12-12 05:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 6: | 2017-12-12 05:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 05:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 05:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 05:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 05:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 11: | 2017-12-12 06:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 06:05:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 13: | 2017-12-12 06:10:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 06:15:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 06:20:00 | 39523 | 31 | 31 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 57 | 31 | [SEP] row 16: | 2017-12-12 06:25:00 | 39523 | 0 | 0 | 31 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 17: | 2017-12-12 06:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 18: | 2017-12-12 06:35:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 19: | 2017-12-12 06:40:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 20: | 2017-12-12 06:45:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, an anomaly is detected at 2017-12-12 06:15:00. The reason for the anomaly is the high value of num_routes=31. This is an unusual increase in the number of routes compared to the previous time periods, indicating a potential anomaly.'}, {'instruction': 'The goal for this task is to determine if the data indicates an anomaly. The context, section, and table columns provide important information for identifying the correct anomaly type.', 'input_seg': '[TLE] The context is about BGP data analysis for detecting anomalies. The section is related to a specific time period of BGP monitoring. [TAB] col: | timestamp | asn | num_routes | num_new_routes | num_withdrawals | num_origin_changes | num_route_changes | max_path_length | avg_path_length | max_edit_distance | avg_edit_distance | num_announcements | num_unique_prefixes_announced | row 1: | 2017-12-12 06:50:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 2: | 2017-12-12 06:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 3: | 2017-12-12 07:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 4: | 2017-12-12 07:05:00 | 39523 | 74 | 74 | 2211 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 16467 | 74 | [SEP] row 5: | 2017-12-12 07:10:00 | 39523 | 20 | 2 | 96 | 0 | 16 | 8 | 6.3 | 4 | 2.6 | 73 | 20 | [SEP] row 6: | 2017-12-12 07:15:00 | 39523 | 0 | 0 | 20 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 7: | 2017-12-12 07:20:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 8: | 2017-12-12 07:25:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 9: | 2017-12-12 07:30:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 10: | 2017-12-12 07:35:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 181 | 1 | [SEP] row 11: | 2017-12-12 07:40:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 12: | 2017-12-12 07:45:00 | 39523 | 1 | 1 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 1 | 1 | [SEP] row 13: | 2017-12-12 07:50:00 | 39523 | 0 | 0 | 1 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 14: | 2017-12-12 07:55:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP] row 15: | 2017-12-12 08:00:00 | 39523 | 0 | 0 | 0 | 0 | 0 | 0 | 0.0 | 0 | 0.0 | 0 | 0 | [SEP]', 'question': \"Based on the data provided, does the data indicate an anomaly? If an anomaly is detected, include the timestamp of the anomaly data and provide a reason explaining which values are anomalous. For example, 'anomaly detected at 2024-06-10 12:00:00 due to high value of num_routes=77'\", 'output': 'Based on the data provided, there is no anomaly detected. All the values are within the expected range and there are no sudden changes or spikes in any of the columns. The data appears to be consistent and normal.\\n\\nHowever, if we look at the data more closely, we can see that there is a slight increase in the number of routes announced by ASN 39523 between 2017-12-12 07:00:00 and 2017-12-12 07:10:00. This could be an indication of an anomaly, as the number of routes announced by this ASN is higher than usual.\\n\\nTherefore, the anomaly detected at 2017-12-12 07:10:00 is due to the high value of num_routes=77. This is an anomaly because the number of routes announced by this ASN is higher than usual.'}]\n",
      "Results saved to table135-20split-2k-with-outputs-20.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tablular_eval_util import combine_csv_files, split_dataframe, preprocess_data, run_llm_inference\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "\n",
    "if 'anomaly_status' in combined_df.columns:\n",
    "    combined_df = combined_df.drop(columns=['anomaly_status'])\n",
    "    \n",
    "# Split the DataFrame into smaller chunks\n",
    "split_size = 10\n",
    "data_list = split_dataframe(combined_df, split_size)\n",
    "\n",
    "# Preprocess the data into the required format\n",
    "formatted_data = [preprocess_data(chunk) for chunk in data_list]\n",
    "\n",
    "formatted_data_file = f'llm_table_bgp_data_test_{split_size}.json'\n",
    "with open(formatted_data_file, 'w') as f:\n",
    "    json.dump(formatted_data, f, indent=4)\n",
    "\n",
    "with open(formatted_data_file, 'r') as f:\n",
    "    formatted_data = json.load(f)\n",
    "\n",
    "output_results_file = f'table135-20split-2k-with-outputs-{split_size}.json'\n",
    "run_llm_inference(formatted_data, model, tokenizer, max_length=2050, output_results_file=output_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from tablular_eval_util import combine_csv_files, split_dataframe, preprocess_data, run_llm_inference, shuffle_and_split_dataframe\n",
    "\n",
    "# directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "# combined_df = combine_csv_files(directory)\n",
    "\n",
    "# if 'anomaly_status' in combined_df.columns:\n",
    "#     combined_df = combined_df.drop(columns=['anomaly_status'])\n",
    "    \n",
    "# # Split the DataFrame into smaller chunks\n",
    "# split_size = 20\n",
    "# data_list = shuffle_and_split_dataframe(combined_df, split_size)\n",
    "\n",
    "# # Preprocess the data into the required format\n",
    "# formatted_data = [preprocess_data(chunk) for chunk in data_list]\n",
    "\n",
    "# formatted_data_file = f'llm_table_bgp_data_test_{split_size}_shuffled.json'\n",
    "# with open(formatted_data_file, 'w') as f:\n",
    "#     json.dump(formatted_data, f, indent=4)\n",
    "\n",
    "# with open(formatted_data_file, 'r') as f:\n",
    "#     formatted_data = json.load(f)\n",
    "\n",
    "# output_results_file = f'table135-20split-2k-with-outputs-{split_size}_shuffled.json'\n",
    "# run_llm_inference(formatted_data, model, tokenizer, max_length=3050, output_results_file=output_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 07:10:00', '2022-03-28 10:15:00', '2022-03-28 10:15:00', '2022-03-28 10:25:00', '2022-03-28 10:30:00', '2022-03-28 10:35:00', '2022-03-28 10:45:00', '2022-03-28 11:25:00', '2022-03-28 11:35:00', '2022-03-28 11:45:00', '2022-03-28 13:25:00', '2022-03-28 13:45:00', '2022-03-28 13:55:00', '2022-03-28 14:05:00', '2022-03-28 14:15:00', '2022-03-28 14:25:00', '2022-03-28 14:35:00', '2022-03-28 14:45:00', '2022-03-28 14:55:00', '2022-03-28 13:45:00', '2022-03-28 13:55:00', '2022-03-28 14:05:00', '2022-03-28 14:15:00', '2022-03-28 14:25:00', '2022-03-28 14:35:00', '2022-03-28 14:45:00', '2022-03-28 14:55:00', '2022-03-28 16:45:00', '2022-03-28 16:45:00', '2019-05-08 14:55:00', '2017-12-12 04:35:00', '2017-12-12 06:15:00', '2017-12-12 07:00:00', '2017-12-12 07:10:00', '2017-12-12 07:10:00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "output_file = pd.read_json(f\"/home/hb/LLM-research/finetune_main/finetuning_tabular/table_read/table135-20split-2k-with-outputs-{split_size}.json\")\n",
    "output_file = output_file[\"output\"]\n",
    "output_file.to_csv(f\"table135-20split-2k-outputs-{split_size}.csv\")\n",
    "\n",
    "timestamps = []\n",
    "\n",
    "timestamp_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}')\n",
    "\n",
    "for output in output_file:\n",
    "    matches = timestamp_pattern.findall(output)\n",
    "    timestamps.extend(matches)\n",
    "\n",
    "bgp_llm_output = list(set(timestamps))\n",
    "\n",
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# gpt4o_test1 = pd.read_csv(\"/home/hb/LLM-research/finetune_main/finetuning_tabular/table_read/gpt4o_test1.csv\")\n",
    "# gpt4o_test1 = gpt4o_test1[\"timestamp\"].tolist()\n",
    "# print(gpt4o_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # File paths\n",
    "# file_paths = [\n",
    "#     \"/home/hb/LLM-research/finetune_main/finetuning_tabular/table_read/gpt4o_test1.csv\",\n",
    "#     \"/home/hb/LLM-research/finetune_main/finetuning_tabular/table_read/gpt4o_test2.csv\",\n",
    "#     \"/home/hb/LLM-research/finetune_main/finetuning_tabular/table_read/gpt4o_test3.csv\"\n",
    "# ]\n",
    "\n",
    "# # Read and concatenate the timestamp columns from each file\n",
    "# gpt4o_combined_df = pd.concat([pd.read_csv(file)[\"timestamp\"] for file in file_paths], ignore_index=True)\n",
    "\n",
    "# # Convert the combined DataFrame to a list\n",
    "# gpt4o_combined_list = gpt4o_combined_df.tolist()\n",
    "\n",
    "# print(gpt4o_combined_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-03-28 10:25:00', '2022-03-28 10:30:00', '2022-03-28 10:35:00', '2022-03-28 10:40:00', '2022-03-28 10:55:00', '2022-03-28 11:00:00', '2022-03-28 11:35:00', '2022-03-28 11:40:00', '2022-03-28 11:45:00', '2022-03-28 13:25:00', '2022-03-28 13:30:00', '2022-03-28 13:35:00', '2022-03-28 14:00:00', '2022-03-28 14:05:00', '2022-03-28 14:15:00', '2022-03-28 14:20:00', '2022-03-28 14:25:00', '2022-03-28 15:55:00', '2019-05-08 15:05:00', '2019-05-08 15:10:00', '2019-05-08 15:15:00', '2019-05-08 15:30:00', '2017-12-12 04:40:00', '2017-12-12 04:45:00', '2017-12-12 04:50:00', '2017-12-12 07:05:00', '2017-12-12 07:10:00']\n"
     ]
    }
   ],
   "source": [
    "from tablular_eval_util import combine_csv_files\n",
    "\n",
    "directory = '/home/hb/dataset_bgp/bgp_tab_dataset_test'\n",
    "combined_df = combine_csv_files(directory)\n",
    "combined_df = combined_df[['anomaly_status']]\n",
    "\n",
    "# Filter the rows with \"anomaly detected\" in the anomaly_status\n",
    "filtered_df = combined_df[combined_df['anomaly_status'].str.contains('anomaly detected', na=False)]\n",
    "# filtered_df.to_csv('/home/hb/dataset_bgp/bgp_tab_dataset_test/test_true_label.csv', index=False)\n",
    "\n",
    "# Extract the date from the anomaly_status string\n",
    "true_label = filtered_df['anomaly_status'].str.extract(r'anomaly detected at (\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})')\n",
    "\n",
    "# Convert the dates to a list\n",
    "true_label = true_label[0].tolist()\n",
    "\n",
    "print(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results 20 split:\n",
      "Precision: 0.42\n",
      "Recall: 0.37\n",
      "F1 Score: 0.39\n",
      "True Positives: 10\n",
      "False Positives: 14\n",
      "False Negatives: 17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tablular_eval_util import evaluate_llm_results\n",
    "\n",
    "evaluation_result = evaluate_llm_results(true_anomalies=true_label, llm_results=timestamps)\n",
    "print(f\"Evaluation Results {split_size} split:\")\n",
    "print(f\"Precision: {evaluation_result['precision']:.2f}\")\n",
    "print(f\"Recall: {evaluation_result['recall']:.2f}\")\n",
    "print(f\"F1 Score: {evaluation_result['f1_score']:.2f}\")\n",
    "print(f\"True Positives: {evaluation_result['true_positives']}\")\n",
    "print(f\"False Positives: {evaluation_result['false_positives']}\")\n",
    "print(f\"False Negatives: {evaluation_result['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
