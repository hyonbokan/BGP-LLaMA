# LLM BGP tab eval

## llama 7B:
### Evaluation Results:
Precision: 0.33
Recall: 0.20
F1 Score: 0.25
True Positives: 1
False Positives: 2
False Negatives: 4

### Evaluation Results:
Precision: 0.73
Recall: 0.38
F1 Score: 0.50
True Positives: 11
False Positives: 4
False Negatives: 18


## llama 13B:
### Evaluation Results:
Precision: 1.00
Recall: 0.80
F1 Score: 0.89
True Positives: 4
False Positives: 0
False Negatives: 1

### Evaluation Results New:
Precision: 0.68
Recall: 0.89
F1 Score: 0.77
True Positives: 34
False Positives: 16
False Negatives: 4



## llama 70B:
### Evaluation Results:
Precision: 0.67
Recall: 0.40
F1 Score: 0.50
True Positives: 2
False Positives: 1
False Negatives: 3


## finetuned-7B:
### finetuned-7B 5k 191 tab
#### Evaluation Results:
Precision: 0.71
Recall: 0.52
F1 Score: 0.60
True Positives: 15
False Positives: 6
False Negatives: 14



## gpt-3.5 (table format):
### Evaluation Results:
Precision: 0.83
Recall: 1.00
F1 Score: 0.91
True Positives: 5
False Positives: 1
False Negatives: 0


## gpt-4 (data analysis):
## Evaluation Results:
Precision: 1.00
Recall: 0.40
F1 Score: 0.57
True Positives: 2
False Positives: 0
False Negatives: 3

## gpt-4o (data analysis):
### Evaluation Results:
Precision: 0.00
Recall: 0.00
F1 Score: 0.00
True Positives: 0
False Positives: 4
False Negatives: 5
